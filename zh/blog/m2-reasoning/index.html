<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>M2-Reasoning: èµ‹äºˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†èƒ½åŠ› | INCLUSION AI</title><meta name=keywords content><meta name=description content="ğŸ“– Technical Report | ğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope
ä»‹ç»
æˆ‘ä»¬æ¨å‡ºäº† M2-Reasoning-7Bï¼Œä¸€ä¸ªåœ¨é€šç”¨ä¸ç©ºé—´æ¨ç†æ–¹é¢éƒ½è¡¨ç°å“è¶Šçš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•èåˆäº†ä¸¤é¡¹å…³é”®åˆ›æ–°ï¼š(1) ä¸€ä¸ªå…¨æ–°çš„æ•°æ®ç®¡é“ï¼Œç”Ÿæˆäº†29.42ä¸‡ä¸ªé«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼ˆå…¶ä¸­16.8ä¸‡ç”¨äºå†·å¯åŠ¨å¾®è°ƒï¼Œ12.62ä¸‡ç”¨äºRLVRï¼‰ã€‚è¿™äº›æ•°æ®å…·æœ‰é€»è¾‘è¿è´¯çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶ç»è¿‡äº†å…¨é¢è¯„ä¼°ã€‚(2) ä¸€ç§åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡é€æ­¥ä¼˜åŒ–æ¥ç¼“è§£æ•°æ®é—´çš„å†²çªï¼Œå¹¶åˆ©ç”¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„å¥–åŠ±æœºåˆ¶æ¥æä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚é€šè¿‡è¿™ç§ç²¾å¿ƒç­›é€‰çš„æ•°æ®ä¸å…ˆè¿›è®­ç»ƒæ–¹æ³•çš„ç»“åˆï¼ŒM2-Reasoning-7B åœ¨8ä¸ªåŸºå‡†æµ‹è¯•ä¸­åˆ›é€ äº†æ–°çš„ä¸šç•Œæœ€ä½³æ°´å¹³ï¼ˆSOTAï¼‰ï¼Œåœ¨é€šç”¨å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚


ğŸ“Œ æ›´æ–°

[2025.07.14] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚
[2025.07.11] ğŸ”¥ M2-Reasoningæ¨¡å‹å¼€æº: ğŸ¤— Hugging Faceã€ğŸ¤– ModelScopeã€‚

ä¸»è¦ç‰¹æ€§

é«˜è´¨é‡çš„æ•°æ®æ„å»ºæµç¨‹ï¼šæˆ‘ä»¬è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªå¤šé˜¶æ®µçš„æ•°æ®åˆæˆä¸ç­›é€‰æµç¨‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå¤§é‡çš„æ¨ç†æ•°æ®ã€‚
åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ•°æ®å¼‚æ„æ€§é—®é¢˜ã€‚è¯¥ç­–ç•¥åŒ…æ‹¬é€æ­¥åŠ¨æ€ä¼˜åŒ–ï¼Œä»¥ç¼“è§£ä¸åŒæ•°æ®æºä¹‹é—´çš„å†²çªï¼Œä»¥åŠä»»åŠ¡ç‰¹å®šçš„å¥–åŠ±æœºåˆ¶ï¼Œæä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚
ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†æ¨¡å‹ï¼šæˆ‘ä»¬æå‡ºäº† M2-Reasoning-7Bï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“ä¸ºé€šç”¨æ¨ç†ä¸ç©ºé—´æ¨ç†ä»»åŠ¡è€Œè®¾è®¡çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚åœ¨8ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå€ŸåŠ©æˆ‘ä»¬å®šåˆ¶çš„æ•°æ®å’Œè®­ç»ƒæµç¨‹ï¼ŒM2-Reasoningåœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å–å¾—äº†æ–°çš„SOTAæˆæœã€‚

è¯„æµ‹
æˆ‘ä»¬åœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†å¯¹æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚æˆ‘ä»¬çš„è¯„ä¼°ä½¿ç”¨äº†ä¸€ç»„å¤šæ ·åŒ–çš„å…¬å¼€åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›æµ‹è¯•æ ¹æ®å®ƒä»¬ä¸»è¦è¡¡é‡çš„èƒ½åŠ›è¿›è¡Œåˆ†ç±»ï¼š

é€šç”¨æ¨ç†ï¼ˆæ•°å­¦ä¸é€»è¾‘ï¼‰ï¼šä¸ºäº†è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å…­é¡¹åŸºå‡†æµ‹è¯•ï¼šMathVistaã€MathVisionã€MathVerseã€DynaMathã€WeMath å’Œ LogicVistaã€‚


  
      
          Models
          MathVista
          MathVision
          MathVerse
          DynaMath
          WeMath
          LogicVista
          Avg. (Î”)
      
  
  
      
          åŸºç¡€è§„æ¨¡é€šç”¨æ¨¡å‹
          
          
          
          
          
          
          
      
      
          InternVL3-8B
          70.5
          30.0
          38.5
          25.7
          39.5
          44.5
          41.4
      
      
          InternVL3-9B
          69.0
          29.3
          37.9
          25.1
          34.8
          49.0
          40.8
      
      
          Qwen2.5-VL-7B
          68.1
          25.4
          41.1
          21.8
          36.2
          47.9
          40.1
      
      
          MUG-U-7B
          74.8
          26.1
          35.4
          17.2
          26.5
          39.8
          36.6
      
      
          SAIL-VL-1.6-8B
          74.2
          23.2
          33.4
          14.0
          29.6
          41.4
          36.0
      
      
          åŸºç¡€è§„æ¨¡æ¨ç†æ¨¡å‹
          
          
          
          
          
          
          
      
      
          WeThink-VL-7B
          71.6
          26.0
          44.2
          24.8
          48.0
          51.2
          44.3 (+4.2)
      
      
          Taichu-VLR-7B
          72.3
          27.1
          46.7
          23.0
          44.0
          48.3
          43.6
      
      
          VLAA-Thinker-7B
          68.0
          26.4
          48.2
          22.4
          41.5
          48.5
          42.5 (+2.4)
      
      
          URSA-8B-PS-GRPO
          67.8
          31.8
          41.5
          22.4
          38.3
          44.7
          41.1 (+8.2)
      
      
          Ovis2-8B
          71.8
          25.9
          42.3
          20.4
          27.2
          39.4
          37.8
      
      
          æœ¬æ–‡æ¨¡å‹
          
          
          
          
          
          
          
      
      
          Base Model
          70.2
          25.9
          30.5
          20.2
          27.2
          37.8
          35.5
      
      
          M2-Reasoning-CI-7B
          71.7
          29.2
          42.1
          25.0
          42.8
          46.8
          42.9 (+7.4)
      
      
          M2-Reasoning-7B
          75.0
          31.5
          44.7
          26.8
          41.8
          50.0
          45.0 (+9.5)
      
  



ç©ºé—´æ¨ç†ï¼šæˆ‘ä»¬ä½¿ç”¨ä¸¤é¡¹åŸºå‡†æ¥è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼šCV Benchå’ŒVSI Bench"><meta name=author content="inclusionAI, Ant Group"><link rel=canonical href=https://inclusionai.github.io/zh/blog/m2-reasoning/><link crossorigin=anonymous href=/assets/css/stylesheet.fa92d8da4b04eca0dd3a888f432d2e4fabc3dec8bebb65e348f9ce26d866c08e.css integrity="sha256-+pLY2ksE7KDdOoiPQy0uT6vD3si+u2XjSPnOJthmwI4=" rel="preload stylesheet" as=style><link rel=icon href=https://inclusionai.github.io/favicon.png><link rel=apple-touch-icon href=https://inclusionai.github.io/favicon.png><link rel=manifest href=https://inclusionai.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://inclusionai.github.io/blog/m2-reasoning/><link rel=alternate hreflang=zh href=https://inclusionai.github.io/zh/blog/m2-reasoning/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.e9080c0a180dc80cf80d5fef7c857effb14f65c998e22134feb9896034b1b81a.js integrity="sha256-6QgMChgNyAz4DV/vfIV+/7FPZcmY4iE0/rmJYDSxuBo="></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90")}</script><meta property="og:title" content="M2-Reasoning: èµ‹äºˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†èƒ½åŠ›"><meta property="og:description" content="ğŸ“– Technical Report | ğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope
ä»‹ç»
æˆ‘ä»¬æ¨å‡ºäº† M2-Reasoning-7Bï¼Œä¸€ä¸ªåœ¨é€šç”¨ä¸ç©ºé—´æ¨ç†æ–¹é¢éƒ½è¡¨ç°å“è¶Šçš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•èåˆäº†ä¸¤é¡¹å…³é”®åˆ›æ–°ï¼š(1) ä¸€ä¸ªå…¨æ–°çš„æ•°æ®ç®¡é“ï¼Œç”Ÿæˆäº†29.42ä¸‡ä¸ªé«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼ˆå…¶ä¸­16.8ä¸‡ç”¨äºå†·å¯åŠ¨å¾®è°ƒï¼Œ12.62ä¸‡ç”¨äºRLVRï¼‰ã€‚è¿™äº›æ•°æ®å…·æœ‰é€»è¾‘è¿è´¯çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶ç»è¿‡äº†å…¨é¢è¯„ä¼°ã€‚(2) ä¸€ç§åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡é€æ­¥ä¼˜åŒ–æ¥ç¼“è§£æ•°æ®é—´çš„å†²çªï¼Œå¹¶åˆ©ç”¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„å¥–åŠ±æœºåˆ¶æ¥æä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚é€šè¿‡è¿™ç§ç²¾å¿ƒç­›é€‰çš„æ•°æ®ä¸å…ˆè¿›è®­ç»ƒæ–¹æ³•çš„ç»“åˆï¼ŒM2-Reasoning-7B åœ¨8ä¸ªåŸºå‡†æµ‹è¯•ä¸­åˆ›é€ äº†æ–°çš„ä¸šç•Œæœ€ä½³æ°´å¹³ï¼ˆSOTAï¼‰ï¼Œåœ¨é€šç”¨å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚


ğŸ“Œ æ›´æ–°

[2025.07.14] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚
[2025.07.11] ğŸ”¥ M2-Reasoningæ¨¡å‹å¼€æº: ğŸ¤— Hugging Faceã€ğŸ¤– ModelScopeã€‚

ä¸»è¦ç‰¹æ€§

é«˜è´¨é‡çš„æ•°æ®æ„å»ºæµç¨‹ï¼šæˆ‘ä»¬è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªå¤šé˜¶æ®µçš„æ•°æ®åˆæˆä¸ç­›é€‰æµç¨‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå¤§é‡çš„æ¨ç†æ•°æ®ã€‚
åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ•°æ®å¼‚æ„æ€§é—®é¢˜ã€‚è¯¥ç­–ç•¥åŒ…æ‹¬é€æ­¥åŠ¨æ€ä¼˜åŒ–ï¼Œä»¥ç¼“è§£ä¸åŒæ•°æ®æºä¹‹é—´çš„å†²çªï¼Œä»¥åŠä»»åŠ¡ç‰¹å®šçš„å¥–åŠ±æœºåˆ¶ï¼Œæä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚
ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†æ¨¡å‹ï¼šæˆ‘ä»¬æå‡ºäº† M2-Reasoning-7Bï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“ä¸ºé€šç”¨æ¨ç†ä¸ç©ºé—´æ¨ç†ä»»åŠ¡è€Œè®¾è®¡çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚åœ¨8ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå€ŸåŠ©æˆ‘ä»¬å®šåˆ¶çš„æ•°æ®å’Œè®­ç»ƒæµç¨‹ï¼ŒM2-Reasoningåœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å–å¾—äº†æ–°çš„SOTAæˆæœã€‚

è¯„æµ‹
æˆ‘ä»¬åœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†å¯¹æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚æˆ‘ä»¬çš„è¯„ä¼°ä½¿ç”¨äº†ä¸€ç»„å¤šæ ·åŒ–çš„å…¬å¼€åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›æµ‹è¯•æ ¹æ®å®ƒä»¬ä¸»è¦è¡¡é‡çš„èƒ½åŠ›è¿›è¡Œåˆ†ç±»ï¼š

é€šç”¨æ¨ç†ï¼ˆæ•°å­¦ä¸é€»è¾‘ï¼‰ï¼šä¸ºäº†è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å…­é¡¹åŸºå‡†æµ‹è¯•ï¼šMathVistaã€MathVisionã€MathVerseã€DynaMathã€WeMath å’Œ LogicVistaã€‚


  
      
          Models
          MathVista
          MathVision
          MathVerse
          DynaMath
          WeMath
          LogicVista
          Avg. (Î”)
      
  
  
      
          åŸºç¡€è§„æ¨¡é€šç”¨æ¨¡å‹
          
          
          
          
          
          
          
      
      
          InternVL3-8B
          70.5
          30.0
          38.5
          25.7
          39.5
          44.5
          41.4
      
      
          InternVL3-9B
          69.0
          29.3
          37.9
          25.1
          34.8
          49.0
          40.8
      
      
          Qwen2.5-VL-7B
          68.1
          25.4
          41.1
          21.8
          36.2
          47.9
          40.1
      
      
          MUG-U-7B
          74.8
          26.1
          35.4
          17.2
          26.5
          39.8
          36.6
      
      
          SAIL-VL-1.6-8B
          74.2
          23.2
          33.4
          14.0
          29.6
          41.4
          36.0
      
      
          åŸºç¡€è§„æ¨¡æ¨ç†æ¨¡å‹
          
          
          
          
          
          
          
      
      
          WeThink-VL-7B
          71.6
          26.0
          44.2
          24.8
          48.0
          51.2
          44.3 (+4.2)
      
      
          Taichu-VLR-7B
          72.3
          27.1
          46.7
          23.0
          44.0
          48.3
          43.6
      
      
          VLAA-Thinker-7B
          68.0
          26.4
          48.2
          22.4
          41.5
          48.5
          42.5 (+2.4)
      
      
          URSA-8B-PS-GRPO
          67.8
          31.8
          41.5
          22.4
          38.3
          44.7
          41.1 (+8.2)
      
      
          Ovis2-8B
          71.8
          25.9
          42.3
          20.4
          27.2
          39.4
          37.8
      
      
          æœ¬æ–‡æ¨¡å‹
          
          
          
          
          
          
          
      
      
          Base Model
          70.2
          25.9
          30.5
          20.2
          27.2
          37.8
          35.5
      
      
          M2-Reasoning-CI-7B
          71.7
          29.2
          42.1
          25.0
          42.8
          46.8
          42.9 (+7.4)
      
      
          M2-Reasoning-7B
          75.0
          31.5
          44.7
          26.8
          41.8
          50.0
          45.0 (+9.5)
      
  



ç©ºé—´æ¨ç†ï¼šæˆ‘ä»¬ä½¿ç”¨ä¸¤é¡¹åŸºå‡†æ¥è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼šCV Benchå’ŒVSI Bench"><meta property="og:type" content="article"><meta property="og:url" content="https://inclusionai.github.io/zh/blog/m2-reasoning/"><meta property="og:image" content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-07-11T00:00:03+08:00"><meta property="article:modified_time" content="2025-07-11T00:00:03+08:00"><meta property="og:site_name" content="inclusionAI"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="M2-Reasoning: èµ‹äºˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†èƒ½åŠ›"><meta name=twitter:description content="ğŸ“– Technical Report | ğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope
ä»‹ç»
æˆ‘ä»¬æ¨å‡ºäº† M2-Reasoning-7Bï¼Œä¸€ä¸ªåœ¨é€šç”¨ä¸ç©ºé—´æ¨ç†æ–¹é¢éƒ½è¡¨ç°å“è¶Šçš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•èåˆäº†ä¸¤é¡¹å…³é”®åˆ›æ–°ï¼š(1) ä¸€ä¸ªå…¨æ–°çš„æ•°æ®ç®¡é“ï¼Œç”Ÿæˆäº†29.42ä¸‡ä¸ªé«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼ˆå…¶ä¸­16.8ä¸‡ç”¨äºå†·å¯åŠ¨å¾®è°ƒï¼Œ12.62ä¸‡ç”¨äºRLVRï¼‰ã€‚è¿™äº›æ•°æ®å…·æœ‰é€»è¾‘è¿è´¯çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶ç»è¿‡äº†å…¨é¢è¯„ä¼°ã€‚(2) ä¸€ç§åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡é€æ­¥ä¼˜åŒ–æ¥ç¼“è§£æ•°æ®é—´çš„å†²çªï¼Œå¹¶åˆ©ç”¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„å¥–åŠ±æœºåˆ¶æ¥æä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚é€šè¿‡è¿™ç§ç²¾å¿ƒç­›é€‰çš„æ•°æ®ä¸å…ˆè¿›è®­ç»ƒæ–¹æ³•çš„ç»“åˆï¼ŒM2-Reasoning-7B åœ¨8ä¸ªåŸºå‡†æµ‹è¯•ä¸­åˆ›é€ äº†æ–°çš„ä¸šç•Œæœ€ä½³æ°´å¹³ï¼ˆSOTAï¼‰ï¼Œåœ¨é€šç”¨å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚


ğŸ“Œ æ›´æ–°

[2025.07.14] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚
[2025.07.11] ğŸ”¥ M2-Reasoningæ¨¡å‹å¼€æº: ğŸ¤— Hugging Faceã€ğŸ¤– ModelScopeã€‚

ä¸»è¦ç‰¹æ€§

é«˜è´¨é‡çš„æ•°æ®æ„å»ºæµç¨‹ï¼šæˆ‘ä»¬è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªå¤šé˜¶æ®µçš„æ•°æ®åˆæˆä¸ç­›é€‰æµç¨‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå¤§é‡çš„æ¨ç†æ•°æ®ã€‚
åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ•°æ®å¼‚æ„æ€§é—®é¢˜ã€‚è¯¥ç­–ç•¥åŒ…æ‹¬é€æ­¥åŠ¨æ€ä¼˜åŒ–ï¼Œä»¥ç¼“è§£ä¸åŒæ•°æ®æºä¹‹é—´çš„å†²çªï¼Œä»¥åŠä»»åŠ¡ç‰¹å®šçš„å¥–åŠ±æœºåˆ¶ï¼Œæä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚
ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†æ¨¡å‹ï¼šæˆ‘ä»¬æå‡ºäº† M2-Reasoning-7Bï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“ä¸ºé€šç”¨æ¨ç†ä¸ç©ºé—´æ¨ç†ä»»åŠ¡è€Œè®¾è®¡çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚åœ¨8ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå€ŸåŠ©æˆ‘ä»¬å®šåˆ¶çš„æ•°æ®å’Œè®­ç»ƒæµç¨‹ï¼ŒM2-Reasoningåœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å–å¾—äº†æ–°çš„SOTAæˆæœã€‚

è¯„æµ‹
æˆ‘ä»¬åœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†å¯¹æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚æˆ‘ä»¬çš„è¯„ä¼°ä½¿ç”¨äº†ä¸€ç»„å¤šæ ·åŒ–çš„å…¬å¼€åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›æµ‹è¯•æ ¹æ®å®ƒä»¬ä¸»è¦è¡¡é‡çš„èƒ½åŠ›è¿›è¡Œåˆ†ç±»ï¼š

é€šç”¨æ¨ç†ï¼ˆæ•°å­¦ä¸é€»è¾‘ï¼‰ï¼šä¸ºäº†è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å…­é¡¹åŸºå‡†æµ‹è¯•ï¼šMathVistaã€MathVisionã€MathVerseã€DynaMathã€WeMath å’Œ LogicVistaã€‚


  
      
          Models
          MathVista
          MathVision
          MathVerse
          DynaMath
          WeMath
          LogicVista
          Avg. (Î”)
      
  
  
      
          åŸºç¡€è§„æ¨¡é€šç”¨æ¨¡å‹
          
          
          
          
          
          
          
      
      
          InternVL3-8B
          70.5
          30.0
          38.5
          25.7
          39.5
          44.5
          41.4
      
      
          InternVL3-9B
          69.0
          29.3
          37.9
          25.1
          34.8
          49.0
          40.8
      
      
          Qwen2.5-VL-7B
          68.1
          25.4
          41.1
          21.8
          36.2
          47.9
          40.1
      
      
          MUG-U-7B
          74.8
          26.1
          35.4
          17.2
          26.5
          39.8
          36.6
      
      
          SAIL-VL-1.6-8B
          74.2
          23.2
          33.4
          14.0
          29.6
          41.4
          36.0
      
      
          åŸºç¡€è§„æ¨¡æ¨ç†æ¨¡å‹
          
          
          
          
          
          
          
      
      
          WeThink-VL-7B
          71.6
          26.0
          44.2
          24.8
          48.0
          51.2
          44.3 (+4.2)
      
      
          Taichu-VLR-7B
          72.3
          27.1
          46.7
          23.0
          44.0
          48.3
          43.6
      
      
          VLAA-Thinker-7B
          68.0
          26.4
          48.2
          22.4
          41.5
          48.5
          42.5 (+2.4)
      
      
          URSA-8B-PS-GRPO
          67.8
          31.8
          41.5
          22.4
          38.3
          44.7
          41.1 (+8.2)
      
      
          Ovis2-8B
          71.8
          25.9
          42.3
          20.4
          27.2
          39.4
          37.8
      
      
          æœ¬æ–‡æ¨¡å‹
          
          
          
          
          
          
          
      
      
          Base Model
          70.2
          25.9
          30.5
          20.2
          27.2
          37.8
          35.5
      
      
          M2-Reasoning-CI-7B
          71.7
          29.2
          42.1
          25.0
          42.8
          46.8
          42.9 (+7.4)
      
      
          M2-Reasoning-7B
          75.0
          31.5
          44.7
          26.8
          41.8
          50.0
          45.0 (+9.5)
      
  



ç©ºé—´æ¨ç†ï¼šæˆ‘ä»¬ä½¿ç”¨ä¸¤é¡¹åŸºå‡†æ¥è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼šCV Benchå’ŒVSI Bench"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://inclusionai.github.io/zh/blog/"},{"@type":"ListItem","position":2,"name":"M2-Reasoning: èµ‹äºˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†èƒ½åŠ›","item":"https://inclusionai.github.io/zh/blog/m2-reasoning/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"M2-Reasoning: èµ‹äºˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†èƒ½åŠ›","name":"M2-Reasoning: èµ‹äºˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†èƒ½åŠ›","description":"ğŸ“– Technical Report | ğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope\nä»‹ç» æˆ‘ä»¬æ¨å‡ºäº† M2-Reasoning-7Bï¼Œä¸€ä¸ªåœ¨é€šç”¨ä¸ç©ºé—´æ¨ç†æ–¹é¢éƒ½è¡¨ç°å“è¶Šçš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•èåˆäº†ä¸¤é¡¹å…³é”®åˆ›æ–°ï¼š(1) ä¸€ä¸ªå…¨æ–°çš„æ•°æ®ç®¡é“ï¼Œç”Ÿæˆäº†29.42ä¸‡ä¸ªé«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼ˆå…¶ä¸­16.8ä¸‡ç”¨äºå†·å¯åŠ¨å¾®è°ƒï¼Œ12.62ä¸‡ç”¨äºRLVRï¼‰ã€‚è¿™äº›æ•°æ®å…·æœ‰é€»è¾‘è¿è´¯çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶ç»è¿‡äº†å…¨é¢è¯„ä¼°ã€‚(2) ä¸€ç§åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡é€æ­¥ä¼˜åŒ–æ¥ç¼“è§£æ•°æ®é—´çš„å†²çªï¼Œå¹¶åˆ©ç”¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„å¥–åŠ±æœºåˆ¶æ¥æä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚é€šè¿‡è¿™ç§ç²¾å¿ƒç­›é€‰çš„æ•°æ®ä¸å…ˆè¿›è®­ç»ƒæ–¹æ³•çš„ç»“åˆï¼ŒM2-Reasoning-7B åœ¨8ä¸ªåŸºå‡†æµ‹è¯•ä¸­åˆ›é€ äº†æ–°çš„ä¸šç•Œæœ€ä½³æ°´å¹³ï¼ˆSOTAï¼‰ï¼Œåœ¨é€šç”¨å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ ğŸ“Œ æ›´æ–° [2025.07.14] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚ [2025.07.11] ğŸ”¥ M2-Reasoningæ¨¡å‹å¼€æº: ğŸ¤— Hugging Faceã€ğŸ¤– ModelScopeã€‚ ä¸»è¦ç‰¹æ€§ é«˜è´¨é‡çš„æ•°æ®æ„å»ºæµç¨‹ï¼šæˆ‘ä»¬è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªå¤šé˜¶æ®µçš„æ•°æ®åˆæˆä¸ç­›é€‰æµç¨‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå¤§é‡çš„æ¨ç†æ•°æ®ã€‚ åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ•°æ®å¼‚æ„æ€§é—®é¢˜ã€‚è¯¥ç­–ç•¥åŒ…æ‹¬é€æ­¥åŠ¨æ€ä¼˜åŒ–ï¼Œä»¥ç¼“è§£ä¸åŒæ•°æ®æºä¹‹é—´çš„å†²çªï¼Œä»¥åŠä»»åŠ¡ç‰¹å®šçš„å¥–åŠ±æœºåˆ¶ï¼Œæä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚ ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†æ¨¡å‹ï¼šæˆ‘ä»¬æå‡ºäº† M2-Reasoning-7Bï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“ä¸ºé€šç”¨æ¨ç†ä¸ç©ºé—´æ¨ç†ä»»åŠ¡è€Œè®¾è®¡çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚åœ¨8ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå€ŸåŠ©æˆ‘ä»¬å®šåˆ¶çš„æ•°æ®å’Œè®­ç»ƒæµç¨‹ï¼ŒM2-Reasoningåœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å–å¾—äº†æ–°çš„SOTAæˆæœã€‚ è¯„æµ‹ æˆ‘ä»¬åœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†å¯¹æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚æˆ‘ä»¬çš„è¯„ä¼°ä½¿ç”¨äº†ä¸€ç»„å¤šæ ·åŒ–çš„å…¬å¼€åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›æµ‹è¯•æ ¹æ®å®ƒä»¬ä¸»è¦è¡¡é‡çš„èƒ½åŠ›è¿›è¡Œåˆ†ç±»ï¼š\né€šç”¨æ¨ç†ï¼ˆæ•°å­¦ä¸é€»è¾‘ï¼‰ï¼šä¸ºäº†è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å…­é¡¹åŸºå‡†æµ‹è¯•ï¼šMathVistaã€MathVisionã€MathVerseã€DynaMathã€WeMath å’Œ LogicVistaã€‚ Models MathVista MathVision MathVerse DynaMath WeMath LogicVista Avg. (Î”) åŸºç¡€è§„æ¨¡é€šç”¨æ¨¡å‹ InternVL3-8B 70.5 30.0 38.5 25.7 39.5 44.5 41.4 InternVL3-9B 69.0 29.3 37.9 25.1 34.8 49.0 40.8 Qwen2.5-VL-7B 68.1 25.4 41.1 21.8 36.2 47.9 40.1 MUG-U-7B 74.8 26.1 35.4 17.2 26.5 39.8 36.6 SAIL-VL-1.6-8B 74.2 23.2 33.4 14.0 29.6 41.4 36.0 åŸºç¡€è§„æ¨¡æ¨ç†æ¨¡å‹ WeThink-VL-7B 71.6 26.0 44.2 24.8 48.0 51.2 44.3 (+4.2) Taichu-VLR-7B 72.3 27.1 46.7 23.0 44.0 48.3 43.6 VLAA-Thinker-7B 68.0 26.4 48.2 22.4 41.5 48.5 42.5 (+2.4) URSA-8B-PS-GRPO 67.8 31.8 41.5 22.4 38.3 44.7 41.1 (+8.2) Ovis2-8B 71.8 25.9 42.3 20.4 27.2 39.4 37.8 æœ¬æ–‡æ¨¡å‹ Base Model 70.2 25.9 30.5 20.2 27.2 37.8 35.5 M2-Reasoning-CI-7B 71.7 29.2 42.1 25.0 42.8 46.8 42.9 (+7.4) M2-Reasoning-7B 75.0 31.5 44.7 26.8 41.8 50.0 45.0 (+9.5) ç©ºé—´æ¨ç†ï¼šæˆ‘ä»¬ä½¿ç”¨ä¸¤é¡¹åŸºå‡†æ¥è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼šCV Benchå’ŒVSI Bench\n","keywords":[],"articleBody":"ğŸ“– Technical Report | ğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope\nä»‹ç» æˆ‘ä»¬æ¨å‡ºäº† M2-Reasoning-7Bï¼Œä¸€ä¸ªåœ¨é€šç”¨ä¸ç©ºé—´æ¨ç†æ–¹é¢éƒ½è¡¨ç°å“è¶Šçš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•èåˆäº†ä¸¤é¡¹å…³é”®åˆ›æ–°ï¼š(1) ä¸€ä¸ªå…¨æ–°çš„æ•°æ®ç®¡é“ï¼Œç”Ÿæˆäº†29.42ä¸‡ä¸ªé«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼ˆå…¶ä¸­16.8ä¸‡ç”¨äºå†·å¯åŠ¨å¾®è°ƒï¼Œ12.62ä¸‡ç”¨äºRLVRï¼‰ã€‚è¿™äº›æ•°æ®å…·æœ‰é€»è¾‘è¿è´¯çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶ç»è¿‡äº†å…¨é¢è¯„ä¼°ã€‚(2) ä¸€ç§åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡é€æ­¥ä¼˜åŒ–æ¥ç¼“è§£æ•°æ®é—´çš„å†²çªï¼Œå¹¶åˆ©ç”¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„å¥–åŠ±æœºåˆ¶æ¥æä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚é€šè¿‡è¿™ç§ç²¾å¿ƒç­›é€‰çš„æ•°æ®ä¸å…ˆè¿›è®­ç»ƒæ–¹æ³•çš„ç»“åˆï¼ŒM2-Reasoning-7B åœ¨8ä¸ªåŸºå‡†æµ‹è¯•ä¸­åˆ›é€ äº†æ–°çš„ä¸šç•Œæœ€ä½³æ°´å¹³ï¼ˆSOTAï¼‰ï¼Œåœ¨é€šç”¨å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚ ğŸ“Œ æ›´æ–° [2025.07.14] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚ [2025.07.11] ğŸ”¥ M2-Reasoningæ¨¡å‹å¼€æº: ğŸ¤— Hugging Faceã€ğŸ¤– ModelScopeã€‚ ä¸»è¦ç‰¹æ€§ é«˜è´¨é‡çš„æ•°æ®æ„å»ºæµç¨‹ï¼šæˆ‘ä»¬è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªå¤šé˜¶æ®µçš„æ•°æ®åˆæˆä¸ç­›é€‰æµç¨‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå¤§é‡çš„æ¨ç†æ•°æ®ã€‚ åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ•°æ®å¼‚æ„æ€§é—®é¢˜ã€‚è¯¥ç­–ç•¥åŒ…æ‹¬é€æ­¥åŠ¨æ€ä¼˜åŒ–ï¼Œä»¥ç¼“è§£ä¸åŒæ•°æ®æºä¹‹é—´çš„å†²çªï¼Œä»¥åŠä»»åŠ¡ç‰¹å®šçš„å¥–åŠ±æœºåˆ¶ï¼Œæä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚ ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†æ¨¡å‹ï¼šæˆ‘ä»¬æå‡ºäº† M2-Reasoning-7Bï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“ä¸ºé€šç”¨æ¨ç†ä¸ç©ºé—´æ¨ç†ä»»åŠ¡è€Œè®¾è®¡çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚åœ¨8ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå€ŸåŠ©æˆ‘ä»¬å®šåˆ¶çš„æ•°æ®å’Œè®­ç»ƒæµç¨‹ï¼ŒM2-Reasoningåœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å–å¾—äº†æ–°çš„SOTAæˆæœã€‚ è¯„æµ‹ æˆ‘ä»¬åœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†å¯¹æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚æˆ‘ä»¬çš„è¯„ä¼°ä½¿ç”¨äº†ä¸€ç»„å¤šæ ·åŒ–çš„å…¬å¼€åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›æµ‹è¯•æ ¹æ®å®ƒä»¬ä¸»è¦è¡¡é‡çš„èƒ½åŠ›è¿›è¡Œåˆ†ç±»ï¼š\né€šç”¨æ¨ç†ï¼ˆæ•°å­¦ä¸é€»è¾‘ï¼‰ï¼šä¸ºäº†è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å…­é¡¹åŸºå‡†æµ‹è¯•ï¼šMathVistaã€MathVisionã€MathVerseã€DynaMathã€WeMath å’Œ LogicVistaã€‚ Models MathVista MathVision MathVerse DynaMath WeMath LogicVista Avg. (Î”) åŸºç¡€è§„æ¨¡é€šç”¨æ¨¡å‹ InternVL3-8B 70.5 30.0 38.5 25.7 39.5 44.5 41.4 InternVL3-9B 69.0 29.3 37.9 25.1 34.8 49.0 40.8 Qwen2.5-VL-7B 68.1 25.4 41.1 21.8 36.2 47.9 40.1 MUG-U-7B 74.8 26.1 35.4 17.2 26.5 39.8 36.6 SAIL-VL-1.6-8B 74.2 23.2 33.4 14.0 29.6 41.4 36.0 åŸºç¡€è§„æ¨¡æ¨ç†æ¨¡å‹ WeThink-VL-7B 71.6 26.0 44.2 24.8 48.0 51.2 44.3 (+4.2) Taichu-VLR-7B 72.3 27.1 46.7 23.0 44.0 48.3 43.6 VLAA-Thinker-7B 68.0 26.4 48.2 22.4 41.5 48.5 42.5 (+2.4) URSA-8B-PS-GRPO 67.8 31.8 41.5 22.4 38.3 44.7 41.1 (+8.2) Ovis2-8B 71.8 25.9 42.3 20.4 27.2 39.4 37.8 æœ¬æ–‡æ¨¡å‹ Base Model 70.2 25.9 30.5 20.2 27.2 37.8 35.5 M2-Reasoning-CI-7B 71.7 29.2 42.1 25.0 42.8 46.8 42.9 (+7.4) M2-Reasoning-7B 75.0 31.5 44.7 26.8 41.8 50.0 45.0 (+9.5) ç©ºé—´æ¨ç†ï¼šæˆ‘ä»¬ä½¿ç”¨ä¸¤é¡¹åŸºå‡†æ¥è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼šCV Benchå’ŒVSI Bench\nCV-Bench: Models Count Relation Depth Distance Avg. å¤§è§„æ¨¡æ¨¡å‹ GPT-4O 65.9 85.7 87.8 78.2 78.9 Gemini-1.5-pro 70.4 85.2 82.4 72.8 77.4 åŸºç¡€è§„æ¨¡æ¨¡å‹ InternVL3-8B 74.0 90.6 84.3 81.0 82.0 Qwen2.5-VL-7B-Instruct 65.2 86.6 70.6 79.8 75.0 LLava-NEXT-Video-7B 59.3 77.0 71.3 54.7 65.2 æœ¬æ–‡æ¨¡å‹ M2-Reasoning-7B 66.6 92.8 89.3 84.3 82.3 VSI-Bench: OC AD OS RS RDs RDr RP AO Avg. å¤§è§„æ¨¡æ¨¡å‹ Gemini-1.5-pro 56.2 30.9 64.1 43.6 51.3 46.3 36.0 34.6 45.4 GPT-4O 46.2 5.3 43.8 38.2 37.0 41.3 31.5 28.5 34.0 åŸºç¡€è§„æ¨¡æ¨¡å‹ InternVL3-8B 68.1 39.0 48.4 33.6 48.3 36.4 27.3 35.4 42.1 Video-R1-7B - - - - - - - - 37.1 Qwen2.5-VL-7B-Instruct 37.7 20.1 49.7 37.4 38.5 40.4 31.4 32.0 35.9 LLava-NeXT-Video-7B 48.5 14.0 47.8 24.2 43.5 42.4 34.0 30.6 35.6 æœ¬æ–‡æ¨¡å‹ M2-Reasoning-7B 41.0 34.0 60.9 55.4 40.7 47.3 29.9 28.8 42.3 æ¨¡å‹ä¸‹è½½ æ‚¨å¯ä»¥ä» Hugging Face å’Œ ModelScope ä¸¤ä¸ªå¹³å°ä¸‹è½½æ¨¡å‹ã€‚ å¦‚æœæ‚¨ä½äºä¸­å›½å¤§é™†ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ä» ModelScope ä¸‹è½½æ¨¡å‹ã€‚\nä½¿ç”¨æ ·ä¾‹ åŸºç¡€ç¯å¢ƒä¸ºï¼špython=3.10ã€torch=2.6.0+cu124ã€transformers=4.49.0\næˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨æœ¬æ¨¡å‹ã€‚\nimport os import torch from transformers import ( AutoProcessor, AutoTokenizer, ) import warnings import argparse from modeling_bailing_qwen2_5 import Bailing_qwen2_5NativeForConditionalGeneration from processing_bailing_qwen2_5 import Bailing_qwen2_5Processor warnings.filterwarnings(\"ignore\") class BailingMMInfer: def __init__(self, model_name_or_path, device=\"cuda\", max_pixels=None, min_pixels=None, video_max_pixels=768 * 28 * 28, video_min_pixels=128 * 28 * 28, generation_config=None ): super().__init__() self.model_name_or_path = model_name_or_path self.device = device self.device_map = device self.video_max_pixels = video_max_pixels if video_max_pixels is not None else 768 * 28 * 28 self.video_min_pixels = video_min_pixels if video_min_pixels is not None else 128 * 28 * 28 self.model, self.tokenizer, self.processor = self.load_model_processor() if max_pixels is not None: self.processor.max_pixels = max_pixels if min_pixels is not None: self.processor.min_pixels = min_pixels if generation_config is None: generation_config = { \"num_beams\": 1, \"do_sample\": True, \"temperature\": 0.9 } self.generation_config = generation_config def load_model_processor(self): model = Bailing_qwen2_5NativeForConditionalGeneration.from_pretrained( self.model_name_or_path, torch_dtype=torch.bfloat16, device_map=self.device_map, _attn_implementation=\"flash_attention_2\" ).eval() tokenizer = AutoTokenizer.from_pretrained(self.model_name_or_path, add_bos_token=True, trust_remote_code=True) processor = Bailing_qwen2_5Processor.from_pretrained(self.model_name_or_path, trust_remote_code=True) return model, tokenizer, processor def generate(self, messages, max_new_tokens=512): text = self.processor.apply_chat_template( messages, tokenize=False, add_generation_prompt=True, use_system=True ) image_inputs, video_inputs = self.processor.process_vision_info(messages) inputs = self.processor( text=[text], images=image_inputs, videos=video_inputs, return_tensors=\"pt\", ) # print(inputs) print(self.tokenizer.decode(inputs['input_ids'][0])) inputs = inputs.to(self.device) for k in inputs.keys(): if k == \"pixel_values\" or k == \"pixel_values_videos\": inputs[k] = inputs[k].to(dtype=torch.bfloat16) with torch.no_grad(): generated_ids = self.model.generate( inputs, max_new_tokens=max_new_tokens, eos_token_id=self.processor.tokenizer.eos_token_id, **self.generation_config, ) generated_ids_trimmed = [ out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids) ] output_text = self.processor.batch_decode( generated_ids_trimmed, skip_special_tokens=False, clean_up_tokenization_spaces=False )[0] return output_text if __name__ == '__main__': parser = argparse.ArgumentParser() parser.add_argument('--model_name_or_path', type=str, default=\"inclusionAI/M2-Reasoning\") parser.add_argument('--max_pixels', type=int, default=401408) parser.add_argument('--min_pixels', type=int, default=401408) parser.add_argument('--max_new_tokens', type=int, default=4096) args = parser.parse_args() device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # model_name_or_path = os.path.join(args.input_dir, args.model_name_or_path) bailing2 = BailingMMInfer( args.model_name_or_path, device=device, max_pixels=args.max_pixels, min_pixels=args.min_pixels ) messages = [ { \"role\": \"system\", \"content\": [ {\"type\": \"text\", \"text\": \"You are a helpful assistant. When the user asks a question, your response must include two parts: first, the reasoning process enclosed in ... tags, then the final answer enclosed in ... tags. The critical answer or key result should be placed within \\\\boxed{}.\"}]}, { \"role\": \"user\", \"content\": [ {\"type\": \"image\", \"image\": \"./assets/example1.png\"}, {\"type\": \"text\", \"text\": \"\\nQuestion:\\n\\nRhombus $QRST$ has an area of 137.9 square meters. If $RT$ is 12.2 meters, find $QS$.\\nA. 11.3\\nB. 22.4\\nC. 22.6\\nD. 25.6\"}, ], }, ] output_text = bailing2.generate(messages, max_new_tokens=args.max_new_tokens) print(output_text) ''' [Output]: To find the length of \\( QS \\) in the rhombus \\( QRST \\), we can use the formula for the area of a rhombus, which is given by: \\[ \\text{Area} = \\frac{1}{2} \\times d_1 \\times d_2 \\] where \\( d_1 \\) and \\( d_2 \\) are the lengths of the diagonals. In this problem, we are given: - The area of the rhombus is 137.9 square meters. - One of the diagonals, ","wordCount":"736","inLanguage":"zh","datePublished":"2025-07-11T00:00:03+08:00","dateModified":"2025-07-11T00:00:03+08:00","author":{"@type":"Person","name":"inclusionAI, Ant Group"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://inclusionai.github.io/zh/blog/m2-reasoning/"},"publisher":{"@type":"Organization","name":"INCLUSION AI","logo":{"@type":"ImageObject","url":"https://inclusionai.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="inclusionAI (Alt + H)"><img src=https://inclusionai.github.io/img/logo_head.png alt aria-label=logo height=50></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://github.com/inclusionAI title="Try Ling & Ming"><span>Try Ling & Ming</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>M2-Reasoning: èµ‹äºˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†èƒ½åŠ›</h1><div class=post-meta>&lt;span title='2025-07-11 00:00:03 +0800 +0800'>2025å¹´7æœˆ11æ—¥&lt;/span>&amp;nbsp;Â·&amp;nbsp;4 åˆ†é’Ÿ&amp;nbsp;Â·&amp;nbsp;736 å­—&amp;nbsp;Â·&amp;nbsp;inclusionAI, Ant Group&nbsp;|&nbsp;è¯­è¨€:<ul class=i18n_list><li><a href=https://inclusionai.github.io/blog/m2-reasoning/>English</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><p>ğŸ“– <a href=https://arxiv.org/abs/2507.08306>Technical Report</a> | ğŸ¤— <a href=https://huggingface.co/inclusionAI/M2-Reasoning>Hugging Face</a>ï½œ ğŸ¤– <a href=https://www.modelscope.cn/models/inclusionAI/M2-Reasoning>ModelScope</a></p><h2 id=ä»‹ç»>ä»‹ç»<a hidden class=anchor aria-hidden=true href=#ä»‹ç»>#</a></h2><p>æˆ‘ä»¬æ¨å‡ºäº† M2-Reasoning-7Bï¼Œä¸€ä¸ªåœ¨é€šç”¨ä¸ç©ºé—´æ¨ç†æ–¹é¢éƒ½è¡¨ç°å“è¶Šçš„æ¨¡å‹ã€‚æˆ‘ä»¬çš„æ–¹æ³•èåˆäº†ä¸¤é¡¹å…³é”®åˆ›æ–°ï¼š(1) ä¸€ä¸ªå…¨æ–°çš„æ•°æ®ç®¡é“ï¼Œç”Ÿæˆäº†29.42ä¸‡ä¸ªé«˜è´¨é‡æ•°æ®æ ·æœ¬ï¼ˆå…¶ä¸­16.8ä¸‡ç”¨äºå†·å¯åŠ¨å¾®è°ƒï¼Œ12.62ä¸‡ç”¨äºRLVRï¼‰ã€‚è¿™äº›æ•°æ®å…·æœ‰é€»è¾‘è¿è´¯çš„æ¨ç†è½¨è¿¹ï¼Œå¹¶ç»è¿‡äº†å…¨é¢è¯„ä¼°ã€‚(2) ä¸€ç§åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼Œé€šè¿‡é€æ­¥ä¼˜åŒ–æ¥ç¼“è§£æ•°æ®é—´çš„å†²çªï¼Œå¹¶åˆ©ç”¨é’ˆå¯¹ç‰¹å®šä»»åŠ¡çš„å¥–åŠ±æœºåˆ¶æ¥æä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚é€šè¿‡è¿™ç§ç²¾å¿ƒç­›é€‰çš„æ•°æ®ä¸å…ˆè¿›è®­ç»ƒæ–¹æ³•çš„ç»“åˆï¼ŒM2-Reasoning-7B åœ¨8ä¸ªåŸºå‡†æµ‹è¯•ä¸­åˆ›é€ äº†æ–°çš„ä¸šç•Œæœ€ä½³æ°´å¹³ï¼ˆSOTAï¼‰ï¼Œåœ¨é€šç”¨å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å±•ç°å‡ºå“è¶Šçš„æ€§èƒ½ã€‚
<img loading=lazy src=assets/teaser.png alt></p><h2 id=-æ›´æ–°>ğŸ“Œ æ›´æ–°<a hidden class=anchor aria-hidden=true href=#-æ›´æ–°>#</a></h2><ul><li>[2025.07.14] ğŸ”¥ æˆ‘ä»¬çš„<a href=https://arxiv.org/abs/2507.08306>æŠ€æœ¯æŠ¥å‘Š</a>å·²å…¬å¼€å‘å¸ƒäº arxivã€‚</li><li>[2025.07.11] ğŸ”¥ M2-Reasoningæ¨¡å‹å¼€æº: ğŸ¤— <a href=https://huggingface.co/inclusionAI/M2-Reasoning>Hugging Face</a>ã€ğŸ¤– <a href=https://www.modelscope.cn/models/inclusionAI/M2-Reasoning>ModelScope</a>ã€‚</li></ul><h2 id=ä¸»è¦ç‰¹æ€§>ä¸»è¦ç‰¹æ€§<a hidden class=anchor aria-hidden=true href=#ä¸»è¦ç‰¹æ€§>#</a></h2><ul><li>é«˜è´¨é‡çš„æ•°æ®æ„å»ºæµç¨‹ï¼šæˆ‘ä»¬è®¾è®¡å¹¶å®ç°äº†ä¸€ä¸ªå¤šé˜¶æ®µçš„æ•°æ®åˆæˆä¸ç­›é€‰æµç¨‹ï¼Œèƒ½å¤Ÿç”Ÿæˆå¤§é‡çš„æ¨ç†æ•°æ®ã€‚</li><li>åŠ¨æ€å¤šä»»åŠ¡è®­ç»ƒç­–ç•¥ï¼šæˆ‘ä»¬æå‡ºäº†ä¸€ç§é«˜æ•ˆçš„è®­ç»ƒç­–ç•¥ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æ•°æ®å¼‚æ„æ€§é—®é¢˜ã€‚è¯¥ç­–ç•¥åŒ…æ‹¬é€æ­¥åŠ¨æ€ä¼˜åŒ–ï¼Œä»¥ç¼“è§£ä¸åŒæ•°æ®æºä¹‹é—´çš„å†²çªï¼Œä»¥åŠä»»åŠ¡ç‰¹å®šçš„å¥–åŠ±æœºåˆ¶ï¼Œæä¾›å®šåˆ¶åŒ–çš„æ¿€åŠ±ä¿¡å·ã€‚</li><li>ç»Ÿä¸€çš„é€šç”¨ä¸ç©ºé—´æ¨ç†æ¨¡å‹ï¼šæˆ‘ä»¬æå‡ºäº† M2-Reasoning-7Bï¼Œè¿™æ˜¯ä¸€æ¬¾ä¸“ä¸ºé€šç”¨æ¨ç†ä¸ç©ºé—´æ¨ç†ä»»åŠ¡è€Œè®¾è®¡çš„å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹ï¼ˆMLLMï¼‰ã€‚åœ¨8ä¸ªä¸åŒçš„åŸºå‡†æµ‹è¯•ä¸­è¿›è¡Œçš„å¹¿æ³›è¯„ä¼°è¡¨æ˜ï¼Œå€ŸåŠ©æˆ‘ä»¬å®šåˆ¶çš„æ•°æ®å’Œè®­ç»ƒæµç¨‹ï¼ŒM2-Reasoningåœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†é¢†åŸŸå‡å–å¾—äº†æ–°çš„SOTAæˆæœã€‚</li></ul><h2 id=è¯„æµ‹>è¯„æµ‹<a hidden class=anchor aria-hidden=true href=#è¯„æµ‹>#</a></h2><p>æˆ‘ä»¬åœ¨é€šç”¨æ¨ç†å’Œç©ºé—´æ¨ç†å¯¹æ¨¡å‹è¿›è¡Œäº†å…¨é¢è¯„ä¼°ã€‚æˆ‘ä»¬çš„è¯„ä¼°ä½¿ç”¨äº†ä¸€ç»„å¤šæ ·åŒ–çš„å…¬å¼€åŸºå‡†æµ‹è¯•ï¼Œè¿™äº›æµ‹è¯•æ ¹æ®å®ƒä»¬ä¸»è¦è¡¡é‡çš„èƒ½åŠ›è¿›è¡Œåˆ†ç±»ï¼š</p><ul><li>é€šç”¨æ¨ç†ï¼ˆæ•°å­¦ä¸é€»è¾‘ï¼‰ï¼šä¸ºäº†è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†å…­é¡¹åŸºå‡†æµ‹è¯•ï¼šMathVistaã€MathVisionã€MathVerseã€DynaMathã€WeMath å’Œ LogicVistaã€‚</li></ul><table><thead><tr><th style=text-align:center>Models</th><th style=text-align:center>MathVista</th><th style=text-align:center>MathVision</th><th style=text-align:center>MathVerse</th><th style=text-align:center>DynaMath</th><th style=text-align:center>WeMath</th><th style=text-align:center>LogicVista</th><th style=text-align:center>Avg. (Î”)</th></tr></thead><tbody><tr><td style=text-align:center><em><strong>åŸºç¡€è§„æ¨¡é€šç”¨æ¨¡å‹</strong></em></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td style=text-align:center>InternVL3-8B</td><td style=text-align:center>70.5</td><td style=text-align:center>30.0</td><td style=text-align:center>38.5</td><td style=text-align:center>25.7</td><td style=text-align:center>39.5</td><td style=text-align:center>44.5</td><td style=text-align:center>41.4</td></tr><tr><td style=text-align:center>InternVL3-9B</td><td style=text-align:center>69.0</td><td style=text-align:center>29.3</td><td style=text-align:center>37.9</td><td style=text-align:center>25.1</td><td style=text-align:center>34.8</td><td style=text-align:center>49.0</td><td style=text-align:center>40.8</td></tr><tr><td style=text-align:center>Qwen2.5-VL-7B</td><td style=text-align:center>68.1</td><td style=text-align:center>25.4</td><td style=text-align:center>41.1</td><td style=text-align:center>21.8</td><td style=text-align:center>36.2</td><td style=text-align:center>47.9</td><td style=text-align:center>40.1</td></tr><tr><td style=text-align:center>MUG-U-7B</td><td style=text-align:center>74.8</td><td style=text-align:center>26.1</td><td style=text-align:center>35.4</td><td style=text-align:center>17.2</td><td style=text-align:center>26.5</td><td style=text-align:center>39.8</td><td style=text-align:center>36.6</td></tr><tr><td style=text-align:center>SAIL-VL-1.6-8B</td><td style=text-align:center>74.2</td><td style=text-align:center>23.2</td><td style=text-align:center>33.4</td><td style=text-align:center>14.0</td><td style=text-align:center>29.6</td><td style=text-align:center>41.4</td><td style=text-align:center>36.0</td></tr><tr><td style=text-align:center><em><strong>åŸºç¡€è§„æ¨¡æ¨ç†æ¨¡å‹</strong></em></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td style=text-align:center>WeThink-VL-7B</td><td style=text-align:center>71.6</td><td style=text-align:center>26.0</td><td style=text-align:center>44.2</td><td style=text-align:center>24.8</td><td style=text-align:center><strong>48.0</strong></td><td style=text-align:center><strong>51.2</strong></td><td style=text-align:center>44.3 (+4.2)</td></tr><tr><td style=text-align:center>Taichu-VLR-7B</td><td style=text-align:center>72.3</td><td style=text-align:center>27.1</td><td style=text-align:center>46.7</td><td style=text-align:center>23.0</td><td style=text-align:center>44.0</td><td style=text-align:center>48.3</td><td style=text-align:center>43.6</td></tr><tr><td style=text-align:center>VLAA-Thinker-7B</td><td style=text-align:center>68.0</td><td style=text-align:center>26.4</td><td style=text-align:center><strong>48.2</strong></td><td style=text-align:center>22.4</td><td style=text-align:center>41.5</td><td style=text-align:center>48.5</td><td style=text-align:center>42.5 (+2.4)</td></tr><tr><td style=text-align:center>URSA-8B-PS-GRPO</td><td style=text-align:center>67.8</td><td style=text-align:center><strong>31.8</strong></td><td style=text-align:center>41.5</td><td style=text-align:center>22.4</td><td style=text-align:center>38.3</td><td style=text-align:center>44.7</td><td style=text-align:center>41.1 (+8.2)</td></tr><tr><td style=text-align:center>Ovis2-8B</td><td style=text-align:center>71.8</td><td style=text-align:center>25.9</td><td style=text-align:center>42.3</td><td style=text-align:center>20.4</td><td style=text-align:center>27.2</td><td style=text-align:center>39.4</td><td style=text-align:center>37.8</td></tr><tr><td style=text-align:center><em><strong>æœ¬æ–‡æ¨¡å‹</strong></em></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr><tr><td style=text-align:center>Base Model</td><td style=text-align:center>70.2</td><td style=text-align:center>25.9</td><td style=text-align:center>30.5</td><td style=text-align:center>20.2</td><td style=text-align:center>27.2</td><td style=text-align:center>37.8</td><td style=text-align:center>35.5</td></tr><tr><td style=text-align:center>M2-Reasoning-CI-7B</td><td style=text-align:center>71.7</td><td style=text-align:center>29.2</td><td style=text-align:center>42.1</td><td style=text-align:center>25.0</td><td style=text-align:center>42.8</td><td style=text-align:center>46.8</td><td style=text-align:center>42.9 (+7.4)</td></tr><tr><td style=text-align:center>M2-Reasoning-7B</td><td style=text-align:center><strong>75.0</strong></td><td style=text-align:center>31.5</td><td style=text-align:center>44.7</td><td style=text-align:center><strong>26.8</strong></td><td style=text-align:center>41.8</td><td style=text-align:center>50.0</td><td style=text-align:center><strong>45.0 (+9.5)</strong></td></tr></tbody></table><ul><li><p>ç©ºé—´æ¨ç†ï¼šæˆ‘ä»¬ä½¿ç”¨ä¸¤é¡¹åŸºå‡†æ¥è¯„ä¼°è¿™ä¸€èƒ½åŠ›ï¼šCV Benchå’ŒVSI Bench</p><ul><li>CV-Bench:</li></ul><table><thead><tr><th style=text-align:left>Models</th><th style=text-align:center>Count</th><th style=text-align:center>Relation</th><th style=text-align:center>Depth</th><th style=text-align:center>Distance</th><th style=text-align:center>Avg.</th></tr></thead><tbody><tr><td style=text-align:left><em><strong>å¤§è§„æ¨¡æ¨¡å‹</strong></em></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td></tr><tr><td style=text-align:left>GPT-4O</td><td style=text-align:center>65.9</td><td style=text-align:center>85.7</td><td style=text-align:center>87.8</td><td style=text-align:center>78.2</td><td style=text-align:center>78.9</td></tr><tr><td style=text-align:left>Gemini-1.5-pro</td><td style=text-align:center>70.4</td><td style=text-align:center>85.2</td><td style=text-align:center>82.4</td><td style=text-align:center>72.8</td><td style=text-align:center>77.4</td></tr><tr><td style=text-align:left><em><strong>åŸºç¡€è§„æ¨¡æ¨¡å‹</strong></em></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td></tr><tr><td style=text-align:left>InternVL3-8B</td><td style=text-align:center><strong>74.0</strong></td><td style=text-align:center>90.6</td><td style=text-align:center>84.3</td><td style=text-align:center>81.0</td><td style=text-align:center>82.0</td></tr><tr><td style=text-align:left>Qwen2.5-VL-7B-Instruct</td><td style=text-align:center>65.2</td><td style=text-align:center>86.6</td><td style=text-align:center>70.6</td><td style=text-align:center>79.8</td><td style=text-align:center>75.0</td></tr><tr><td style=text-align:left>LLava-NEXT-Video-7B</td><td style=text-align:center>59.3</td><td style=text-align:center>77.0</td><td style=text-align:center>71.3</td><td style=text-align:center>54.7</td><td style=text-align:center>65.2</td></tr><tr><td style=text-align:left><em><strong>æœ¬æ–‡æ¨¡å‹</strong></em></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td></tr><tr><td style=text-align:left>M2-Reasoning-7B</td><td style=text-align:center>66.6</td><td style=text-align:center><strong>92.8</strong></td><td style=text-align:center><strong>89.3</strong></td><td style=text-align:center><strong>84.3</strong></td><td style=text-align:center><strong>82.3</strong></td></tr></tbody></table><ul><li>VSI-Bench:</li></ul><table><thead><tr><th style=text-align:left></th><th style=text-align:center>OC</th><th style=text-align:center>AD</th><th style=text-align:center>OS</th><th style=text-align:center>RS</th><th style=text-align:center>RDs</th><th style=text-align:center>RDr</th><th style=text-align:center>RP</th><th style=text-align:center>AO</th><th style=text-align:center>Avg.</th></tr></thead><tbody><tr><td style=text-align:left><em><strong>å¤§è§„æ¨¡æ¨¡å‹</strong></em></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td></tr><tr><td style=text-align:left>Gemini-1.5-pro</td><td style=text-align:center>56.2</td><td style=text-align:center>30.9</td><td style=text-align:center>64.1</td><td style=text-align:center>43.6</td><td style=text-align:center>51.3</td><td style=text-align:center>46.3</td><td style=text-align:center>36.0</td><td style=text-align:center>34.6</td><td style=text-align:center>45.4</td></tr><tr><td style=text-align:left>GPT-4O</td><td style=text-align:center>46.2</td><td style=text-align:center>5.3</td><td style=text-align:center>43.8</td><td style=text-align:center>38.2</td><td style=text-align:center>37.0</td><td style=text-align:center>41.3</td><td style=text-align:center>31.5</td><td style=text-align:center>28.5</td><td style=text-align:center>34.0</td></tr><tr><td style=text-align:left><em><strong>åŸºç¡€è§„æ¨¡æ¨¡å‹</strong></em></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td></tr><tr><td style=text-align:left>InternVL3-8B</td><td style=text-align:center><strong>68.1</strong></td><td style=text-align:center><strong>39.0</strong></td><td style=text-align:center>48.4</td><td style=text-align:center>33.6</td><td style=text-align:center><strong>48.3</strong></td><td style=text-align:center>36.4</td><td style=text-align:center>27.3</td><td style=text-align:center><strong>35.4</strong></td><td style=text-align:center>42.1</td></tr><tr><td style=text-align:left>Video-R1-7B</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>37.1</td></tr><tr><td style=text-align:left>Qwen2.5-VL-7B-Instruct</td><td style=text-align:center>37.7</td><td style=text-align:center>20.1</td><td style=text-align:center>49.7</td><td style=text-align:center>37.4</td><td style=text-align:center>38.5</td><td style=text-align:center>40.4</td><td style=text-align:center>31.4</td><td style=text-align:center>32.0</td><td style=text-align:center>35.9</td></tr><tr><td style=text-align:left>LLava-NeXT-Video-7B</td><td style=text-align:center>48.5</td><td style=text-align:center>14.0</td><td style=text-align:center>47.8</td><td style=text-align:center>24.2</td><td style=text-align:center>43.5</td><td style=text-align:center>42.4</td><td style=text-align:center><strong>34.0</strong></td><td style=text-align:center>30.6</td><td style=text-align:center>35.6</td></tr><tr><td style=text-align:left><em><strong>æœ¬æ–‡æ¨¡å‹</strong></em></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td><td style=text-align:center></td></tr><tr><td style=text-align:left>M2-Reasoning-7B</td><td style=text-align:center>41.0</td><td style=text-align:center>34.0</td><td style=text-align:center><strong>60.9</strong></td><td style=text-align:center><strong>55.4</strong></td><td style=text-align:center>40.7</td><td style=text-align:center><strong>47.3</strong></td><td style=text-align:center>29.9</td><td style=text-align:center>28.8</td><td style=text-align:center><strong>42.3</strong></td></tr></tbody></table></li></ul><h2 id=æ¨¡å‹ä¸‹è½½>æ¨¡å‹ä¸‹è½½<a hidden class=anchor aria-hidden=true href=#æ¨¡å‹ä¸‹è½½>#</a></h2><p>æ‚¨å¯ä»¥ä» <a href=https://huggingface.co/inclusionAI/M2-Reasoning>Hugging Face</a> å’Œ <a href=https://www.modelscope.cn/models/inclusionAI/M2-Reasoning>ModelScope</a> ä¸¤ä¸ªå¹³å°ä¸‹è½½æ¨¡å‹ã€‚
å¦‚æœæ‚¨ä½äºä¸­å›½å¤§é™†ï¼Œæˆ‘ä»¬å»ºè®®æ‚¨ä» <a href=https://www.modelscope.cn/models/inclusionAI/M2-Reasoning>ModelScope</a> ä¸‹è½½æ¨¡å‹ã€‚</p><h2 id=ä½¿ç”¨æ ·ä¾‹>ä½¿ç”¨æ ·ä¾‹<a hidden class=anchor aria-hidden=true href=#ä½¿ç”¨æ ·ä¾‹>#</a></h2><p>åŸºç¡€ç¯å¢ƒä¸ºï¼š<code>python=3.10</code>ã€<code>torch=2.6.0+cu124</code>ã€<code>transformers=4.49.0</code></p><p>æˆ‘ä»¬æä¾›äº†ä¸€ä¸ªç®€å•çš„ç¤ºä¾‹ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨æœ¬æ¨¡å‹ã€‚</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>AutoProcessor</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>AutoTokenizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>warnings</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>argparse</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>modeling_bailing_qwen2_5</span> <span class=kn>import</span> <span class=n>Bailing_qwen2_5NativeForConditionalGeneration</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>processing_bailing_qwen2_5</span> <span class=kn>import</span> <span class=n>Bailing_qwen2_5Processor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>warnings</span><span class=o>.</span><span class=n>filterwarnings</span><span class=p>(</span><span class=s2>&#34;ignore&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>BailingMMInfer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>model_name_or_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>device</span><span class=o>=</span><span class=s2>&#34;cuda&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_pixels</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>min_pixels</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>video_max_pixels</span><span class=o>=</span><span class=mi>768</span> <span class=o>*</span> <span class=mi>28</span> <span class=o>*</span> <span class=mi>28</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>video_min_pixels</span><span class=o>=</span><span class=mi>128</span> <span class=o>*</span> <span class=mi>28</span> <span class=o>*</span> <span class=mi>28</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>generation_config</span><span class=o>=</span><span class=kc>None</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model_name_or_path</span> <span class=o>=</span> <span class=n>model_name_or_path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>device</span> <span class=o>=</span> <span class=n>device</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>device_map</span> <span class=o>=</span> <span class=n>device</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>video_max_pixels</span> <span class=o>=</span> <span class=n>video_max_pixels</span> <span class=k>if</span> <span class=n>video_max_pixels</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=k>else</span> <span class=mi>768</span> <span class=o>*</span> <span class=mi>28</span> <span class=o>*</span> <span class=mi>28</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>video_min_pixels</span> <span class=o>=</span> <span class=n>video_min_pixels</span> <span class=k>if</span> <span class=n>video_min_pixels</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span> <span class=k>else</span> <span class=mi>128</span> <span class=o>*</span> <span class=mi>28</span> <span class=o>*</span> <span class=mi>28</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>load_model_processor</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>max_pixels</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>max_pixels</span> <span class=o>=</span> <span class=n>max_pixels</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>min_pixels</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>min_pixels</span> <span class=o>=</span> <span class=n>min_pixels</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>generation_config</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>generation_config</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;num_beams&#34;</span><span class=p>:</span> <span class=mi>1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;do_sample&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;temperature&#34;</span><span class=p>:</span> <span class=mf>0.9</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>generation_config</span> <span class=o>=</span> <span class=n>generation_config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>load_model_processor</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>model</span> <span class=o>=</span> <span class=n>Bailing_qwen2_5NativeForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>model_name_or_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>device_map</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>device_map</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>_attn_implementation</span><span class=o>=</span><span class=s2>&#34;flash_attention_2&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model_name_or_path</span><span class=p>,</span> <span class=n>add_bos_token</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>processor</span> <span class=o>=</span> <span class=n>Bailing_qwen2_5Processor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>model_name_or_path</span><span class=p>,</span> <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>model</span><span class=p>,</span> <span class=n>tokenizer</span><span class=p>,</span> <span class=n>processor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>generate</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>messages</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>512</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>text</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>use_system</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>image_inputs</span><span class=p>,</span> <span class=n>video_inputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>process_vision_info</span><span class=p>(</span><span class=n>messages</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>inputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>text</span><span class=o>=</span><span class=p>[</span><span class=n>text</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>images</span><span class=o>=</span><span class=n>image_inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>videos</span><span class=o>=</span><span class=n>video_inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1># print(inputs)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>inputs</span><span class=p>[</span><span class=s1>&#39;input_ids&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>inputs</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>inputs</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>k</span> <span class=o>==</span> <span class=s2>&#34;pixel_values&#34;</span> <span class=ow>or</span> <span class=n>k</span> <span class=o>==</span> <span class=s2>&#34;pixel_values_videos&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>inputs</span><span class=p>[</span><span class=n>k</span><span class=p>]</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>generated_ids</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>max_new_tokens</span><span class=o>=</span><span class=n>max_new_tokens</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>eos_token_id</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=o>**</span><span class=bp>self</span><span class=o>.</span><span class=n>generation_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>generated_ids_trimmed</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>out_ids</span><span class=p>[</span><span class=nb>len</span><span class=p>(</span><span class=n>in_ids</span><span class=p>):]</span> <span class=k>for</span> <span class=n>in_ids</span><span class=p>,</span> <span class=n>out_ids</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>inputs</span><span class=o>.</span><span class=n>input_ids</span><span class=p>,</span> <span class=n>generated_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>output_text</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>generated_ids_trimmed</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>clean_up_tokenization_spaces</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>        <span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>output_text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span> <span class=o>=</span> <span class=n>argparse</span><span class=o>.</span><span class=n>ArgumentParser</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;--model_name_or_path&#39;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>str</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=s2>&#34;inclusionAI/M2-Reasoning&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;--max_pixels&#39;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>int</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=mi>401408</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;--min_pixels&#39;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>int</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=mi>401408</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s1>&#39;--max_new_tokens&#39;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>int</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=mi>4096</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>args</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>device</span> <span class=o>=</span> <span class=s2>&#34;cuda&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># model_name_or_path = os.path.join(args.input_dir, args.model_name_or_path)</span>
</span></span><span class=line><span class=cl>    <span class=n>bailing2</span> <span class=o>=</span> <span class=n>BailingMMInfer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>args</span><span class=o>.</span><span class=n>model_name_or_path</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>        <span class=n>device</span><span class=o>=</span><span class=n>device</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>        <span class=n>max_pixels</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>max_pixels</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>        <span class=n>min_pixels</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>min_pixels</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>            <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;You are a helpful assistant. When the user asks a question, your response must include two parts: first, the reasoning process enclosed in &lt;think&gt;...&lt;/think&gt; tags, then the final answer enclosed in &lt;answer&gt;...&lt;/answer&gt; tags. The critical answer or key result should be placed within </span><span class=se>\\</span><span class=s2>boxed</span><span class=si>{}</span><span class=s2>.&#34;</span><span class=p>}]},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image&#34;</span><span class=p>,</span> <span class=s2>&#34;image&#34;</span><span class=p>:</span> <span class=s2>&#34;./assets/example1.png&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;</span><span class=se>\n</span><span class=s2>Question:</span><span class=se>\n\n</span><span class=s2>Rhombus $QRST$ has an area of 137.9 square meters. If $RT$ is 12.2 meters, find $QS$.</span><span class=se>\n</span><span class=s2>A. 11.3</span><span class=se>\n</span><span class=s2>B. 22.4</span><span class=se>\n</span><span class=s2>C. 22.6</span><span class=se>\n</span><span class=s2>D. 25.6&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>output_text</span> <span class=o>=</span> <span class=n>bailing2</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>messages</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=n>args</span><span class=o>.</span><span class=n>max_new_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>output_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=s1>&#39;&#39;&#39;
</span></span></span><span class=line><span class=cl><span class=s1>[Output]:
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>&lt;think&gt;
</span></span></span><span class=line><span class=cl><span class=s1>To find the length of \( QS \) in the rhombus \( QRST \), we can use the formula for the area of a rhombus, which is given by:
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>\[
</span></span></span><span class=line><span class=cl><span class=se>\t</span><span class=s1>ext</span><span class=si>{Area}</span><span class=s1> = </span><span class=se>\f</span><span class=s1>rac</span><span class=si>{1}{2}</span><span class=s1> </span><span class=se>\t</span><span class=s1>imes d_1 </span><span class=se>\t</span><span class=s1>imes d_2
</span></span></span><span class=line><span class=cl><span class=s1>\]
</span></span></span><span class=line><span class=cl><span class=s1>
</span></span></span><span class=line><span class=cl><span class=s1>where \( d_1 \) and \( d_2 \) are the lengths of the diagonals. In this problem, we are given:
</span></span></span><span class=line><span class=cl><span class=s1>- The area of the rhombus is 137.9 square meters.
</span></span></span><span class=line><span class=cl><span class=s1>- One of the diagonals,
</span></span></span></code></pre></div></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://inclusionai.github.io/zh/>INCLUSION AI</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 8" fill="currentColor"><path d="M12 8H0l6-8z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="å¤åˆ¶";function s(){t.innerHTML="å·²å¤åˆ¶ï¼",setTimeout(()=>{t.innerHTML="å¤åˆ¶"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>