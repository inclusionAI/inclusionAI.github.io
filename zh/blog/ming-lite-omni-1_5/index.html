<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Ming-lite-omni v1.5：全能模型再升级，效果与体验双优化 | INCLUSION AI</title><meta name=keywords content><meta name=description content="GITHUB 🤗 Hugging Face｜ 🤖 ModelScope
概述 本次发布的 Ming-lite-omni V1.5 是对 Ming-lite-omni(Github) 全模态能力的一次全面升级， 在包括图文理解、文档理解、视频理解、语音理解和合成、图像生成和编辑等任务上均有明显提升。Ming-lite-omni V1.5 基于Ling-lite-1.5 构建，总参数20.3B, MoE部分激活参数为3B。与各领域同等规模的业界领先模型相比，在各模态基准测试中展现出极具竞争力的结果：
性能对比图
Ming-lite-omni v1.5能力介绍：三大维度全面优化，效果与体验双提升！ 可控图像生成：像素级掌控，创意无限 Ming-lite-omni v1.5 重点优化了图像编辑的 场景一致性（Scene Consistency）、ID 一致性（Character / Style Consistency），在人物图像编辑时，在场景和人物ID 保持上展现出明显的优势，同时拓展了对生成式分割、深度预测、目标检测 以及 边缘轮廓生成 等感知任务的支持。
生成式图像分割 Next User Given the following instructions: little girl, pink, your monitors colors off friend p pink shirt girl; please perform referring segmentation on this image. Ming-lite-omni v1.5 User Please segment different classes in this image."><meta name=author content="inclusionAI, Ant Group"><link rel=canonical href=https://inclusionai.github.io/zh/blog/ming-lite-omni-1_5/><link crossorigin=anonymous href=/assets/css/stylesheet.fa92d8da4b04eca0dd3a888f432d2e4fabc3dec8bebb65e348f9ce26d866c08e.css integrity="sha256-+pLY2ksE7KDdOoiPQy0uT6vD3si+u2XjSPnOJthmwI4=" rel="preload stylesheet" as=style><link rel=icon href=https://inclusionai.github.io/favicon.png><link rel=apple-touch-icon href=https://inclusionai.github.io/favicon.png><link rel=manifest href=https://inclusionai.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://inclusionai.github.io/blog/ming-lite-omni-1_5/><link rel=alternate hreflang=zh href=https://inclusionai.github.io/zh/blog/ming-lite-omni-1_5/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.e9080c0a180dc80cf80d5fef7c857effb14f65c998e22134feb9896034b1b81a.js integrity="sha256-6QgMChgNyAz4DV/vfIV+/7FPZcmY4iE0/rmJYDSxuBo="></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script>
<script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Ming-lite-omni v1.5：全能模型再升级，效果与体验双优化"><meta property="og:description" content="GITHUB 🤗 Hugging Face｜ 🤖 ModelScope
概述 本次发布的 Ming-lite-omni V1.5 是对 Ming-lite-omni(Github) 全模态能力的一次全面升级， 在包括图文理解、文档理解、视频理解、语音理解和合成、图像生成和编辑等任务上均有明显提升。Ming-lite-omni V1.5 基于Ling-lite-1.5 构建，总参数20.3B, MoE部分激活参数为3B。与各领域同等规模的业界领先模型相比，在各模态基准测试中展现出极具竞争力的结果：
性能对比图
Ming-lite-omni v1.5能力介绍：三大维度全面优化，效果与体验双提升！ 可控图像生成：像素级掌控，创意无限 Ming-lite-omni v1.5 重点优化了图像编辑的 场景一致性（Scene Consistency）、ID 一致性（Character / Style Consistency），在人物图像编辑时，在场景和人物ID 保持上展现出明显的优势，同时拓展了对生成式分割、深度预测、目标检测 以及 边缘轮廓生成 等感知任务的支持。
生成式图像分割 Next User Given the following instructions: little girl, pink, your monitors colors off friend p pink shirt girl; please perform referring segmentation on this image. Ming-lite-omni v1.5 User Please segment different classes in this image."><meta property="og:type" content="article"><meta property="og:url" content="https://inclusionai.github.io/zh/blog/ming-lite-omni-1_5/"><meta property="og:image" content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-07-21T00:00:03+08:00"><meta property="article:modified_time" content="2025-07-21T00:00:03+08:00"><meta property="og:site_name" content="inclusionAI"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Ming-lite-omni v1.5：全能模型再升级，效果与体验双优化"><meta name=twitter:description content="GITHUB 🤗 Hugging Face｜ 🤖 ModelScope
概述 本次发布的 Ming-lite-omni V1.5 是对 Ming-lite-omni(Github) 全模态能力的一次全面升级， 在包括图文理解、文档理解、视频理解、语音理解和合成、图像生成和编辑等任务上均有明显提升。Ming-lite-omni V1.5 基于Ling-lite-1.5 构建，总参数20.3B, MoE部分激活参数为3B。与各领域同等规模的业界领先模型相比，在各模态基准测试中展现出极具竞争力的结果：
性能对比图
Ming-lite-omni v1.5能力介绍：三大维度全面优化，效果与体验双提升！ 可控图像生成：像素级掌控，创意无限 Ming-lite-omni v1.5 重点优化了图像编辑的 场景一致性（Scene Consistency）、ID 一致性（Character / Style Consistency），在人物图像编辑时，在场景和人物ID 保持上展现出明显的优势，同时拓展了对生成式分割、深度预测、目标检测 以及 边缘轮廓生成 等感知任务的支持。
生成式图像分割 Next User Given the following instructions: little girl, pink, your monitors colors off friend p pink shirt girl; please perform referring segmentation on this image. Ming-lite-omni v1.5 User Please segment different classes in this image."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://inclusionai.github.io/zh/blog/"},{"@type":"ListItem","position":2,"name":"Ming-lite-omni v1.5：全能模型再升级，效果与体验双优化","item":"https://inclusionai.github.io/zh/blog/ming-lite-omni-1_5/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Ming-lite-omni v1.5：全能模型再升级，效果与体验双优化","name":"Ming-lite-omni v1.5：全能模型再升级，效果与体验双优化","description":"GITHUB 🤗 Hugging Face｜ 🤖 ModelScope\n概述 本次发布的 Ming-lite-omni V1.5 是对 Ming-lite-omni(Github) 全模态能力的一次全面升级， 在包括图文理解、文档理解、视频理解、语音理解和合成、图像生成和编辑等任务上均有明显提升。Ming-lite-omni V1.5 基于Ling-lite-1.5 构建，总参数20.3B, MoE部分激活参数为3B。与各领域同等规模的业界领先模型相比，在各模态基准测试中展现出极具竞争力的结果：\n性能对比图\nMing-lite-omni v1.5能力介绍：三大维度全面优化，效果与体验双提升！ 可控图像生成：像素级掌控，创意无限 Ming-lite-omni v1.5 重点优化了图像编辑的 场景一致性（Scene Consistency）、ID 一致性（Character / Style Consistency），在人物图像编辑时，在场景和人物ID 保持上展现出明显的优势，同时拓展了对生成式分割、深度预测、目标检测 以及 边缘轮廓生成 等感知任务的支持。\n生成式图像分割 Next User Given the following instructions: little girl, pink, your monitors colors off friend p pink shirt girl; please perform referring segmentation on this image. Ming-lite-omni v1.5 User Please segment different classes in this image.","keywords":[],"articleBody":"GITHUB 🤗 Hugging Face｜ 🤖 ModelScope\n概述 本次发布的 Ming-lite-omni V1.5 是对 Ming-lite-omni(Github) 全模态能力的一次全面升级， 在包括图文理解、文档理解、视频理解、语音理解和合成、图像生成和编辑等任务上均有明显提升。Ming-lite-omni V1.5 基于Ling-lite-1.5 构建，总参数20.3B, MoE部分激活参数为3B。与各领域同等规模的业界领先模型相比，在各模态基准测试中展现出极具竞争力的结果：\n性能对比图\nMing-lite-omni v1.5能力介绍：三大维度全面优化，效果与体验双提升！ 可控图像生成：像素级掌控，创意无限 Ming-lite-omni v1.5 重点优化了图像编辑的 场景一致性（Scene Consistency）、ID 一致性（Character / Style Consistency），在人物图像编辑时，在场景和人物ID 保持上展现出明显的优势，同时拓展了对生成式分割、深度预测、目标检测 以及 边缘轮廓生成 等感知任务的支持。\n生成式图像分割 Next User Given the following instructions: little girl, pink, your monitors colors off friend p pink shirt girl; please perform referring segmentation on this image. Ming-lite-omni v1.5 User Please segment different classes in this image. Ming-lite-omni v1.5 User Please segment different instances in this image. Ming-lite-omni v1.5 深度及边缘检测\n原图 生成的深度图 生成的检测框 生成的边缘轮廓 音视频交互理解：音视频全线提升，理解力MAX！ 体验对齐优化：智能交互更懂你，沟通无障碍 User 这张图片看起来设计感很强烈，可以详细描述一下它的各个设计元素？ Ming-Lite-Omni 这张图片展示了一款高端游戏鼠标，具有现代感和科技感的设计。鼠标主体为黑色，表面光滑且具有金属质感。鼠标顶部有一个蓝色的发光标志，标志下方是鼠标滚轮和左右按键区域。鼠标侧面有蓝色的灯光装饰，增加了视觉吸引力。鼠标底部有防滑纹理设计，确保使用时的稳定性。整体设计简洁而富有未来感，适合游戏玩家使用。 Ming-Lite-Omni V1.5 这张图片展示了一款设计感强烈的游戏鼠标，具有以下设计元素： 1. 颜色和材质： - 鼠标主体为黑色，表面光滑且具有金属质感。 - 鼠标边缘和按钮部分有蓝色LED灯带，增加了科技感和视觉吸引力。 2. 形状和结构： - 鼠标整体呈流线型设计，顶部略微倾斜，便于手部自然放置。 - 鼠标侧面有明显的曲线设计，符合人体工程学，提供舒适的握持感。 3. 按钮和滚轮： - 鼠标左侧有一个滚轮，滚轮上方有蓝色LED灯带。 - 鼠标右侧有额外的按钮，这些按钮也有蓝色LED灯带，增加了功能性和美观性。 4. 品牌标识： - 鼠标底部中央有一个发光的“G”标志，这是该品牌的标志性设计元素。 5. 灯光效果： - 鼠标上的蓝色LED灯带在暗色背景下显得尤为突出，增强了科技感和未来感。 6. 纹理和细节： - 鼠标顶部有纹理设计，可能是为了增加防滑效果。 - 鼠标侧面有细长的纹理设计，增加了视觉上的层次感。 整体来看，这款鼠标的设计结合了现代科技感和人体工程学设计，既美观又实用，适合游戏玩家使用。 User 图中的书法为什么好？ Ming-Lite-Omni 这幅书法作品展示了高超的书法技巧和深厚的文化底蕴。笔法流畅自然，字形结构严谨，布局合理，体现了书法家的深厚功力和艺术修养。 Ming-Lite-Omni V1.5 这幅书法作品展示了几个显著的特点，使其成为一件优秀的书法作品： 1. 笔法精湛：书法的笔法流畅自然，线条粗细变化丰富，表现出书法家的深厚功力和熟练技巧。 2. 结构严谨：每个字的结构都经过精心设计，笔画之间的衔接自然，字与字之间保持了良好的平衡和协调。 3. 章法布局：整幅作品的章法布局合理，行距和字距均匀，给人一种整齐有序的感觉。 4. 墨色变化：墨色的浓淡变化自然，增添了作品的层次感和立体感。 5. 内容优美：书法内容是一篇优美的古文，文字内容富有哲理和文学价值，增加了作品的文化内涵。 6. 印章点缀：作品上有红色的印章，印章的使用不仅增加了作品的装饰性，还起到了点缀和平衡的作用。 这些特点共同构成了这幅书法作品的高超艺术价值，使其成为一件值得欣赏和学习的佳作。 User 图中这款手机适合给父母买吗？ Ming-Lite-Omni 这款手机外观简约时尚，适合追求简约风格的父母使用。相机配置也较为先进，适合喜欢拍照的用户。 Ming-Lite-Omni V1.5 这款手机适合给父母购买，原因如下： 1. 外观设计：手机采用简约时尚的设计，白色机身显得干净利落，符合现代审美。 2. 摄像头配置：后置摄像头设计独特，排列整齐，可能提供良好的拍照体验。 3. 品牌：荣耀（Honor）品牌在智能手机市场上有良好的口碑，提供稳定可靠的产品。 4. 功能：通常这类手机会配备大容量电池和长续航能力，适合日常使用。 5. 易用性：可能提供简洁的用户界面和易于操作的功能，适合不太熟悉复杂操作的用户。 6. 性价比：荣耀手机通常以高性价比著称，适合预算有限但希望获得良好体验的用户。 当然，具体是否适合还需考虑父母的实际需求和偏好。 User 如何使用图中软件购买机票？请列出具体操作步骤 Ming-Lite-Omni 使用图中软件购买机票的具体操作步骤如下： 1. 打开携程app。 2. 点击“机票”选项。 3. 在机票页面选择出发地、目的地、出发日期和返回日期。 4. 点击搜索按钮，查看可用的航班信息。 5. 选择合适的航班后，点击“预订”按钮。 6. 填写乘客信息并选择支付方式。 7. 确认订单信息并提交支付，完成购票。 Ming-Lite-Omni V1.5 使用携程软件购买机票的具体操作步骤如下： 1. 下载并安装携程App： - 如果您还没有安装携程App，可以在应用商店（如苹果App Store或安卓应用市场）搜索“携程旅行”并下载安装。 2. 打开携程App： - 安装完成后，打开携程App。 3. 选择“机票”选项： - 在首页的导航栏中，点击“机票”选项。 4. 输入出发地和目的地： - 在机票预订页面，输入您的出发地和目的地。 5. 选择出发日期和返回日期： - 选择您的出发日期和返回日期（如果是往返票）。 6. 选择乘客信息： - 输入乘客人数和座位类型（成人、儿童、婴儿）。 7. 选择航班： - 浏览并选择您喜欢的航班。 8. 填写乘客信息： - 输入乘客的姓名、身份证号码、联系方式等信息。 9. 选择支付方式： - 选择您喜欢的支付方式（如支付宝、微信支付、银行卡等）。 10. 确认订单并支付： - 确认订单信息无误后，点击“支付”按钮完成支付。 11. 接收电子机票： - 支付成功后，您将收到电子机票，可以通过App内的“我的订单”查看或下载。 通过以上步骤，您就可以使用携程App轻松购买机票了。 User 根据图表计算样本之间的 Δct 在哪一个引物下相差最小？ | 根据图表计算样本之间的 Δct 在 cGAS-qF+qR 引物下相差最小。（图片来源：互联网公开-舒桐科技公众号） Ming-Lite-Omni 根据图表计算样本之间的 Δct 在 cGAS-qF+qR 引物下相差最小。 Ming-Lite-Omni V1.5 在 EGFP-cGAS单克隆 引物下，样本之间的 Δct 相差最小。 计算过程： 1. 理解 Δct 的含义： Δct 是目标基因（cGAS-qF+qR 或 EGFP-cGAS）与内参基因（cTubulin）的相对表达量差值。Δct 越小，说明目标基因与内参基因的表达量差异越小。 2. 比较不同引物下的 Δct： - cGAS-qF+qR 引物： - 野生型：Δct = 8.06 - EGFP-cGAS单克隆：Δct = -0.15 - 差异：8.06 - (-0.15) = 8.21 - EGFP-cGAS单克隆 引物： - 野生型：Δct = 10.44 - EGFP-cGAS单克隆：Δct = -2.9 - 差异：10.44 - (-2.9) = 13.34 - EGFP-cGAS-qF+qR 引物： - 野生型：Δct = 21.43 - EGFP-cGAS单克隆：Δct = -13.45 - 差异：21.43 - (-13.45) = 34.88 3. 结论： 在 EGFP-cGAS单克隆 引物下，样本之间的 Δct 差异最小（Δct 差异为 13.34），说明该引物下样本之间的表达量差异最小。 总结： 在 EGFP-cGAS单克隆 引物下，样本之间的 Δct 相差最小。 模型架构升级与能力评测 Ming-lite-omni v1.5 模型架构如下，主题参考了Ming-lite-omni v1版本的结构，区别在于为了增强图像编辑人物 和 场景一致性，升级Vision head 支持参考图特征输入。\n模型架构图\n模型能力上重点在全模态理解能力、精准的视觉编辑控制 以及 用户体验 三个方面进行优化升级。\n增强的全模态理解能力 得益于数据质量优化，Ming-lite-omni v1.5 在视觉文本理解(包括图文理解、文档理解、视频理解)和语音理解等任务上均有明显提升，达到相同规模的业界领先水平。\n视觉文本理解\nTask Type Dataset Qwen2.5-VL-7B Ming-lite-omni Ming-lite-omni v1.5 OpenCompass图文 AI2D 84.36 83.1 84.91 HallusionBench 55.77 55.0 54.59 MMBench_TEST_V11 82.75 80.8 80.73 MMMU 56.56 56.3 54.33 MMStar 65.27 64.7 65.07 MMVet 71.61 71.3 73.99 MathVista 68.10 71.6 72.00 OCRBench 87.80 88.4 88.90 Average 71.5 71.4 71.8 视频理解 VideoMME(w/o subs) 65.10 63.4 67.07 VideoMME(w/ subs) 71.60 66.01 72.59 VideoMME(avg) 68.35 67.7 69.83 MVBench 69.60 67.7 69.43 LongVideoBench 56.00 56.6 59.54 OvOBench 51.10 48.48 52.17 Average 61.26 58.89 62.74 文档理解 ChartQA_test 87.24 85.1 88.84 DocVQA_test 95.57 93 93.68 TextVQA_val 85.06 82.8 82.27 OCRBench 87.8 88.4 88.9 Average 88.91 87.32 88.42 语音理解\nModel Average(Open-ended QA) AlpacaEval CommonEval SD-QA MMSU OpenBookQA IFEval AdvBench Ming-lite-omni v1.5 4.474 4.648 4.3 61.16 45.77 65.934 55.599 98.076 Ming-lite-omni 4.34 4.63 4.06 58.84 47.53 61.98 58.36 99.04 MiniCPM-o 4.285 4.42 4.15 50.72 54.78 78.02 49.25 97.69 Kimi-Audio 4.215 4.46 3.97 63.12 62.17 83.52 61.10 100.00 Qwen2.5-Omni 4.21 4.49 3.93 55.71 61.32 81.10 52.87 99.42 GLM-4-Voice 3.77 4.06 3.48 43.31 40.11 52.97 24.91 88.08 精准的视觉编辑控制 Ming-lite-omni v1.5 针对图像编辑时的人物ID及场景ID一致性问题采用以下优化策略:\n引入ID和场景一致性损失，通过增大目标图编辑区域的权重 和 参考图非编辑区域的参考强度， 同时降低参考图编辑区域的参考强度 以增强图像编辑一致性 引入生成式检测分割任务增强感知能力。通过支持生成式分割和关键点检测，提升模型对画面细节和空间关系的理解，增强编辑和生成过程的结构可控性，显著提高评测指标中与位置、结构、数量相关的得分。 引入多任务协同学习策略。通过联合训练链路实现生成与编辑的相互促进，将分割任务转化为彩色上色编辑任务，显著提升分割指标和图像局部编辑的精度与可控性，使编辑区域边缘更光滑。 基于以上优化，Ming-lite-omni v1.5在图像编辑能力明显提升，Gen-eval上达到0.87。 Gen-eval 1-Obj 2-Obj Counting Colors Position ColorAttr Avg. Ming-lite-omni 0.99 0.77 0.68 0.78 0.46 0.42 0.64 Ming-lite-omni v1.5 0.99 0.93 0.86 0.87 0.90 0.66 0.87 优化的用户体验 得益于高质量的对齐偏好数据构建， Ming-lite-omni v1.5 在图文问答的内容准确性、相关性、格式美观性以及表述流畅性方面相比领先模型展现出一定优势， Ming-lite-omni v1.5在内部对抗评测集上相比Ming-lite-omni v1 胜和率为 87.07%, 使用体验得到了明显优化。\n体验评测维度 Qwen2.5-VL-7B Ming-Omni-Lite V1.5 相关性 4.308 4.5 流畅性 4.765 4.91 内容丰富性 3.828 3.69 格式合理性 4.727 4.8 正确性 3.741 3.92 均分 4.274 4.365 开始使用 Ming-lite-omni v1.5 Ming-lite-omni v1.5的模型和代码已开源，诚邀大家试用、反馈和交流。值得期待的是，我们即将发布量化加速版本的Ming-lite-omni，该版本将不仅进一步优化全模态效果，还使Ming-lite-omni更加轻量化，同时强化多模推理和生成能力。欢迎持续关注！\nGithub: https://github.com/inclusionAI/Ming Hugging Face: https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5 ModelScope: https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5 ","wordCount":"603","inLanguage":"zh","datePublished":"2025-07-21T00:00:03+08:00","dateModified":"2025-07-21T00:00:03+08:00","author":{"@type":"Person","name":"inclusionAI, Ant Group"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://inclusionai.github.io/zh/blog/ming-lite-omni-1_5/"},"publisher":{"@type":"Organization","name":"INCLUSION AI","logo":{"@type":"ImageObject","url":"https://inclusionai.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="inclusionAI (Alt + H)"><img src=https://inclusionai.github.io/img/logo_head.png alt aria-label=logo height=50></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://github.com/inclusionAI title="Try Ling & Ming"><span>Try Ling & Ming</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero><h1 class=post-title>Ming-lite-omni v1.5：全能模型再升级，效果与体验双优化</h1><div class=post-meta><span title='2025-07-21 00:00:03 +0800 +0800'>2025年7月21日</span>&nbsp;·&nbsp;3 分钟&nbsp;·&nbsp;603 字&nbsp;·&nbsp;inclusionAI, Ant Group&nbsp;|&nbsp;语言:<ul class=i18n_list><li><a href=https://inclusionai.github.io/blog/ming-lite-omni-1_5/>English</a></li></ul></div></div></div><main class=main><article class=post-single><div class=post-content><p><a href=https://github.com/inclusionAI/Ming class="btn external" target=_blank>GITHUB</a> 🤗 <a href=https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5>Hugging Face</a>｜ 🤖 <a href=https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5>ModelScope</a></p><h1 id=概述>概述<a hidden class=anchor aria-hidden=true href=#概述>#</a></h1><p>本次发布的 Ming-lite-omni V1.5 是对 Ming-lite-omni(<a href=https://github.com/inclusionAI/Ming/tree/v1.0>Github</a>) 全模态能力的一次全面升级， 在包括图文理解、文档理解、视频理解、语音理解和合成、图像生成和编辑等任务上均有明显提升。Ming-lite-omni V1.5 基于Ling-lite-1.5 构建，总参数20.3B, MoE部分激活参数为3B。与各领域同等规模的业界领先模型相比，在各模态基准测试中展现出极具竞争力的结果：</p><div style=text-align:center;margin:auto;width:70%><img src=https://mdn.alipayobjects.com/huamei_drbxn1/afts/img/vh2qSIuScFMAAAAAYuAAAAgADkliAQFr/original alt="Image description"><p style=font-size:14px;color:gray>性能对比图</p></div><h2 id=ming-lite-omni-v15能力介绍三大维度全面优化效果与体验双提升>Ming-lite-omni v1.5能力介绍：三大维度全面优化，效果与体验双提升！<a hidden class=anchor aria-hidden=true href=#ming-lite-omni-v15能力介绍三大维度全面优化效果与体验双提升>#</a></h2><h3 id=可控图像生成像素级掌控创意无限>可控图像生成：像素级掌控，创意无限<a hidden class=anchor aria-hidden=true href=#可控图像生成像素级掌控创意无限>#</a></h3><p>Ming-lite-omni v1.5 重点优化了图像编辑的 场景一致性（Scene Consistency）、ID 一致性（Character / Style Consistency），在人物图像编辑时，在场景和人物ID 保持上展现出明显的优势，同时拓展了对生成式分割、深度预测、目标检测 以及 边缘轮廓生成 等感知任务的支持。</p><div style=text-align:center><img src=https://mdn.alipayobjects.com/huamei_aukff7/afts/img/e-mDS5UyUogAAAAAgCAAAAgAeuUHAQFr/fmt.webp alt="Image description">
<video src=https://gw.alipayobjects.com/v/huamei_aukff7/afts/video/UoqbRYQnZYEAAAAAgCAAAAgAeuUHAQFr controls></video></div><div class="full-width-container example-container"><div class=example-content><div class=title><span>生成式图像分割</span>
<a class=next-button>Next</a></div><div class="grid-layout scroll"><div class=role>User</div><div class=content><figure><img src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/gen/1752115158022-12254e69-e8c0-43fb-a725-f6730cda22d8.webp height=256px></figure>Given the following instructions: little girl, pink, your monitors colors off friend p pink shirt girl; please perform referring segmentation on this image.</div><div class=role>Ming-lite-omni v1.5</div><div class=content><figure><img src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/gen/1752115142775-3975827c-4110-445b-af53-e20201d1043a.webp height=256px></figure></div><div class=role>User</div><div class=content>Please segment different classes in this image.</div><div class=role>Ming-lite-omni v1.5</div><div class=content><figure><img src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/gen/1752116495974-7708ba3a-5909-46df-82f5-a1bfa1519d4d.webp height=256px></figure></div><div class=role>User</div><div class=content>Please segment different instances in this image.</div><div class=role>Ming-lite-omni v1.5</div><div class=content><figure><img src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/gen/1752115151406-c4780a97-5f1c-46cd-9a45-d4ef600d0897.webp height=256px></figure></div></div></div></div><p><strong>深度及边缘检测</strong></p><table><thead><tr><th style=text-align:center>原图</th><th style=text-align:center>生成的深度图</th><th style=text-align:center>生成的检测框</th><th style=text-align:center>生成的边缘轮廓</th></tr></thead><tbody><tr><td style=text-align:center><img loading=lazy src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/gen/1752466889319-bd19acce-c07d-4664-9890-41e4dff1ba8d.webp alt></td><td style=text-align:center><img loading=lazy src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/gen/1752466903529-996bcd35-a9a0-484b-98bf-2f2468f4df42.webp alt></td><td style=text-align:center><img loading=lazy src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/gen/1752466895795-1955ead5-6d94-4142-8d7b-e265352d2bcb.webp alt></td><td style=text-align:center><img loading=lazy src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/gen/1752467020122-ad8b436c-bb33-4ef0-85b8-cf45ae8c9be1.webp alt></td></tr></tbody></table><h3 id=音视频交互理解音视频全线提升理解力max>音视频交互理解：音视频全线提升，理解力MAX！<a hidden class=anchor aria-hidden=true href=#音视频交互理解音视频全线提升理解力max>#</a></h3><p><video src=https://gw.alipayobjects.com/v/huamei_drbxn1/afts/video/TptZRJDixVUAAAAAhqAAAAgADkliAQFr width=540px height=800px controls></video></p><h3 id=体验对齐优化智能交互更懂你沟通无障碍>体验对齐优化：智能交互更懂你，沟通无障碍<a hidden class=anchor aria-hidden=true href=#体验对齐优化智能交互更懂你沟通无障碍>#</a></h3><div class="full-width-container example-container"><div class=example-content><div class="grid-layout scroll"><div class=role>User</div><div class=content><figure><img src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/0715/2.jpg height=256px></figure>这张图片看起来设计感很强烈，可以详细描述一下它的各个设计元素？</div><div class=role>Ming-Lite-Omni</div><div class=content>这张图片展示了一款高端游戏鼠标，具有现代感和科技感的设计。鼠标主体为黑色，表面光滑且具有金属质感。鼠标顶部有一个蓝色的发光标志，标志下方是鼠标滚轮和左右按键区域。鼠标侧面有蓝色的灯光装饰，增加了视觉吸引力。鼠标底部有防滑纹理设计，确保使用时的稳定性。整体设计简洁而富有未来感，适合游戏玩家使用。</div><div class=role>Ming-Lite-Omni V1.5</div><div class=content>这张图片展示了一款设计感强烈的游戏鼠标，具有以下设计元素：<br>1. <strong>颜色和材质</strong>： - 鼠标主体为黑色，表面光滑且具有金属质感。 - 鼠标边缘和按钮部分有蓝色LED灯带，增加了科技感和视觉吸引力。<br>2. <strong>形状和结构</strong>： - 鼠标整体呈流线型设计，顶部略微倾斜，便于手部自然放置。 - 鼠标侧面有明显的曲线设计，符合人体工程学，提供舒适的握持感。<br>3. <strong>按钮和滚轮</strong>： - 鼠标左侧有一个滚轮，滚轮上方有蓝色LED灯带。 - 鼠标右侧有额外的按钮，这些按钮也有蓝色LED灯带，增加了功能性和美观性。<br>4. <strong>品牌标识</strong>： - 鼠标底部中央有一个发光的“G”标志，这是该品牌的标志性设计元素。<br>5. <strong>灯光效果</strong>： - 鼠标上的蓝色LED灯带在暗色背景下显得尤为突出，增强了科技感和未来感。<br>6. <strong>纹理和细节</strong>： - 鼠标顶部有纹理设计，可能是为了增加防滑效果。 - 鼠标侧面有细长的纹理设计，增加了视觉上的层次感。<br>整体来看，这款鼠标的设计结合了现代科技感和人体工程学设计，既美观又实用，适合游戏玩家使用。</div><div class=role>User</div><div class=content><figure><img src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/0715/3.webp height=256px></figure>图中的书法为什么好？</div><div class=role>Ming-Lite-Omni</div><div class=content>这幅书法作品展示了高超的书法技巧和深厚的文化底蕴。笔法流畅自然，字形结构严谨，布局合理，体现了书法家的深厚功力和艺术修养。</div><div class=role>Ming-Lite-Omni V1.5</div><div class=content>这幅书法作品展示了几个显著的特点，使其成为一件优秀的书法作品：<br>1. <strong>笔法精湛</strong>：书法的笔法流畅自然，线条粗细变化丰富，表现出书法家的深厚功力和熟练技巧。<br>2. <strong>结构严谨</strong>：每个字的结构都经过精心设计，笔画之间的衔接自然，字与字之间保持了良好的平衡和协调。<br>3. <strong>章法布局</strong>：整幅作品的章法布局合理，行距和字距均匀，给人一种整齐有序的感觉。<br>4. <strong>墨色变化</strong>：墨色的浓淡变化自然，增添了作品的层次感和立体感。<br>5. <strong>内容优美</strong>：书法内容是一篇优美的古文，文字内容富有哲理和文学价值，增加了作品的文化内涵。<br>6. <strong>印章点缀</strong>：作品上有红色的印章，印章的使用不仅增加了作品的装饰性，还起到了点缀和平衡的作用。<br>这些特点共同构成了这幅书法作品的高超艺术价值，使其成为一件值得欣赏和学习的佳作。</div><div class=role>User</div><div class=content><figure><img src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/0715/4.webp height=256px></figure>图中这款手机适合给父母买吗？</div><div class=role>Ming-Lite-Omni</div><div class=content>这款手机外观简约时尚，适合追求简约风格的父母使用。相机配置也较为先进，适合喜欢拍照的用户。</div><div class=role>Ming-Lite-Omni V1.5</div><div class=content>这款手机适合给父母购买，原因如下：<br>1. <strong>外观设计</strong>：手机采用简约时尚的设计，白色机身显得干净利落，符合现代审美。<br>2. <strong>摄像头配置</strong>：后置摄像头设计独特，排列整齐，可能提供良好的拍照体验。<br>3. <strong>品牌</strong>：荣耀（Honor）品牌在智能手机市场上有良好的口碑，提供稳定可靠的产品。<br>4. <strong>功能</strong>：通常这类手机会配备大容量电池和长续航能力，适合日常使用。<br>5. <strong>易用性</strong>：可能提供简洁的用户界面和易于操作的功能，适合不太熟悉复杂操作的用户。<br>6. <strong>性价比</strong>：荣耀手机通常以高性价比著称，适合预算有限但希望获得良好体验的用户。<br>当然，具体是否适合还需考虑父母的实际需求和偏好。</div><div class=role>User</div><div class=content><figure><img src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/0715/6.webp height=256px></figure>如何使用图中软件购买机票？请列出具体操作步骤</div><div class=role>Ming-Lite-Omni</div><div class=content>使用图中软件购买机票的具体操作步骤如下：<br>1. 打开携程app。 2. 点击“机票”选项。 3. 在机票页面选择出发地、目的地、出发日期和返回日期。 4. 点击搜索按钮，查看可用的航班信息。 5. 选择合适的航班后，点击“预订”按钮。 6. 填写乘客信息并选择支付方式。 7. 确认订单信息并提交支付，完成购票。</div><div class=role>Ming-Lite-Omni V1.5</div><div class=content>使用携程软件购买机票的具体操作步骤如下：<br>1. <strong>下载并安装携程App</strong>： - 如果您还没有安装携程App，可以在应用商店（如苹果App Store或安卓应用市场）搜索“携程旅行”并下载安装。<br>2. <strong>打开携程App</strong>： - 安装完成后，打开携程App。<br>3. <strong>选择“机票”选项</strong>： - 在首页的导航栏中，点击“机票”选项。<br>4. <strong>输入出发地和目的地</strong>： - 在机票预订页面，输入您的出发地和目的地。<br>5. <strong>选择出发日期和返回日期</strong>： - 选择您的出发日期和返回日期（如果是往返票）。<br>6. <strong>选择乘客信息</strong>： - 输入乘客人数和座位类型（成人、儿童、婴儿）。<br>7. <strong>选择航班</strong>： - 浏览并选择您喜欢的航班。<br>8. <strong>填写乘客信息</strong>： - 输入乘客的姓名、身份证号码、联系方式等信息。<br>9. <strong>选择支付方式</strong>： - 选择您喜欢的支付方式（如支付宝、微信支付、银行卡等）。<br>10. <strong>确认订单并支付</strong>： - 确认订单信息无误后，点击“支付”按钮完成支付。<br>11. <strong>接收电子机票</strong>： - 支付成功后，您将收到电子机票，可以通过App内的“我的订单”查看或下载。<br>通过以上步骤，您就可以使用携程App轻松购买机票了。</div><div class=role>User</div><div class=content><figure><img src=https://gcore.jsdelivr.net/gh/biao-gong/static@main/0715/7.webp height=128px></figure>根据图表计算样本之间的 Δct 在哪一个引物下相差最小？ | 根据图表计算样本之间的 Δct 在 cGAS-qF+qR 引物下相差最小。（图片来源：互联网公开-舒桐科技公众号）</div><div class=role>Ming-Lite-Omni</div><div class=content>根据图表计算样本之间的 Δct 在 cGAS-qF+qR 引物下相差最小。</div><div class=role>Ming-Lite-Omni V1.5</div><div class=content>在 <strong>EGFP-cGAS单克隆</strong> 引物下，样本之间的 Δct 相差最小。<br><br><strong>计算过程：</strong><br><strong>1. 理解 Δct 的含义：</strong> Δct 是目标基因（cGAS-qF+qR 或 EGFP-cGAS）与内参基因（cTubulin）的相对表达量差值。Δct 越小，说明目标基因与内参基因的表达量差异越小。<br><strong>2. 比较不同引物下的 Δct：</strong><br>- <strong>cGAS-qF+qR 引物：</strong> - 野生型：Δct = 8.06 - EGFP-cGAS单克隆：Δct = -0.15 - 差异：8.06 - (-0.15) = 8.21<br>- <strong>EGFP-cGAS单克隆 引物：</strong> - 野生型：Δct = 10.44 - EGFP-cGAS单克隆：Δct = -2.9 - 差异：10.44 - (-2.9) = 13.34<br>- <strong>EGFP-cGAS-qF+qR 引物：</strong> - 野生型：Δct = 21.43 - EGFP-cGAS单克隆：Δct = -13.45 - 差异：21.43 - (-13.45) = 34.88<br><strong>3. 结论：</strong> 在 <strong>EGFP-cGAS单克隆</strong> 引物下，样本之间的 Δct 差异最小（Δct 差异为 13.34），说明该引物下样本之间的表达量差异最小。<br><br><strong>总结：</strong> 在 <strong>EGFP-cGAS单克隆</strong> 引物下，样本之间的 Δct 相差最小。</div></div></div></div><h1 id=模型架构升级与能力评测>模型架构升级与能力评测<a hidden class=anchor aria-hidden=true href=#模型架构升级与能力评测>#</a></h1><p>Ming-lite-omni v1.5 模型架构如下，主题参考了Ming-lite-omni v1版本的结构，区别在于为了增强图像编辑人物 和 场景一致性，升级Vision head 支持参考图特征输入。</p><div style=text-align:center><img src=https://mdn.alipayobjects.com/huamei_aukff7/afts/img/A_LZTJcsc3EAAAAAXuAAAAgAeuUHAQFr/fmt.webp alt="Image description"><p style=font-size:14px;color:gray>模型架构图</p></div><p>模型能力上重点在全模态理解能力、精准的视觉编辑控制 以及 用户体验 三个方面进行优化升级。</p><h2 id=增强的全模态理解能力>增强的全模态理解能力<a hidden class=anchor aria-hidden=true href=#增强的全模态理解能力>#</a></h2><p>得益于数据质量优化，Ming-lite-omni v1.5 在视觉文本理解(包括图文理解、文档理解、视频理解)和语音理解等任务上均有明显提升，达到相同规模的业界领先水平。</p><p><strong>视觉文本理解</strong></p><table><thead><tr><th>Task Type</th><th>Dataset</th><th>Qwen2.5-VL-7B</th><th>Ming-lite-omni</th><th>Ming-lite-omni v1.5</th></tr></thead><tbody><tr><td>OpenCompass图文</td><td>AI2D</td><td>84.36</td><td>83.1</td><td><strong>84.91</strong></td></tr><tr><td></td><td>HallusionBench</td><td><strong>55.77</strong></td><td>55.0</td><td>54.59</td></tr><tr><td></td><td>MMBench_TEST_V11</td><td><strong>82.75</strong></td><td>80.8</td><td>80.73</td></tr><tr><td></td><td>MMMU</td><td><strong>56.56</strong></td><td>56.3</td><td>54.33</td></tr><tr><td></td><td>MMStar</td><td><strong>65.27</strong></td><td>64.7</td><td>65.07</td></tr><tr><td></td><td>MMVet</td><td>71.61</td><td>71.3</td><td><strong>73.99</strong></td></tr><tr><td></td><td>MathVista</td><td>68.10</td><td>71.6</td><td><strong>72.00</strong></td></tr><tr><td></td><td>OCRBench</td><td>87.80</td><td>88.4</td><td><strong>88.90</strong></td></tr><tr><td></td><td><strong>Average</strong></td><td>71.5</td><td>71.4</td><td><strong>71.8</strong></td></tr><tr><td>视频理解</td><td>VideoMME(w/o subs)</td><td>65.10</td><td>63.4</td><td><strong>67.07</strong></td></tr><tr><td></td><td>VideoMME(w/ subs)</td><td>71.60</td><td>66.01</td><td><strong>72.59</strong></td></tr><tr><td></td><td>VideoMME(avg)</td><td>68.35</td><td>67.7</td><td><strong>69.83</strong></td></tr><tr><td></td><td>MVBench</td><td><strong>69.60</strong></td><td>67.7</td><td>69.43</td></tr><tr><td></td><td>LongVideoBench</td><td>56.00</td><td>56.6</td><td><strong>59.54</strong></td></tr><tr><td></td><td>OvOBench</td><td>51.10</td><td>48.48</td><td><strong>52.17</strong></td></tr><tr><td></td><td><strong>Average</strong></td><td>61.26</td><td>58.89</td><td><strong>62.74</strong></td></tr><tr><td>文档理解</td><td>ChartQA_test</td><td>87.24</td><td>85.1</td><td><strong>88.84</strong></td></tr><tr><td></td><td>DocVQA_test</td><td><strong>95.57</strong></td><td>93</td><td>93.68</td></tr><tr><td></td><td>TextVQA_val</td><td><strong>85.06</strong></td><td>82.8</td><td>82.27</td></tr><tr><td></td><td>OCRBench</td><td>87.8</td><td>88.4</td><td><strong>88.9</strong></td></tr><tr><td></td><td><strong>Average</strong></td><td><strong>88.91</strong></td><td>87.32</td><td>88.42</td></tr></tbody></table><p><strong>语音理解</strong></p><table><thead><tr><th>Model</th><th>Average(Open-ended QA)</th><th>AlpacaEval</th><th>CommonEval</th><th>SD-QA</th><th>MMSU</th><th>OpenBookQA</th><th>IFEval</th><th>AdvBench</th></tr></thead><tbody><tr><td>Ming-lite-omni v1.5</td><td>4.474</td><td>4.648</td><td>4.3</td><td>61.16</td><td>45.77</td><td>65.934</td><td>55.599</td><td>98.076</td></tr><tr><td>Ming-lite-omni</td><td>4.34</td><td>4.63</td><td>4.06</td><td>58.84</td><td>47.53</td><td>61.98</td><td>58.36</td><td>99.04</td></tr><tr><td>MiniCPM-o</td><td>4.285</td><td>4.42</td><td>4.15</td><td>50.72</td><td>54.78</td><td>78.02</td><td>49.25</td><td>97.69</td></tr><tr><td>Kimi-Audio</td><td>4.215</td><td>4.46</td><td>3.97</td><td>63.12</td><td>62.17</td><td>83.52</td><td>61.10</td><td>100.00</td></tr><tr><td>Qwen2.5-Omni</td><td>4.21</td><td>4.49</td><td>3.93</td><td>55.71</td><td>61.32</td><td>81.10</td><td>52.87</td><td>99.42</td></tr><tr><td>GLM-4-Voice</td><td>3.77</td><td>4.06</td><td>3.48</td><td>43.31</td><td>40.11</td><td>52.97</td><td>24.91</td><td>88.08</td></tr></tbody></table><h2 id=精准的视觉编辑控制>精准的视觉编辑控制<a hidden class=anchor aria-hidden=true href=#精准的视觉编辑控制>#</a></h2><p>Ming-lite-omni v1.5 针对图像编辑时的人物ID及场景ID一致性问题采用以下优化策略:</p><ol><li>引入ID和场景一致性损失，通过增大目标图编辑区域的权重 和 参考图非编辑区域的参考强度， 同时降低参考图编辑区域的参考强度 以增强图像编辑一致性</li><li>引入生成式检测分割任务增强感知能力。通过支持生成式分割和关键点检测，提升模型对画面细节和空间关系的理解，增强编辑和生成过程的结构可控性，显著提高评测指标中与位置、结构、数量相关的得分。</li><li>引入多任务协同学习策略。通过联合训练链路实现生成与编辑的相互促进，将分割任务转化为彩色上色编辑任务，显著提升分割指标和图像局部编辑的精度与可控性，使编辑区域边缘更光滑。
基于以上优化，Ming-lite-omni v1.5在图像编辑能力明显提升，Gen-eval上达到0.87。</li></ol><table><thead><tr><th>Gen-eval</th><th>1-Obj</th><th>2-Obj</th><th>Counting</th><th>Colors</th><th>Position</th><th>ColorAttr</th><th>Avg.</th></tr></thead><tbody><tr><td>Ming-lite-omni</td><td>0.99</td><td>0.77</td><td>0.68</td><td>0.78</td><td>0.46</td><td>0.42</td><td>0.64</td></tr><tr><td>Ming-lite-omni v1.5</td><td>0.99</td><td>0.93</td><td>0.86</td><td>0.87</td><td>0.90</td><td>0.66</td><td>0.87</td></tr></tbody></table><h2 id=优化的用户体验>优化的用户体验<a hidden class=anchor aria-hidden=true href=#优化的用户体验>#</a></h2><p>得益于高质量的对齐偏好数据构建， Ming-lite-omni v1.5 在图文问答的内容准确性、相关性、格式美观性以及表述流畅性方面相比领先模型展现出一定优势， Ming-lite-omni v1.5在内部对抗评测集上相比Ming-lite-omni v1 胜和率为 87.07%, 使用体验得到了明显优化。</p><table><thead><tr><th>体验评测维度</th><th>Qwen2.5-VL-7B</th><th>Ming-Omni-Lite V1.5</th></tr></thead><tbody><tr><td>相关性</td><td>4.308</td><td>4.5</td></tr><tr><td>流畅性</td><td>4.765</td><td>4.91</td></tr><tr><td>内容丰富性</td><td>3.828</td><td>3.69</td></tr><tr><td>格式合理性</td><td>4.727</td><td>4.8</td></tr><tr><td>正确性</td><td>3.741</td><td>3.92</td></tr><tr><td><strong>均分</strong></td><td>4.274</td><td><strong>4.365</strong></td></tr></tbody></table><h2 id=开始使用-ming-lite-omni-v15>开始使用 Ming-lite-omni v1.5<a hidden class=anchor aria-hidden=true href=#开始使用-ming-lite-omni-v15>#</a></h2><p>Ming-lite-omni v1.5的模型和代码已开源，诚邀大家试用、反馈和交流。值得期待的是，我们即将发布量化加速版本的Ming-lite-omni，该版本将不仅进一步优化全模态效果，还使Ming-lite-omni更加轻量化，同时强化多模推理和生成能力。欢迎持续关注！</p><ul><li>Github: <a href=https://github.com/inclusionAI/Ming>https://github.com/inclusionAI/Ming</a></li><li>Hugging Face: <a href=https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5>https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5</a></li><li>ModelScope: <a href=https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5>https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5</a></li></ul></div></article></main><footer class=footer><span>&copy; 2025 <a href=https://inclusionai.github.io/zh/>INCLUSION AI</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="复制";function s(){t.innerHTML="已复制！",setTimeout(()=>{t.innerHTML="复制"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>