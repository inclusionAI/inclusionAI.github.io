<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Ming-Omniï¼šä¸€ä¸ªç”¨äºæ„ŸçŸ¥ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹ | INCLUSION AI</title><meta name=keywords content><meta name=description content="
GITHUB ğŸ“‘ Technical Reportï½œğŸ“–Project Page ï½œğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope
ä»‹ç»
Ming-lite-omni æ˜¯ Ming-omni çš„è½»é‡ç‰ˆï¼Œæºè‡ª Ling-liteï¼Œæ‹¥æœ‰ 28 äº¿æ¿€æ´»å‚æ•°ã€‚Ming-lite-omni æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘ï¼Œå¹¶åœ¨è¯­éŸ³å’Œå›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè¾ƒå¼ºèƒ½åŠ›ã€‚Ming-lite-omni ä½¿ç”¨ä¸“ç”¨ç¼–ç å™¨ä»ä¸åŒæ¨¡æ€æå– tokenï¼Œç„¶åç”± Ling å¤„ç†ï¼ŒLing æ˜¯ä¸€ä¸ª MoE æ¶æ„ï¼Œé…å¤‡äº†æ–°æå‡ºçš„æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨ã€‚è¯¥è®¾è®¡ä½¿å•ä¸€æ¨¡å‹èƒ½åœ¨ç»Ÿä¸€æ¡†æ¶å†…é«˜æ•ˆå¤„ç†å’Œèåˆå¤šæ¨¡æ€è¾“å…¥ï¼Œä»è€Œæ”¯æŒå¤šæ ·åŒ–ä»»åŠ¡ï¼Œæ— éœ€ä½¿ç”¨å¤šä¸ªæ¨¡å‹ã€ä»»åŠ¡ä¸“ç”¨å¾®è°ƒæˆ–ç»“æ„æ”¹åŠ¨ã€‚é‡è¦çš„æ˜¯ï¼ŒMing-lite-omni è¶…è¶Šä¼ ç»Ÿå¤šæ¨¡æ€æ¨¡å‹ï¼Œæ”¯æŒéŸ³é¢‘å’Œå›¾åƒç”Ÿæˆã€‚é€šè¿‡é›†æˆå…ˆè¿›çš„éŸ³é¢‘è§£ç å™¨å®ç°è‡ªç„¶è¯­éŸ³ï¼Œä»¥åŠåˆ©ç”¨ Ming-Lite-Uni å®ç°é«˜è´¨é‡å›¾åƒç”Ÿæˆï¼Œæ¨¡å‹è¿˜èƒ½è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥èŠå¤©ã€æ–‡æœ¬è½¬è¯­éŸ³åŠå¤šåŠŸèƒ½å›¾åƒç¼–è¾‘ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMing-lite-omni åœ¨æ‰€æœ‰æ¨¡æ€ä¸Šçš„ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆæ–¹é¢æä¾›äº†å¼ºå¤§è§£å†³æ–¹æ¡ˆã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMing-lite-omni æ˜¯æˆ‘ä»¬æ‰€çŸ¥é¦–ä¸ªæ¨¡æ€æ”¯æŒä¸ GPT-4o åŒ¹é…çš„å¼€æºæ¨¡å‹ï¼Œä¸”æˆ‘ä»¬å‘å¸ƒäº†å…¨éƒ¨ä»£ç å’Œæ¨¡å‹æƒé‡ï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºè¿›ä¸€æ­¥ç ”ç©¶å’Œå‘å±•ã€‚
ğŸ“Œ æ›´æ–°

[2025.06.12] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚
[2025.05.28] ğŸ”¥ Ming-lite-omni å®˜æ–¹ç‰ˆæœ¬å‘å¸ƒï¼Œæ€§èƒ½æ›´ä½³å¹¶æ”¯æŒå›¾åƒç”Ÿæˆã€‚
[2025.05.04] ğŸ”¥ å‘å¸ƒ Ming-lite-omni æµ‹è¯•ç‰ˆæœ¬ï¼šMing-lite-omni-Previewã€‚

ä¸»è¦ç‰¹æ€§


ç»Ÿä¸€å…¨æ¨¡æ€æ„ŸçŸ¥ï¼šMing-lite-omni åŸºäº Lingï¼ˆä¸€ä¸ª MoE æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹ï¼‰ï¼Œé€šè¿‡æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨è§£å†³ä»»åŠ¡å†²çªï¼Œç¡®ä¿æ¥è‡ªä¸åŒæ¨¡æ€çš„ token çš„è¿è´¯èåˆã€‚


ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆï¼šMing-lite-omni å®ç°ç»Ÿä¸€çš„ç†è§£ä¸ç”Ÿæˆï¼Œä½¿æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­èƒ½è§£è¯»å¤šæ¨¡æ€æŒ‡ä»¤å’Œç”¨æˆ·æ„å›¾ï¼Œä»è€Œæå‡ç”Ÿæˆè´¨é‡å¹¶å¢å¼ºå¤šä»»åŠ¡ä½¿ç”¨ä¾¿åˆ©æ€§ã€‚


åˆ›æ–°çš„ç”Ÿæˆèƒ½åŠ›ï¼šMing-lite-omni èƒ½æ„ŸçŸ¥æ‰€æœ‰æ¨¡æ€ï¼ŒåŒæ—¶ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬ã€å®æ—¶è¯­éŸ³å’Œç”ŸåŠ¨å›¾åƒï¼Œå±•ç°å‡ºå“è¶Šçš„è·¨æ¨¡æ€è¡¨ç°ï¼Œæ¶µç›–å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’å’Œå›¾åƒç”Ÿæˆç­‰å¤šæ ·ä»»åŠ¡ã€‚


è¯„æµ‹
Ming-lite-omni åœ¨å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’åŠå›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å‡å±•ç°å‡ºä¼˜å¼‚çš„è·¨æ¨¡æ€æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å›¾åƒæ„ŸçŸ¥ä»»åŠ¡ä¸­ï¼ŒMing-lite-omni ä»…æ¿€æ´» 28 äº¿å‚æ•°ï¼Œæ€§èƒ½å·²å¯ä¸ Qwen2.5-VL-7B ç›¸åª²ç¾ã€‚å®ƒåœ¨ç«¯åˆ°ç«¯è¯­éŸ³ç†è§£å’ŒæŒ‡ä»¤æ‰§è¡Œä¸Šè¡¨ç°ä¼˜äº Qwen2.5-Omni å’Œ Kimi-Audioã€‚åŒæ—¶æ”¯æŒåŸç”Ÿåˆ†è¾¨ç‡çš„å›¾åƒç”Ÿæˆã€ç¼–è¾‘åŠé£æ ¼è¿ç§»ï¼ŒGenEval å¾—åˆ†è¾¾ 0.64ï¼Œä¼˜äºä¸»æµæ¨¡å‹å¦‚ SDXLã€‚åœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒMing-lite-omni è¾¾åˆ° 4.85ï¼Œåˆ·æ–°äº†ç°æœ‰æ–¹æ³•çš„æœ€ä½³æ°´å¹³ã€‚"><meta name=author content="inclusionAI, Ant Group"><link rel=canonical href=https://inclusionai.github.io/zh/blog/ming-omni/><link crossorigin=anonymous href=/assets/css/stylesheet.e43d02cb5d47286722d4c0b3c445053495d7038e5d2de897387de22eaa50244e.css integrity="sha256-5D0Cy11HKGci1MCzxEUFNJXXA45dLeiXOH3iLqpQJE4=" rel="preload stylesheet" as=style><link rel=icon href=https://inclusionai.github.io/favicon.png><link rel=apple-touch-icon href=https://inclusionai.github.io/favicon.png><link rel=manifest href=https://inclusionai.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://inclusionai.github.io/blog/ming-omni/><link rel=alternate hreflang=zh href=https://inclusionai.github.io/zh/blog/ming-omni/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.e9080c0a180dc80cf80d5fef7c857effb14f65c998e22134feb9896034b1b81a.js integrity="sha256-6QgMChgNyAz4DV/vfIV+/7FPZcmY4iE0/rmJYDSxuBo="></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90")}</script><meta property="og:title" content="Ming-Omniï¼šä¸€ä¸ªç”¨äºæ„ŸçŸ¥ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹"><meta property="og:description" content="
GITHUB ğŸ“‘ Technical Reportï½œğŸ“–Project Page ï½œğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope
ä»‹ç»
Ming-lite-omni æ˜¯ Ming-omni çš„è½»é‡ç‰ˆï¼Œæºè‡ª Ling-liteï¼Œæ‹¥æœ‰ 28 äº¿æ¿€æ´»å‚æ•°ã€‚Ming-lite-omni æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘ï¼Œå¹¶åœ¨è¯­éŸ³å’Œå›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè¾ƒå¼ºèƒ½åŠ›ã€‚Ming-lite-omni ä½¿ç”¨ä¸“ç”¨ç¼–ç å™¨ä»ä¸åŒæ¨¡æ€æå– tokenï¼Œç„¶åç”± Ling å¤„ç†ï¼ŒLing æ˜¯ä¸€ä¸ª MoE æ¶æ„ï¼Œé…å¤‡äº†æ–°æå‡ºçš„æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨ã€‚è¯¥è®¾è®¡ä½¿å•ä¸€æ¨¡å‹èƒ½åœ¨ç»Ÿä¸€æ¡†æ¶å†…é«˜æ•ˆå¤„ç†å’Œèåˆå¤šæ¨¡æ€è¾“å…¥ï¼Œä»è€Œæ”¯æŒå¤šæ ·åŒ–ä»»åŠ¡ï¼Œæ— éœ€ä½¿ç”¨å¤šä¸ªæ¨¡å‹ã€ä»»åŠ¡ä¸“ç”¨å¾®è°ƒæˆ–ç»“æ„æ”¹åŠ¨ã€‚é‡è¦çš„æ˜¯ï¼ŒMing-lite-omni è¶…è¶Šä¼ ç»Ÿå¤šæ¨¡æ€æ¨¡å‹ï¼Œæ”¯æŒéŸ³é¢‘å’Œå›¾åƒç”Ÿæˆã€‚é€šè¿‡é›†æˆå…ˆè¿›çš„éŸ³é¢‘è§£ç å™¨å®ç°è‡ªç„¶è¯­éŸ³ï¼Œä»¥åŠåˆ©ç”¨ Ming-Lite-Uni å®ç°é«˜è´¨é‡å›¾åƒç”Ÿæˆï¼Œæ¨¡å‹è¿˜èƒ½è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥èŠå¤©ã€æ–‡æœ¬è½¬è¯­éŸ³åŠå¤šåŠŸèƒ½å›¾åƒç¼–è¾‘ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMing-lite-omni åœ¨æ‰€æœ‰æ¨¡æ€ä¸Šçš„ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆæ–¹é¢æä¾›äº†å¼ºå¤§è§£å†³æ–¹æ¡ˆã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMing-lite-omni æ˜¯æˆ‘ä»¬æ‰€çŸ¥é¦–ä¸ªæ¨¡æ€æ”¯æŒä¸ GPT-4o åŒ¹é…çš„å¼€æºæ¨¡å‹ï¼Œä¸”æˆ‘ä»¬å‘å¸ƒäº†å…¨éƒ¨ä»£ç å’Œæ¨¡å‹æƒé‡ï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºè¿›ä¸€æ­¥ç ”ç©¶å’Œå‘å±•ã€‚
ğŸ“Œ æ›´æ–°

[2025.06.12] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚
[2025.05.28] ğŸ”¥ Ming-lite-omni å®˜æ–¹ç‰ˆæœ¬å‘å¸ƒï¼Œæ€§èƒ½æ›´ä½³å¹¶æ”¯æŒå›¾åƒç”Ÿæˆã€‚
[2025.05.04] ğŸ”¥ å‘å¸ƒ Ming-lite-omni æµ‹è¯•ç‰ˆæœ¬ï¼šMing-lite-omni-Previewã€‚

ä¸»è¦ç‰¹æ€§


ç»Ÿä¸€å…¨æ¨¡æ€æ„ŸçŸ¥ï¼šMing-lite-omni åŸºäº Lingï¼ˆä¸€ä¸ª MoE æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹ï¼‰ï¼Œé€šè¿‡æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨è§£å†³ä»»åŠ¡å†²çªï¼Œç¡®ä¿æ¥è‡ªä¸åŒæ¨¡æ€çš„ token çš„è¿è´¯èåˆã€‚


ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆï¼šMing-lite-omni å®ç°ç»Ÿä¸€çš„ç†è§£ä¸ç”Ÿæˆï¼Œä½¿æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­èƒ½è§£è¯»å¤šæ¨¡æ€æŒ‡ä»¤å’Œç”¨æˆ·æ„å›¾ï¼Œä»è€Œæå‡ç”Ÿæˆè´¨é‡å¹¶å¢å¼ºå¤šä»»åŠ¡ä½¿ç”¨ä¾¿åˆ©æ€§ã€‚


åˆ›æ–°çš„ç”Ÿæˆèƒ½åŠ›ï¼šMing-lite-omni èƒ½æ„ŸçŸ¥æ‰€æœ‰æ¨¡æ€ï¼ŒåŒæ—¶ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬ã€å®æ—¶è¯­éŸ³å’Œç”ŸåŠ¨å›¾åƒï¼Œå±•ç°å‡ºå“è¶Šçš„è·¨æ¨¡æ€è¡¨ç°ï¼Œæ¶µç›–å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’å’Œå›¾åƒç”Ÿæˆç­‰å¤šæ ·ä»»åŠ¡ã€‚


è¯„æµ‹
Ming-lite-omni åœ¨å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’åŠå›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å‡å±•ç°å‡ºä¼˜å¼‚çš„è·¨æ¨¡æ€æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å›¾åƒæ„ŸçŸ¥ä»»åŠ¡ä¸­ï¼ŒMing-lite-omni ä»…æ¿€æ´» 28 äº¿å‚æ•°ï¼Œæ€§èƒ½å·²å¯ä¸ Qwen2.5-VL-7B ç›¸åª²ç¾ã€‚å®ƒåœ¨ç«¯åˆ°ç«¯è¯­éŸ³ç†è§£å’ŒæŒ‡ä»¤æ‰§è¡Œä¸Šè¡¨ç°ä¼˜äº Qwen2.5-Omni å’Œ Kimi-Audioã€‚åŒæ—¶æ”¯æŒåŸç”Ÿåˆ†è¾¨ç‡çš„å›¾åƒç”Ÿæˆã€ç¼–è¾‘åŠé£æ ¼è¿ç§»ï¼ŒGenEval å¾—åˆ†è¾¾ 0.64ï¼Œä¼˜äºä¸»æµæ¨¡å‹å¦‚ SDXLã€‚åœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒMing-lite-omni è¾¾åˆ° 4.85ï¼Œåˆ·æ–°äº†ç°æœ‰æ–¹æ³•çš„æœ€ä½³æ°´å¹³ã€‚"><meta property="og:type" content="article"><meta property="og:url" content="https://inclusionai.github.io/zh/blog/ming-omni/"><meta property="og:image" content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-06-11T00:00:03+08:00"><meta property="article:modified_time" content="2025-06-11T00:00:03+08:00"><meta property="og:site_name" content="inclusionAI"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Ming-Omniï¼šä¸€ä¸ªç”¨äºæ„ŸçŸ¥ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹"><meta name=twitter:description content="
GITHUB ğŸ“‘ Technical Reportï½œğŸ“–Project Page ï½œğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope
ä»‹ç»
Ming-lite-omni æ˜¯ Ming-omni çš„è½»é‡ç‰ˆï¼Œæºè‡ª Ling-liteï¼Œæ‹¥æœ‰ 28 äº¿æ¿€æ´»å‚æ•°ã€‚Ming-lite-omni æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘ï¼Œå¹¶åœ¨è¯­éŸ³å’Œå›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè¾ƒå¼ºèƒ½åŠ›ã€‚Ming-lite-omni ä½¿ç”¨ä¸“ç”¨ç¼–ç å™¨ä»ä¸åŒæ¨¡æ€æå– tokenï¼Œç„¶åç”± Ling å¤„ç†ï¼ŒLing æ˜¯ä¸€ä¸ª MoE æ¶æ„ï¼Œé…å¤‡äº†æ–°æå‡ºçš„æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨ã€‚è¯¥è®¾è®¡ä½¿å•ä¸€æ¨¡å‹èƒ½åœ¨ç»Ÿä¸€æ¡†æ¶å†…é«˜æ•ˆå¤„ç†å’Œèåˆå¤šæ¨¡æ€è¾“å…¥ï¼Œä»è€Œæ”¯æŒå¤šæ ·åŒ–ä»»åŠ¡ï¼Œæ— éœ€ä½¿ç”¨å¤šä¸ªæ¨¡å‹ã€ä»»åŠ¡ä¸“ç”¨å¾®è°ƒæˆ–ç»“æ„æ”¹åŠ¨ã€‚é‡è¦çš„æ˜¯ï¼ŒMing-lite-omni è¶…è¶Šä¼ ç»Ÿå¤šæ¨¡æ€æ¨¡å‹ï¼Œæ”¯æŒéŸ³é¢‘å’Œå›¾åƒç”Ÿæˆã€‚é€šè¿‡é›†æˆå…ˆè¿›çš„éŸ³é¢‘è§£ç å™¨å®ç°è‡ªç„¶è¯­éŸ³ï¼Œä»¥åŠåˆ©ç”¨ Ming-Lite-Uni å®ç°é«˜è´¨é‡å›¾åƒç”Ÿæˆï¼Œæ¨¡å‹è¿˜èƒ½è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥èŠå¤©ã€æ–‡æœ¬è½¬è¯­éŸ³åŠå¤šåŠŸèƒ½å›¾åƒç¼–è¾‘ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMing-lite-omni åœ¨æ‰€æœ‰æ¨¡æ€ä¸Šçš„ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆæ–¹é¢æä¾›äº†å¼ºå¤§è§£å†³æ–¹æ¡ˆã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMing-lite-omni æ˜¯æˆ‘ä»¬æ‰€çŸ¥é¦–ä¸ªæ¨¡æ€æ”¯æŒä¸ GPT-4o åŒ¹é…çš„å¼€æºæ¨¡å‹ï¼Œä¸”æˆ‘ä»¬å‘å¸ƒäº†å…¨éƒ¨ä»£ç å’Œæ¨¡å‹æƒé‡ï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºè¿›ä¸€æ­¥ç ”ç©¶å’Œå‘å±•ã€‚
ğŸ“Œ æ›´æ–°

[2025.06.12] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚
[2025.05.28] ğŸ”¥ Ming-lite-omni å®˜æ–¹ç‰ˆæœ¬å‘å¸ƒï¼Œæ€§èƒ½æ›´ä½³å¹¶æ”¯æŒå›¾åƒç”Ÿæˆã€‚
[2025.05.04] ğŸ”¥ å‘å¸ƒ Ming-lite-omni æµ‹è¯•ç‰ˆæœ¬ï¼šMing-lite-omni-Previewã€‚

ä¸»è¦ç‰¹æ€§


ç»Ÿä¸€å…¨æ¨¡æ€æ„ŸçŸ¥ï¼šMing-lite-omni åŸºäº Lingï¼ˆä¸€ä¸ª MoE æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹ï¼‰ï¼Œé€šè¿‡æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨è§£å†³ä»»åŠ¡å†²çªï¼Œç¡®ä¿æ¥è‡ªä¸åŒæ¨¡æ€çš„ token çš„è¿è´¯èåˆã€‚


ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆï¼šMing-lite-omni å®ç°ç»Ÿä¸€çš„ç†è§£ä¸ç”Ÿæˆï¼Œä½¿æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­èƒ½è§£è¯»å¤šæ¨¡æ€æŒ‡ä»¤å’Œç”¨æˆ·æ„å›¾ï¼Œä»è€Œæå‡ç”Ÿæˆè´¨é‡å¹¶å¢å¼ºå¤šä»»åŠ¡ä½¿ç”¨ä¾¿åˆ©æ€§ã€‚


åˆ›æ–°çš„ç”Ÿæˆèƒ½åŠ›ï¼šMing-lite-omni èƒ½æ„ŸçŸ¥æ‰€æœ‰æ¨¡æ€ï¼ŒåŒæ—¶ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬ã€å®æ—¶è¯­éŸ³å’Œç”ŸåŠ¨å›¾åƒï¼Œå±•ç°å‡ºå“è¶Šçš„è·¨æ¨¡æ€è¡¨ç°ï¼Œæ¶µç›–å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’å’Œå›¾åƒç”Ÿæˆç­‰å¤šæ ·ä»»åŠ¡ã€‚


è¯„æµ‹
Ming-lite-omni åœ¨å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’åŠå›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å‡å±•ç°å‡ºä¼˜å¼‚çš„è·¨æ¨¡æ€æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å›¾åƒæ„ŸçŸ¥ä»»åŠ¡ä¸­ï¼ŒMing-lite-omni ä»…æ¿€æ´» 28 äº¿å‚æ•°ï¼Œæ€§èƒ½å·²å¯ä¸ Qwen2.5-VL-7B ç›¸åª²ç¾ã€‚å®ƒåœ¨ç«¯åˆ°ç«¯è¯­éŸ³ç†è§£å’ŒæŒ‡ä»¤æ‰§è¡Œä¸Šè¡¨ç°ä¼˜äº Qwen2.5-Omni å’Œ Kimi-Audioã€‚åŒæ—¶æ”¯æŒåŸç”Ÿåˆ†è¾¨ç‡çš„å›¾åƒç”Ÿæˆã€ç¼–è¾‘åŠé£æ ¼è¿ç§»ï¼ŒGenEval å¾—åˆ†è¾¾ 0.64ï¼Œä¼˜äºä¸»æµæ¨¡å‹å¦‚ SDXLã€‚åœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒMing-lite-omni è¾¾åˆ° 4.85ï¼Œåˆ·æ–°äº†ç°æœ‰æ–¹æ³•çš„æœ€ä½³æ°´å¹³ã€‚"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://inclusionai.github.io/zh/blog/"},{"@type":"ListItem","position":2,"name":"Ming-Omniï¼šä¸€ä¸ªç”¨äºæ„ŸçŸ¥ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹","item":"https://inclusionai.github.io/zh/blog/ming-omni/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Ming-Omniï¼šä¸€ä¸ªç”¨äºæ„ŸçŸ¥ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹","name":"Ming-Omniï¼šä¸€ä¸ªç”¨äºæ„ŸçŸ¥ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹","description":" GITHUB ğŸ“‘ Technical Reportï½œğŸ“–Project Page ï½œğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope\nä»‹ç» Ming-lite-omni æ˜¯ Ming-omni çš„è½»é‡ç‰ˆï¼Œæºè‡ª Ling-liteï¼Œæ‹¥æœ‰ 28 äº¿æ¿€æ´»å‚æ•°ã€‚Ming-lite-omni æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘ï¼Œå¹¶åœ¨è¯­éŸ³å’Œå›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè¾ƒå¼ºèƒ½åŠ›ã€‚Ming-lite-omni ä½¿ç”¨ä¸“ç”¨ç¼–ç å™¨ä»ä¸åŒæ¨¡æ€æå– tokenï¼Œç„¶åç”± Ling å¤„ç†ï¼ŒLing æ˜¯ä¸€ä¸ª MoE æ¶æ„ï¼Œé…å¤‡äº†æ–°æå‡ºçš„æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨ã€‚è¯¥è®¾è®¡ä½¿å•ä¸€æ¨¡å‹èƒ½åœ¨ç»Ÿä¸€æ¡†æ¶å†…é«˜æ•ˆå¤„ç†å’Œèåˆå¤šæ¨¡æ€è¾“å…¥ï¼Œä»è€Œæ”¯æŒå¤šæ ·åŒ–ä»»åŠ¡ï¼Œæ— éœ€ä½¿ç”¨å¤šä¸ªæ¨¡å‹ã€ä»»åŠ¡ä¸“ç”¨å¾®è°ƒæˆ–ç»“æ„æ”¹åŠ¨ã€‚é‡è¦çš„æ˜¯ï¼ŒMing-lite-omni è¶…è¶Šä¼ ç»Ÿå¤šæ¨¡æ€æ¨¡å‹ï¼Œæ”¯æŒéŸ³é¢‘å’Œå›¾åƒç”Ÿæˆã€‚é€šè¿‡é›†æˆå…ˆè¿›çš„éŸ³é¢‘è§£ç å™¨å®ç°è‡ªç„¶è¯­éŸ³ï¼Œä»¥åŠåˆ©ç”¨ Ming-Lite-Uni å®ç°é«˜è´¨é‡å›¾åƒç”Ÿæˆï¼Œæ¨¡å‹è¿˜èƒ½è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥èŠå¤©ã€æ–‡æœ¬è½¬è¯­éŸ³åŠå¤šåŠŸèƒ½å›¾åƒç¼–è¾‘ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMing-lite-omni åœ¨æ‰€æœ‰æ¨¡æ€ä¸Šçš„ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆæ–¹é¢æä¾›äº†å¼ºå¤§è§£å†³æ–¹æ¡ˆã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMing-lite-omni æ˜¯æˆ‘ä»¬æ‰€çŸ¥é¦–ä¸ªæ¨¡æ€æ”¯æŒä¸ GPT-4o åŒ¹é…çš„å¼€æºæ¨¡å‹ï¼Œä¸”æˆ‘ä»¬å‘å¸ƒäº†å…¨éƒ¨ä»£ç å’Œæ¨¡å‹æƒé‡ï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºè¿›ä¸€æ­¥ç ”ç©¶å’Œå‘å±•ã€‚\nğŸ“Œ æ›´æ–° [2025.06.12] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚ [2025.05.28] ğŸ”¥ Ming-lite-omni å®˜æ–¹ç‰ˆæœ¬å‘å¸ƒï¼Œæ€§èƒ½æ›´ä½³å¹¶æ”¯æŒå›¾åƒç”Ÿæˆã€‚ [2025.05.04] ğŸ”¥ å‘å¸ƒ Ming-lite-omni æµ‹è¯•ç‰ˆæœ¬ï¼šMing-lite-omni-Previewã€‚ ä¸»è¦ç‰¹æ€§ ç»Ÿä¸€å…¨æ¨¡æ€æ„ŸçŸ¥ï¼šMing-lite-omni åŸºäº Lingï¼ˆä¸€ä¸ª MoE æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹ï¼‰ï¼Œé€šè¿‡æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨è§£å†³ä»»åŠ¡å†²çªï¼Œç¡®ä¿æ¥è‡ªä¸åŒæ¨¡æ€çš„ token çš„è¿è´¯èåˆã€‚\nç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆï¼šMing-lite-omni å®ç°ç»Ÿä¸€çš„ç†è§£ä¸ç”Ÿæˆï¼Œä½¿æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­èƒ½è§£è¯»å¤šæ¨¡æ€æŒ‡ä»¤å’Œç”¨æˆ·æ„å›¾ï¼Œä»è€Œæå‡ç”Ÿæˆè´¨é‡å¹¶å¢å¼ºå¤šä»»åŠ¡ä½¿ç”¨ä¾¿åˆ©æ€§ã€‚\nåˆ›æ–°çš„ç”Ÿæˆèƒ½åŠ›ï¼šMing-lite-omni èƒ½æ„ŸçŸ¥æ‰€æœ‰æ¨¡æ€ï¼ŒåŒæ—¶ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬ã€å®æ—¶è¯­éŸ³å’Œç”ŸåŠ¨å›¾åƒï¼Œå±•ç°å‡ºå“è¶Šçš„è·¨æ¨¡æ€è¡¨ç°ï¼Œæ¶µç›–å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’å’Œå›¾åƒç”Ÿæˆç­‰å¤šæ ·ä»»åŠ¡ã€‚\nè¯„æµ‹ Ming-lite-omni åœ¨å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’åŠå›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å‡å±•ç°å‡ºä¼˜å¼‚çš„è·¨æ¨¡æ€æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å›¾åƒæ„ŸçŸ¥ä»»åŠ¡ä¸­ï¼ŒMing-lite-omni ä»…æ¿€æ´» 28 äº¿å‚æ•°ï¼Œæ€§èƒ½å·²å¯ä¸ Qwen2.5-VL-7B ç›¸åª²ç¾ã€‚å®ƒåœ¨ç«¯åˆ°ç«¯è¯­éŸ³ç†è§£å’ŒæŒ‡ä»¤æ‰§è¡Œä¸Šè¡¨ç°ä¼˜äº Qwen2.5-Omni å’Œ Kimi-Audioã€‚åŒæ—¶æ”¯æŒåŸç”Ÿåˆ†è¾¨ç‡çš„å›¾åƒç”Ÿæˆã€ç¼–è¾‘åŠé£æ ¼è¿ç§»ï¼ŒGenEval å¾—åˆ†è¾¾ 0.64ï¼Œä¼˜äºä¸»æµæ¨¡å‹å¦‚ SDXLã€‚åœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒMing-lite-omni è¾¾åˆ° 4.85ï¼Œåˆ·æ–°äº†ç°æœ‰æ–¹æ³•çš„æœ€ä½³æ°´å¹³ã€‚\n","keywords":[],"articleBody":" GITHUB ğŸ“‘ Technical Reportï½œğŸ“–Project Page ï½œğŸ¤— Hugging Faceï½œ ğŸ¤– ModelScope\nä»‹ç» Ming-lite-omni æ˜¯ Ming-omni çš„è½»é‡ç‰ˆï¼Œæºè‡ª Ling-liteï¼Œæ‹¥æœ‰ 28 äº¿æ¿€æ´»å‚æ•°ã€‚Ming-lite-omni æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘ï¼Œå¹¶åœ¨è¯­éŸ³å’Œå›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè¾ƒå¼ºèƒ½åŠ›ã€‚Ming-lite-omni ä½¿ç”¨ä¸“ç”¨ç¼–ç å™¨ä»ä¸åŒæ¨¡æ€æå– tokenï¼Œç„¶åç”± Ling å¤„ç†ï¼ŒLing æ˜¯ä¸€ä¸ª MoE æ¶æ„ï¼Œé…å¤‡äº†æ–°æå‡ºçš„æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨ã€‚è¯¥è®¾è®¡ä½¿å•ä¸€æ¨¡å‹èƒ½åœ¨ç»Ÿä¸€æ¡†æ¶å†…é«˜æ•ˆå¤„ç†å’Œèåˆå¤šæ¨¡æ€è¾“å…¥ï¼Œä»è€Œæ”¯æŒå¤šæ ·åŒ–ä»»åŠ¡ï¼Œæ— éœ€ä½¿ç”¨å¤šä¸ªæ¨¡å‹ã€ä»»åŠ¡ä¸“ç”¨å¾®è°ƒæˆ–ç»“æ„æ”¹åŠ¨ã€‚é‡è¦çš„æ˜¯ï¼ŒMing-lite-omni è¶…è¶Šä¼ ç»Ÿå¤šæ¨¡æ€æ¨¡å‹ï¼Œæ”¯æŒéŸ³é¢‘å’Œå›¾åƒç”Ÿæˆã€‚é€šè¿‡é›†æˆå…ˆè¿›çš„éŸ³é¢‘è§£ç å™¨å®ç°è‡ªç„¶è¯­éŸ³ï¼Œä»¥åŠåˆ©ç”¨ Ming-Lite-Uni å®ç°é«˜è´¨é‡å›¾åƒç”Ÿæˆï¼Œæ¨¡å‹è¿˜èƒ½è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥èŠå¤©ã€æ–‡æœ¬è½¬è¯­éŸ³åŠå¤šåŠŸèƒ½å›¾åƒç¼–è¾‘ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMing-lite-omni åœ¨æ‰€æœ‰æ¨¡æ€ä¸Šçš„ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆæ–¹é¢æä¾›äº†å¼ºå¤§è§£å†³æ–¹æ¡ˆã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMing-lite-omni æ˜¯æˆ‘ä»¬æ‰€çŸ¥é¦–ä¸ªæ¨¡æ€æ”¯æŒä¸ GPT-4o åŒ¹é…çš„å¼€æºæ¨¡å‹ï¼Œä¸”æˆ‘ä»¬å‘å¸ƒäº†å…¨éƒ¨ä»£ç å’Œæ¨¡å‹æƒé‡ï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºè¿›ä¸€æ­¥ç ”ç©¶å’Œå‘å±•ã€‚\nğŸ“Œ æ›´æ–° [2025.06.12] ğŸ”¥ æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šå·²å…¬å¼€å‘å¸ƒäº arxivã€‚ [2025.05.28] ğŸ”¥ Ming-lite-omni å®˜æ–¹ç‰ˆæœ¬å‘å¸ƒï¼Œæ€§èƒ½æ›´ä½³å¹¶æ”¯æŒå›¾åƒç”Ÿæˆã€‚ [2025.05.04] ğŸ”¥ å‘å¸ƒ Ming-lite-omni æµ‹è¯•ç‰ˆæœ¬ï¼šMing-lite-omni-Previewã€‚ ä¸»è¦ç‰¹æ€§ ç»Ÿä¸€å…¨æ¨¡æ€æ„ŸçŸ¥ï¼šMing-lite-omni åŸºäº Lingï¼ˆä¸€ä¸ª MoE æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹ï¼‰ï¼Œé€šè¿‡æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨è§£å†³ä»»åŠ¡å†²çªï¼Œç¡®ä¿æ¥è‡ªä¸åŒæ¨¡æ€çš„ token çš„è¿è´¯èåˆã€‚\nç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆï¼šMing-lite-omni å®ç°ç»Ÿä¸€çš„ç†è§£ä¸ç”Ÿæˆï¼Œä½¿æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­èƒ½è§£è¯»å¤šæ¨¡æ€æŒ‡ä»¤å’Œç”¨æˆ·æ„å›¾ï¼Œä»è€Œæå‡ç”Ÿæˆè´¨é‡å¹¶å¢å¼ºå¤šä»»åŠ¡ä½¿ç”¨ä¾¿åˆ©æ€§ã€‚\nåˆ›æ–°çš„ç”Ÿæˆèƒ½åŠ›ï¼šMing-lite-omni èƒ½æ„ŸçŸ¥æ‰€æœ‰æ¨¡æ€ï¼ŒåŒæ—¶ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬ã€å®æ—¶è¯­éŸ³å’Œç”ŸåŠ¨å›¾åƒï¼Œå±•ç°å‡ºå“è¶Šçš„è·¨æ¨¡æ€è¡¨ç°ï¼Œæ¶µç›–å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’å’Œå›¾åƒç”Ÿæˆç­‰å¤šæ ·ä»»åŠ¡ã€‚\nè¯„æµ‹ Ming-lite-omni åœ¨å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’åŠå›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å‡å±•ç°å‡ºä¼˜å¼‚çš„è·¨æ¨¡æ€æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å›¾åƒæ„ŸçŸ¥ä»»åŠ¡ä¸­ï¼ŒMing-lite-omni ä»…æ¿€æ´» 28 äº¿å‚æ•°ï¼Œæ€§èƒ½å·²å¯ä¸ Qwen2.5-VL-7B ç›¸åª²ç¾ã€‚å®ƒåœ¨ç«¯åˆ°ç«¯è¯­éŸ³ç†è§£å’ŒæŒ‡ä»¤æ‰§è¡Œä¸Šè¡¨ç°ä¼˜äº Qwen2.5-Omni å’Œ Kimi-Audioã€‚åŒæ—¶æ”¯æŒåŸç”Ÿåˆ†è¾¨ç‡çš„å›¾åƒç”Ÿæˆã€ç¼–è¾‘åŠé£æ ¼è¿ç§»ï¼ŒGenEval å¾—åˆ†è¾¾ 0.64ï¼Œä¼˜äºä¸»æµæ¨¡å‹å¦‚ SDXLã€‚åœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒMing-lite-omni è¾¾åˆ° 4.85ï¼Œåˆ·æ–°äº†ç°æœ‰æ–¹æ³•çš„æœ€ä½³æ°´å¹³ã€‚\nImage benchmark Benchmarks Ming-lite-omni Qwen2.5-VL-7B-Instruct InternVL2.5-8B-MPO AI2D 83.1 84.4 84.5 HallusionBench 55.0 55.8 51.7 MMBench_TEST_V11 80.8 82.8 82.0 MMMU 56.3 56.6 54.8 MMStar 64.7 65.3 65.2 MMVet 71.3 71.6 68.1 MathVista 71.6 68.1 67.9 OCRBench 88.4 87.8 88.2 Average 71.4 71.5 70.3 Encyclopedia Benchmarks Object Recognition Ming-lite-omni Qwen2.5-VL-7B-Instruct Plants 54.96 47.8 Animals 56.7 50.85 Vehicles 41.91 42.29 Food \u0026 Ingredients 62.28 54.09 Dishes 44.3 39.07 General 91.08 92.42 Average 58.54 54.43 Video benchmark Benchmarks Ming-lite-omni Qwen2.5VL-7B-Instruct VideoMME 67.0 67.3 MVBench 67.7 67.4 Video-MMMU 46.3 47.4 LongVideoBench 56.6 54.7 Average 59.4 59.2 Note: All models are evaluated based on 128 uniformly sampled frames. Audio benchmark SpeechQA Model Average AlpacaEval CommonEval SD-QA MMSU OpenBookQA IFEval AdvBench Qwen2-Audio-chat 3.545 3.69 3.40 35.35 35.43 49.01 22.57 98.85 Baichuan-Audio 3.695 4.00 3.39 49.64 48.80 63.30 41.32 86.73 GLM-4-Voice 3.77 4.06 3.48 43.31 40.11 52.97 24.91 88.08 Kimi-Audio 4.215 4.46 3.97 63.12 62.17 83.52 61.10 100.00 Qwen2.5-Omni 4.21 4.49 3.93 55.71 61.32 81.10 52.87 99.42 Ming-lite-omni 4.34 4.63 4.06 58.84 47.53 61.98 58.36 99.04 ASR Model aishell1 aishell2_android aishell2_ios cv15_zh fleurs_zh wenetspeech_meeting wenetspeech_net librispeech_test_clean librispeech_test_other multilingual_librispeech cv15_en fleurs_en voxpopuli_v1.0_en Ming-lite-omni 1.47 2.55 2.52 6.31 2.96 5.95 5.46 1.44 2.80 4.15 6.89 3.39 5.80 Qwen2.-Omni 1.18 2.75 2.63 5.20 3.00 5.90 7.70 1.80 3.40 7.56 7.60 4.10 5.80 Qwen2-Audio 1.53 2.92 2.92 6.90 7.50 7.16 8.42 1.60 3.60 5.40 8.60 6.90 6.84 Kimi-Audio 0.60 2.64 2.56 7.21 2.69 6.28 5.37 1.28 2.42 5.88 10.31 4.44 7.97 Information-Seeking Benchmark Model InfoSeek_H-mean InfoSeek_unseen_question InfoSeek_unseen_entity GPT-4o 36.05 - - PaLI-X 22.06 23.5 20.8 Qwen2.5-vl-32B 19.35 20.55 18.28 Ming-lite-omni 27.7 30.4 25.4 OCR Model Ming-lite-omni Qwen2.5-VL-7B-Instruct ChartQA_TEST 85.1 87.3 DocVQA_TEST 93 95.7 OCRBenchV2_en/zh 53.3/52 56.3/57.2 OmniDocBenchâ†“ 34/34.4 30.8/39.8 TextVQA_VAL 82.8 84.9 GUI Model Ming-lite-omni InternVL3 8B Qwen2.5-VL-7B-Instruct ScreenSpot 82.1 79.5 78.9* ScreenSpot-V2 84.1 81.4 - AITZ(EM) 66.6 - 57.6* Note: * denotes the reproduced results. Unified Generation Benchmark Model single_object two_object counting colors position color_attr GENEVAL DPGBench FIDâ†“ Ming-lite-omni 0.9875 0.7727 0.6812 0.7872 0.31 0.29 0.64 81.72 4.85 Metaquery-XL - - - - - - 0.61 82.05 6.02 SDv2.1 0.98 0.51 0.44 0.85 0.07 0.17 0.50 68.09 26.96 Emu3-Gen 0.98 0.71 0.34 0.81 0.17 0.21 0.54 80.60 - SDXL 0.98 0.74 0.39 0.85 0.15 0.23 0.55 74.65 8.76 Janus 0.97 0.68 0.30 0.84 0.46 0.42 0.61 79.68 10.10 JanusFlow - - - - - - 0.63 80.09 9.51 Please refer to our technical report for more comprehensive evaluation results.\næ¨¡å‹ä¸‹è½½ æ‚¨å¯ä»¥ä» Huggingface å’Œ ModelScope ä¸¤ä¸ªå¹³å°ä¸‹è½½æ¨¡å‹ã€‚\næ¨¡å‹ è¾“å…¥æ¨¡æ€ è¾“å‡ºæ¨¡æ€ ä¸‹è½½åœ°å€ Ming-Lite-Omni å›¾åƒã€æ–‡æœ¬ã€è§†é¢‘ã€éŸ³é¢‘ å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘ ğŸ¤— HuggingFace ğŸ¤– ModelScope å¦‚æœæ‚¨ä½äºä¸­å›½å¤§é™†ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨ä» ğŸ¤– ModelScope ä¸‹è½½æ¨¡å‹ã€‚\nç¯å¢ƒå‡†å¤‡ Installation with pip pip install -r requirements.txt # for python 3.10 pip install data/matcha_tts-0.0.5.1-cp310-cp310-linux_x86_64.whl # for python 3.8 # pip install data/matcha_tts-0.0.5.1-cp38-cp38-linux_x86_64.whl pip install diffusers==0.33.0 pip install nvidia-cublas-cu12==12.4.5.8 # for H20 GPU Installation with docker You can also initialize the environment by building the docker image. First clone this repository:\ngit clone --depth 1 https://github.com/inclusionAI/Ming.git cd Ming Then build the docker image with the provided Dockerfile in docker/docker-py310-cu121. This step might take a while:\ndocker build -t ming:py310-cu121 docker/docker-py310-cu121 At last, start the container with the current repo directory mounted:\ndocker run -it --gpus all -v \"$(pwd)\":/workspace/Ming ming:py310-cu121 ming:py310-cu121 /bin/bash You can run the model with python interface. You may download the huggingface model in the repo directory first (.../Ming/) or mount the downloaded model path when starting the container.\nä½¿ç”¨æ ·ä¾‹ We provide a step-by-step running example:\nStep 1 - Download the source code\ngit clone https://github.com/inclusionAI/Ming.git cd Ming Step 2 - Download the model weights and create a soft link to the source code directory\nDownload our model following Model Downloads\nmkdir inclusionAI ln -s /path/to/inclusionAI/Ming-Lite-Omni inclusionAI/Ming-Lite-Omni Step 3 - Enter the code directory, you can refer to the following codes to run the Ming-Lite-Omni model.\njupyter notebook cookbook.ipynb We also provide a simple example on the usage of this repo. For detailed usage, please refer to cookbook.ipynb.\nimport torch from transformers import AutoProcessor, GenerationConfig from modeling_bailingmm import BailingMMNativeForConditionalGeneration # load model model = BailingMMNativeForConditionalGeneration.from_pretrained( \"inclusionAI/Ming-Lite-Omni\", torch_dtype=torch.bfloat16, low_cpu_mem_usage=True ).to(\"cuda\") # build processor processor = AutoProcessor.from_pretrained(\"inclusionAI/Ming-Lite-Omni\", trust_remote_code=True) # qa messages = [ { \"role\": \"HUMAN\", \"content\": [ {\"type\": \"text\", \"text\": \"è¯·è¯¦ç»†ä»‹ç»é¹¦é¹‰çš„ç”Ÿæ´»ä¹ æ€§ã€‚\"} ], }, ] # 1. Format inputs using chat template text = processor.apply_chat_template(messages, add_generation_prompt=True) # 2. Extract vision/audio data image_inputs, video_inputs, audio_inputs = processor.process_vision_info(messages) # 3. Prepare tensor inputs inputs = processor( text=[text], images=image_inputs, videos=video_inputs, audios=audio_inputs, return_tensors=\"pt\", ) inputs = inputs.to(model.device) for k in inputs.keys(): if k == \"pixel_values\" or k == \"pixel_values_videos\" or k == \"audio_feats\": inputs[k] = inputs[k].to(dtype=torch.bfloat16) # 4. Configure generation generation_config = GenerationConfig.from_dict({'no_repeat_ngram_size': 10}) generated_ids = model.generate( **inputs, max_new_tokens=512, use_cache=True, eos_token_id=processor.gen_terminator, generation_config=generation_config, ) generated_ids_trimmed = [ out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, generated_ids) ] # 5. Decode output output_text = processor.batch_decode( generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False )[0] print(output_text) # Output: # é¹¦é¹‰æ˜¯ä¸€ç§éå¸¸èªæ˜å’Œç¤¾äº¤æ€§å¼ºçš„é¸Ÿç±»ï¼Œå®ƒä»¬çš„ç”Ÿæ´»ä¹ æ€§éå¸¸ä¸°å¯Œå’Œæœ‰è¶£ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å…³äºé¹¦é¹‰ç”Ÿæ´»ä¹ æ€§çš„è¯¦ç»†ä»‹ç»ï¼š # ### 1. **æ –æ¯åœ°** # é¹¦é¹‰ä¸»è¦åˆ†å¸ƒåœ¨çƒ­å¸¦å’Œäºšçƒ­å¸¦åœ°åŒºï¼ŒåŒ…æ‹¬éæ´²ã€äºšæ´²ã€æ¾³å¤§åˆ©äºšå’Œå—ç¾æ´²ã€‚å®ƒä»¬é€šå¸¸ç”Ÿæ´»åœ¨æ£®æ—ã€è‰åŸã€æ²™æ¼ å’ŒåŸå¸‚ç¯å¢ƒä¸­ã€‚ä¸åŒç§ç±»çš„é¹¦é¹‰å¯¹æ –æ¯åœ°çš„è¦æ±‚æœ‰æ‰€ä¸åŒï¼Œä½†å¤§å¤šæ•°é¹¦é¹‰å–œæ¬¢æœ‰ä¸°å¯Œæ¤è¢«å’Œæ°´æºçš„åœ°æ–¹ã€‚ # ### 2. **é¥®é£Ÿ** # é¹¦é¹‰æ˜¯æ‚é£Ÿæ€§åŠ¨ç‰©ï¼Œå®ƒä»¬çš„é¥®é£Ÿéå¸¸å¤šæ ·åŒ–ã€‚å®ƒä»¬çš„é£Ÿç‰©åŒ…æ‹¬ç§å­ã€åšæœã€æ°´æœã€è”¬èœã€èŠ±èœœå’Œæ˜†è™«ã€‚é¹¦é¹‰çš„å–™éå¸¸å¼ºå£®ï¼Œèƒ½å¤Ÿè½»æ¾åœ°æ‰“å¼€åšç¡¬çš„æœå£³å’Œåšæœã€‚ä¸€äº›é¹¦é¹‰è¿˜ä¼šåƒæ³¥åœŸæˆ–æ²™å­ï¼Œä»¥å¸®åŠ©æ¶ˆåŒ–å’Œè¡¥å……çŸ¿ç‰©è´¨ã€‚ # ...... Note: We test the examples on hardware of NVIDIA H800-80GB/H20-96G with CUDA 12.4. Loading inclusionAI/Ming-Lite-Omni in bfloat16 takes about 62G GPU memory.\nè®¸å¯ä¸æ³•å¾‹å£°æ˜ æœ¬ä»£ç ä»“åº“éµå¾ª MIT è®¸å¯è¯ï¼Œæ³•å¾‹å£°æ˜è§é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ LEGAL.md æ–‡ä»¶ã€‚\nå¼•ç”¨ å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨ã€‚\n@misc{Mingomni2025, title = {Ming-Omni: A Unified Multimodal Model for Perception and Generation}, author = {Inclusion AI}, year = {2025}, eprint = {2506.09344}, archivePrefix = {arXiv}, url = {https://arxiv.org/abs/2506.09344} } ","wordCount":"936","inLanguage":"zh","datePublished":"2025-06-11T00:00:03+08:00","dateModified":"2025-06-11T00:00:03+08:00","author":{"@type":"Person","name":"inclusionAI, Ant Group"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://inclusionai.github.io/zh/blog/ming-omni/"},"publisher":{"@type":"Organization","name":"INCLUSION AI","logo":{"@type":"ImageObject","url":"https://inclusionai.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="inclusionAI (Alt + H)"><img src=https://inclusionai.github.io/img/logo_head.png alt aria-label=logo height=50></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://github.com/inclusionAI title="Try Ling & Ming"><span>Try Ling & Ming</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=/>Home</a>&nbsp;Â»&nbsp;<a href=https://inclusionai.github.io/zh/blog/>Blog</a></div><h1 class=post-title>Ming-Omniï¼šä¸€ä¸ªç”¨äºæ„ŸçŸ¥ä¸ç”Ÿæˆçš„ç»Ÿä¸€å¤šæ¨¡æ€æ¨¡å‹</h1><div class=post-meta><span class=post-date title="2025-06-11 00:00:03 +0800 +0800">2025å¹´6æœˆ11æ—¥</span>
<span class=post-word-count>936 å­—</span>
<span class=post-author>inclusionAI, Ant Group</span>
&nbsp;|&nbsp;è¯­è¨€:<ul class=i18n_list><li><a href=https://inclusionai.github.io/blog/ming-omni/>English</a></li></ul></div></header><div class=post-content><p><a href=https://github.com/inclusionAI/Ming/tree/Ming-Lite-Omni-Preview/Ming-unify class="btn external" target=_blank>GITHUB</a> ğŸ“‘ <a href=https://arxiv.org/abs/2506.09344>Technical Report</a>ï½œğŸ“–<a href=https://lucaria-academy.github.io/Ming-Omni/>Project Page</a> ï½œğŸ¤— <a href=https://huggingface.co/inclusionAI/Ming-Lite-Omni>Hugging Face</a>ï½œ ğŸ¤– <a href=https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni>ModelScope</a></p><h2 id=ä»‹ç»>ä»‹ç»<a hidden class=anchor aria-hidden=true href=#ä»‹ç»>#</a></h2><p>Ming-lite-omni æ˜¯ Ming-omni çš„è½»é‡ç‰ˆï¼Œæºè‡ª <a href=https://github.com/inclusionAI/Ling>Ling-lite</a>ï¼Œæ‹¥æœ‰ 28 äº¿æ¿€æ´»å‚æ•°ã€‚Ming-lite-omni æ˜¯ä¸€ä¸ªç»Ÿä¸€çš„å¤šæ¨¡æ€æ¨¡å‹ï¼Œèƒ½å¤Ÿå¤„ç†å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘å’Œè§†é¢‘ï¼Œå¹¶åœ¨è¯­éŸ³å’Œå›¾åƒç”Ÿæˆæ–¹é¢è¡¨ç°å‡ºè¾ƒå¼ºèƒ½åŠ›ã€‚Ming-lite-omni ä½¿ç”¨ä¸“ç”¨ç¼–ç å™¨ä»ä¸åŒæ¨¡æ€æå– tokenï¼Œç„¶åç”± Ling å¤„ç†ï¼ŒLing æ˜¯ä¸€ä¸ª MoE æ¶æ„ï¼Œé…å¤‡äº†æ–°æå‡ºçš„æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨ã€‚è¯¥è®¾è®¡ä½¿å•ä¸€æ¨¡å‹èƒ½åœ¨ç»Ÿä¸€æ¡†æ¶å†…é«˜æ•ˆå¤„ç†å’Œèåˆå¤šæ¨¡æ€è¾“å…¥ï¼Œä»è€Œæ”¯æŒå¤šæ ·åŒ–ä»»åŠ¡ï¼Œæ— éœ€ä½¿ç”¨å¤šä¸ªæ¨¡å‹ã€ä»»åŠ¡ä¸“ç”¨å¾®è°ƒæˆ–ç»“æ„æ”¹åŠ¨ã€‚é‡è¦çš„æ˜¯ï¼ŒMing-lite-omni è¶…è¶Šä¼ ç»Ÿå¤šæ¨¡æ€æ¨¡å‹ï¼Œæ”¯æŒéŸ³é¢‘å’Œå›¾åƒç”Ÿæˆã€‚é€šè¿‡é›†æˆå…ˆè¿›çš„éŸ³é¢‘è§£ç å™¨å®ç°è‡ªç„¶è¯­éŸ³ï¼Œä»¥åŠåˆ©ç”¨ Ming-Lite-Uni å®ç°é«˜è´¨é‡å›¾åƒç”Ÿæˆï¼Œæ¨¡å‹è¿˜èƒ½è¿›è¡Œä¸Šä¸‹æ–‡æ„ŸçŸ¥èŠå¤©ã€æ–‡æœ¬è½¬è¯­éŸ³åŠå¤šåŠŸèƒ½å›¾åƒç¼–è¾‘ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒMing-lite-omni åœ¨æ‰€æœ‰æ¨¡æ€ä¸Šçš„ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆæ–¹é¢æä¾›äº†å¼ºå¤§è§£å†³æ–¹æ¡ˆã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼ŒMing-lite-omni æ˜¯æˆ‘ä»¬æ‰€çŸ¥é¦–ä¸ªæ¨¡æ€æ”¯æŒä¸ GPT-4o åŒ¹é…çš„å¼€æºæ¨¡å‹ï¼Œä¸”æˆ‘ä»¬å‘å¸ƒäº†å…¨éƒ¨ä»£ç å’Œæ¨¡å‹æƒé‡ï¼Œä»¥ä¿ƒè¿›ç¤¾åŒºè¿›ä¸€æ­¥ç ”ç©¶å’Œå‘å±•ã€‚</p><h2 id=-æ›´æ–°>ğŸ“Œ æ›´æ–°<a hidden class=anchor aria-hidden=true href=#-æ›´æ–°>#</a></h2><ul><li>[2025.06.12] ğŸ”¥ æˆ‘ä»¬çš„<a href=https://arxiv.org/abs/2506.09344>æŠ€æœ¯æŠ¥å‘Š</a>å·²å…¬å¼€å‘å¸ƒäº arxivã€‚</li><li>[2025.05.28] ğŸ”¥ Ming-lite-omni å®˜æ–¹ç‰ˆæœ¬å‘å¸ƒï¼Œæ€§èƒ½æ›´ä½³å¹¶æ”¯æŒå›¾åƒç”Ÿæˆã€‚</li><li>[2025.05.04] ğŸ”¥ å‘å¸ƒ Ming-lite-omni æµ‹è¯•ç‰ˆæœ¬ï¼š<a href=https://github.com/inclusionAI/Ming/tree/Ming-Lite-Omni-Preview>Ming-lite-omni-Preview</a>ã€‚</li></ul><h2 id=ä¸»è¦ç‰¹æ€§>ä¸»è¦ç‰¹æ€§<a hidden class=anchor aria-hidden=true href=#ä¸»è¦ç‰¹æ€§>#</a></h2><ul><li><p><strong>ç»Ÿä¸€å…¨æ¨¡æ€æ„ŸçŸ¥</strong>ï¼šMing-lite-omni åŸºäº <a href=https://github.com/inclusionAI/Ling>Ling</a>ï¼ˆä¸€ä¸ª MoE æ¶æ„çš„å¤§è¯­è¨€æ¨¡å‹ï¼‰ï¼Œé€šè¿‡æ¨¡æ€ä¸“ç”¨è·¯ç”±å™¨è§£å†³ä»»åŠ¡å†²çªï¼Œç¡®ä¿æ¥è‡ªä¸åŒæ¨¡æ€çš„ token çš„è¿è´¯èåˆã€‚</p></li><li><p><strong>ç»Ÿä¸€æ„ŸçŸ¥ä¸ç”Ÿæˆ</strong>ï¼šMing-lite-omni å®ç°ç»Ÿä¸€çš„ç†è§£ä¸ç”Ÿæˆï¼Œä½¿æ¨¡å‹åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­èƒ½è§£è¯»å¤šæ¨¡æ€æŒ‡ä»¤å’Œç”¨æˆ·æ„å›¾ï¼Œä»è€Œæå‡ç”Ÿæˆè´¨é‡å¹¶å¢å¼ºå¤šä»»åŠ¡ä½¿ç”¨ä¾¿åˆ©æ€§ã€‚</p></li><li><p><strong>åˆ›æ–°çš„ç”Ÿæˆèƒ½åŠ›</strong>ï¼šMing-lite-omni èƒ½æ„ŸçŸ¥æ‰€æœ‰æ¨¡æ€ï¼ŒåŒæ—¶ç”Ÿæˆé«˜è´¨é‡æ–‡æœ¬ã€å®æ—¶è¯­éŸ³å’Œç”ŸåŠ¨å›¾åƒï¼Œå±•ç°å‡ºå“è¶Šçš„è·¨æ¨¡æ€è¡¨ç°ï¼Œæ¶µç›–å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’å’Œå›¾åƒç”Ÿæˆç­‰å¤šæ ·ä»»åŠ¡ã€‚</p></li></ul><h2 id=è¯„æµ‹>è¯„æµ‹<a hidden class=anchor aria-hidden=true href=#è¯„æµ‹>#</a></h2><p>Ming-lite-omni åœ¨å›¾åƒæ„ŸçŸ¥ã€è§†å¬äº¤äº’åŠå›¾åƒç”Ÿæˆä»»åŠ¡ä¸­å‡å±•ç°å‡ºä¼˜å¼‚çš„è·¨æ¨¡æ€æ€§èƒ½ã€‚å…·ä½“æ¥è¯´ï¼Œåœ¨å›¾åƒæ„ŸçŸ¥ä»»åŠ¡ä¸­ï¼ŒMing-lite-omni ä»…æ¿€æ´» 28 äº¿å‚æ•°ï¼Œæ€§èƒ½å·²å¯ä¸ Qwen2.5-VL-7B ç›¸åª²ç¾ã€‚å®ƒåœ¨ç«¯åˆ°ç«¯è¯­éŸ³ç†è§£å’ŒæŒ‡ä»¤æ‰§è¡Œä¸Šè¡¨ç°ä¼˜äº Qwen2.5-Omni å’Œ Kimi-Audioã€‚åŒæ—¶æ”¯æŒåŸç”Ÿåˆ†è¾¨ç‡çš„å›¾åƒç”Ÿæˆã€ç¼–è¾‘åŠé£æ ¼è¿ç§»ï¼ŒGenEval å¾—åˆ†è¾¾ 0.64ï¼Œä¼˜äºä¸»æµæ¨¡å‹å¦‚ SDXLã€‚åœ¨ FID æŒ‡æ ‡ä¸Šï¼ŒMing-lite-omni è¾¾åˆ° 4.85ï¼Œåˆ·æ–°äº†ç°æœ‰æ–¹æ³•çš„æœ€ä½³æ°´å¹³ã€‚</p><h3 id=image-benchmark>Image benchmark<a hidden class=anchor aria-hidden=true href=#image-benchmark>#</a></h3><div align=center><table><thead><tr><th style=text-align:left>Benchmarks</th><th style=text-align:center>Ming-lite-omni</th><th style=text-align:center>Qwen2.5-VL-7B-Instruct</th><th style=text-align:center>InternVL2.5-8B-MPO</th></tr></thead><tbody><tr><td style=text-align:left>AI2D</td><td style=text-align:center>83.1</td><td style=text-align:center>84.4</td><td style=text-align:center><b>84.5</b></td></tr><tr><td style=text-align:left>HallusionBench</td><td style=text-align:center><b>55.0</b></td><td style=text-align:center>55.8</td><td style=text-align:center>51.7</td></tr><tr><td style=text-align:left>MMBench_TEST_V11</td><td style=text-align:center>80.8</td><td style=text-align:center><b>82.8</b></td><td style=text-align:center>82.0</td></tr><tr><td style=text-align:left>MMMU</td><td style=text-align:center>56.3</td><td style=text-align:center><b>56.6</b></td><td style=text-align:center>54.8</td></tr><tr><td style=text-align:left>MMStar</td><td style=text-align:center>64.7</td><td style=text-align:center>65.3</td><td style=text-align:center><b>65.2</b></td></tr><tr><td style=text-align:left>MMVet</td><td style=text-align:center>71.3</td><td style=text-align:center>71.6</td><td style=text-align:center>68.1</td></tr><tr><td style=text-align:left>MathVista</td><td style=text-align:center><b>71.6</b></td><td style=text-align:center>68.1</td><td style=text-align:center>67.9</td></tr><tr><td style=text-align:left>OCRBench</td><td style=text-align:center><b>88.4</b></td><td style=text-align:center>87.8</td><td style=text-align:center>88.2</td></tr><tr><td style=text-align:left>Average</td><td style=text-align:center>71.4</td><td style=text-align:center><b>71.5</b></td><td style=text-align:center>70.3</td></tr></tbody></table></div><h4 id=encyclopedia-benchmarks>Encyclopedia Benchmarks<a hidden class=anchor aria-hidden=true href=#encyclopedia-benchmarks>#</a></h4><div align=center><table><thead><tr><th style=text-align:left>Object Recognition</th><th style=text-align:center>Ming-lite-omni</th><th style=text-align:center>Qwen2.5-VL-7B-Instruct</th></tr></thead><tbody><tr><td style=text-align:left>Plants</td><td style=text-align:center><strong>54.96</strong></td><td style=text-align:center>47.8</td></tr><tr><td style=text-align:left>Animals</td><td style=text-align:center><strong>56.7</strong></td><td style=text-align:center>50.85</td></tr><tr><td style=text-align:left>Vehicles</td><td style=text-align:center>41.91</td><td style=text-align:center><strong>42.29</strong></td></tr><tr><td style=text-align:left>Food & Ingredients</td><td style=text-align:center><strong>62.28</strong></td><td style=text-align:center>54.09</td></tr><tr><td style=text-align:left>Dishes</td><td style=text-align:center><strong>44.3</strong></td><td style=text-align:center>39.07</td></tr><tr><td style=text-align:left>General</td><td style=text-align:center>91.08</td><td style=text-align:center><strong>92.42</strong></td></tr><tr><td style=text-align:left>Average</td><td style=text-align:center><strong>58.54</strong></td><td style=text-align:center>54.43</td></tr></tbody></table></div><h3 id=video-benchmark>Video benchmark<a hidden class=anchor aria-hidden=true href=#video-benchmark>#</a></h3><div align=center><table><thead><tr><th style=text-align:left>Benchmarks</th><th style=text-align:center>Ming-lite-omni</th><th style=text-align:center>Qwen2.5VL-7B-Instruct</th></tr></thead><tbody><tr><td style=text-align:left>VideoMME</td><td style=text-align:center>67.0</td><td style=text-align:center><b>67.3</b></td></tr><tr><td style=text-align:left>MVBench</td><td style=text-align:center>67.7</td><td style=text-align:center><b>67.4</b></td></tr><tr><td style=text-align:left>Video-MMMU</td><td style=text-align:center>46.3</td><td style=text-align:center><b>47.4</b></td></tr><tr><td style=text-align:left>LongVideoBench</td><td style=text-align:center>56.6</td><td style=text-align:center>54.7</td></tr><tr><td style=text-align:left>Average</td><td style=text-align:center><b>59.4</b></td><td style=text-align:center>59.2</td></tr></tbody></table></div>Note: All models are evaluated based on 128 uniformly sampled frames.<h3 id=audio-benchmark>Audio benchmark<a hidden class=anchor aria-hidden=true href=#audio-benchmark>#</a></h3><h4 id=speechqa>SpeechQA<a hidden class=anchor aria-hidden=true href=#speechqa>#</a></h4><div align=center><table><thead><tr><th style=text-align:left>Model</th><th style=text-align:center>Average</th><th style=text-align:center>AlpacaEval</th><th style=text-align:center>CommonEval</th><th style=text-align:center>SD-QA</th><th style=text-align:center>MMSU</th><th style=text-align:center>OpenBookQA</th><th style=text-align:center>IFEval</th><th style=text-align:center>AdvBench</th></tr></thead><tbody><tr><td style=text-align:left>Qwen2-Audio-chat</td><td style=text-align:center>3.545</td><td style=text-align:center>3.69</td><td style=text-align:center>3.40</td><td style=text-align:center>35.35</td><td style=text-align:center>35.43</td><td style=text-align:center>49.01</td><td style=text-align:center>22.57</td><td style=text-align:center>98.85</td></tr><tr><td style=text-align:left>Baichuan-Audio</td><td style=text-align:center>3.695</td><td style=text-align:center>4.00</td><td style=text-align:center>3.39</td><td style=text-align:center>49.64</td><td style=text-align:center>48.80</td><td style=text-align:center>63.30</td><td style=text-align:center>41.32</td><td style=text-align:center>86.73</td></tr><tr><td style=text-align:left>GLM-4-Voice</td><td style=text-align:center>3.77</td><td style=text-align:center>4.06</td><td style=text-align:center>3.48</td><td style=text-align:center>43.31</td><td style=text-align:center>40.11</td><td style=text-align:center>52.97</td><td style=text-align:center>24.91</td><td style=text-align:center>88.08</td></tr><tr><td style=text-align:left>Kimi-Audio</td><td style=text-align:center>4.215</td><td style=text-align:center>4.46</td><td style=text-align:center>3.97</td><td style=text-align:center><b>63.12</b></td><td style=text-align:center><b>62.17</b></td><td style=text-align:center><b>83.52</b></td><td style=text-align:center><b>61.10</b></td><td style=text-align:center><b>100.00</b></td></tr><tr><td style=text-align:left>Qwen2.5-Omni</td><td style=text-align:center>4.21</td><td style=text-align:center>4.49</td><td style=text-align:center>3.93</td><td style=text-align:center>55.71</td><td style=text-align:center>61.32</td><td style=text-align:center>81.10</td><td style=text-align:center>52.87</td><td style=text-align:center>99.42</td></tr><tr><td style=text-align:left>Ming-lite-omni</td><td style=text-align:center><b>4.34</b></td><td style=text-align:center><b>4.63</b></td><td style=text-align:center><b>4.06</b></td><td style=text-align:center>58.84</td><td style=text-align:center>47.53</td><td style=text-align:center>61.98</td><td style=text-align:center>58.36</td><td style=text-align:center>99.04</td></tr></tbody></table></div><h4 id=asr>ASR<a hidden class=anchor aria-hidden=true href=#asr>#</a></h4><div align=center><table><thead><tr><th style=text-align:center>Model</th><th style=text-align:center>aishell1</th><th style=text-align:center>aishell2_android</th><th style=text-align:center>aishell2_ios</th><th style=text-align:center>cv15_zh</th><th style=text-align:center>fleurs_zh</th><th style=text-align:center>wenetspeech_meeting</th><th style=text-align:center>wenetspeech_net</th><th style=text-align:center>librispeech_test_clean</th><th style=text-align:center>librispeech_test_other</th><th style=text-align:center>multilingual_librispeech</th><th style=text-align:center>cv15_en</th><th style=text-align:center>fleurs_en</th><th style=text-align:center>voxpopuli_v1.0_en</th></tr></thead><tbody><tr><td style=text-align:center>Ming-lite-omni</td><td style=text-align:center>1.47</td><td style=text-align:center><strong>2.55</strong></td><td style=text-align:center><strong>2.52</strong></td><td style=text-align:center>6.31</td><td style=text-align:center>2.96</td><td style=text-align:center>5.95</td><td style=text-align:center>5.46</td><td style=text-align:center>1.44</td><td style=text-align:center>2.80</td><td style=text-align:center><strong>4.15</strong></td><td style=text-align:center><strong>6.89</strong></td><td style=text-align:center><strong>3.39</strong></td><td style=text-align:center><strong>5.80</strong></td></tr><tr><td style=text-align:center>Qwen2.-Omni</td><td style=text-align:center>1.18</td><td style=text-align:center>2.75</td><td style=text-align:center>2.63</td><td style=text-align:center><strong>5.20</strong></td><td style=text-align:center>3.00</td><td style=text-align:center><strong>5.90</strong></td><td style=text-align:center>7.70</td><td style=text-align:center>1.80</td><td style=text-align:center>3.40</td><td style=text-align:center>7.56</td><td style=text-align:center>7.60</td><td style=text-align:center>4.10</td><td style=text-align:center><strong>5.80</strong></td></tr><tr><td style=text-align:center>Qwen2-Audio</td><td style=text-align:center>1.53</td><td style=text-align:center>2.92</td><td style=text-align:center>2.92</td><td style=text-align:center>6.90</td><td style=text-align:center>7.50</td><td style=text-align:center>7.16</td><td style=text-align:center>8.42</td><td style=text-align:center>1.60</td><td style=text-align:center>3.60</td><td style=text-align:center>5.40</td><td style=text-align:center>8.60</td><td style=text-align:center>6.90</td><td style=text-align:center>6.84</td></tr><tr><td style=text-align:center>Kimi-Audio</td><td style=text-align:center><strong>0.60</strong></td><td style=text-align:center>2.64</td><td style=text-align:center>2.56</td><td style=text-align:center>7.21</td><td style=text-align:center><strong>2.69</strong></td><td style=text-align:center>6.28</td><td style=text-align:center><strong>5.37</strong></td><td style=text-align:center><strong>1.28</strong></td><td style=text-align:center><strong>2.42</strong></td><td style=text-align:center>5.88</td><td style=text-align:center>10.31</td><td style=text-align:center>4.44</td><td style=text-align:center>7.97</td></tr></tbody></table></div><h3 id=information-seeking-benchmark>Information-Seeking Benchmark<a hidden class=anchor aria-hidden=true href=#information-seeking-benchmark>#</a></h3><div align=center><table><thead><tr><th style=text-align:left>Model</th><th style=text-align:center>InfoSeek_H-mean</th><th style=text-align:center>InfoSeek_unseen_question</th><th style=text-align:center>InfoSeek_unseen_entity</th></tr></thead><tbody><tr><td style=text-align:left>GPT-4o</td><td style=text-align:center><b>36.05</b></td><td style=text-align:center>-</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>PaLI-X</td><td style=text-align:center>22.06</td><td style=text-align:center>23.5</td><td style=text-align:center>20.8</td></tr><tr><td style=text-align:left>Qwen2.5-vl-32B</td><td style=text-align:center>19.35</td><td style=text-align:center>20.55</td><td style=text-align:center>18.28</td></tr><tr><td style=text-align:left>Ming-lite-omni</td><td style=text-align:center>27.7</td><td style=text-align:center><strong>30.4</strong></td><td style=text-align:center><strong>25.4</strong></td></tr></tbody></table></div><h3 id=ocr>OCR<a hidden class=anchor aria-hidden=true href=#ocr>#</a></h3><div align=center><table><thead><tr><th style=text-align:left>Model</th><th style=text-align:center>Ming-lite-omni</th><th style=text-align:center>Qwen2.5-VL-7B-Instruct</th></tr></thead><tbody><tr><td style=text-align:left>ChartQA_TEST</td><td style=text-align:center>85.1</td><td style=text-align:center><b>87.3</b></td></tr><tr><td style=text-align:left>DocVQA_TEST</td><td style=text-align:center>93</td><td style=text-align:center><b>95.7</b></td></tr><tr><td style=text-align:left>OCRBenchV2_en/zh</td><td style=text-align:center>53.3/52</td><td style=text-align:center><b>56.3/57.2</b></td></tr><tr><td style=text-align:left>OmniDocBenchâ†“</td><td style=text-align:center>34/<b>34.4</b></td><td style=text-align:center><b>30.8</b>/39.8</td></tr><tr><td style=text-align:left>TextVQA_VAL</td><td style=text-align:center>82.8</td><td style=text-align:center><b>84.9</b></td></tr></tbody></table></div><h3 id=gui>GUI<a hidden class=anchor aria-hidden=true href=#gui>#</a></h3><div align=center><table><thead><tr><th style=text-align:left>Model</th><th style=text-align:center>Ming-lite-omni</th><th style=text-align:center>InternVL3 8B</th><th style=text-align:center>Qwen2.5-VL-7B-Instruct</th></tr></thead><tbody><tr><td style=text-align:left>ScreenSpot</td><td style=text-align:center><b>82.1</b></td><td style=text-align:center>79.5</td><td style=text-align:center>78.9*</td></tr><tr><td style=text-align:left>ScreenSpot-V2</td><td style=text-align:center><b>84.1</b></td><td style=text-align:center>81.4</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>AITZ(EM)</td><td style=text-align:center><b>66.6</b></td><td style=text-align:center>-</td><td style=text-align:center>57.6*</td></tr></tbody></table></div>Note: * denotes the reproduced results.<h3 id=unified-generation-benchmark>Unified Generation Benchmark<a hidden class=anchor aria-hidden=true href=#unified-generation-benchmark>#</a></h3><div align=center><table><thead><tr><th style=text-align:left>Model</th><th style=text-align:center>single_object</th><th style=text-align:center>two_object</th><th style=text-align:center>counting</th><th style=text-align:center>colors</th><th style=text-align:center>position</th><th style=text-align:center>color_attr</th><th style=text-align:center>GENEVAL</th><th style=text-align:center>DPGBench</th><th style=text-align:center>FIDâ†“</th></tr></thead><tbody><tr><td style=text-align:left>Ming-lite-omni</td><td style=text-align:center><strong>0.9875</strong></td><td style=text-align:center><strong>0.7727</strong></td><td style=text-align:center><strong>0.6812</strong></td><td style=text-align:center>0.7872</td><td style=text-align:center>0.31</td><td style=text-align:center>0.29</td><td style=text-align:center><strong>0.64</strong></td><td style=text-align:center>81.72</td><td style=text-align:center><strong>4.85</strong></td></tr><tr><td style=text-align:left>Metaquery-XL</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>0.61</td><td style=text-align:center><strong>82.05</strong></td><td style=text-align:center>6.02</td></tr><tr><td style=text-align:left>SDv2.1</td><td style=text-align:center>0.98</td><td style=text-align:center>0.51</td><td style=text-align:center>0.44</td><td style=text-align:center><strong>0.85</strong></td><td style=text-align:center>0.07</td><td style=text-align:center>0.17</td><td style=text-align:center>0.50</td><td style=text-align:center>68.09</td><td style=text-align:center>26.96</td></tr><tr><td style=text-align:left>Emu3-Gen</td><td style=text-align:center>0.98</td><td style=text-align:center>0.71</td><td style=text-align:center>0.34</td><td style=text-align:center>0.81</td><td style=text-align:center>0.17</td><td style=text-align:center>0.21</td><td style=text-align:center>0.54</td><td style=text-align:center>80.60</td><td style=text-align:center>-</td></tr><tr><td style=text-align:left>SDXL</td><td style=text-align:center>0.98</td><td style=text-align:center>0.74</td><td style=text-align:center>0.39</td><td style=text-align:center><strong>0.85</strong></td><td style=text-align:center>0.15</td><td style=text-align:center>0.23</td><td style=text-align:center>0.55</td><td style=text-align:center>74.65</td><td style=text-align:center>8.76</td></tr><tr><td style=text-align:left>Janus</td><td style=text-align:center>0.97</td><td style=text-align:center>0.68</td><td style=text-align:center>0.30</td><td style=text-align:center>0.84</td><td style=text-align:center><strong>0.46</strong></td><td style=text-align:center><strong>0.42</strong></td><td style=text-align:center>0.61</td><td style=text-align:center>79.68</td><td style=text-align:center>10.10</td></tr><tr><td style=text-align:left>JanusFlow</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>-</td><td style=text-align:center>0.63</td><td style=text-align:center>80.09</td><td style=text-align:center>9.51</td></tr></tbody></table></div><p>Please refer to our technical report for more comprehensive evaluation results.</p><h2 id=æ¨¡å‹ä¸‹è½½>æ¨¡å‹ä¸‹è½½<a hidden class=anchor aria-hidden=true href=#æ¨¡å‹ä¸‹è½½>#</a></h2><p>æ‚¨å¯ä»¥ä» Huggingface å’Œ ModelScope ä¸¤ä¸ªå¹³å°ä¸‹è½½æ¨¡å‹ã€‚</p><div align=center><table><thead><tr><th style=text-align:left><strong>æ¨¡å‹</strong></th><th style=text-align:center><strong>è¾“å…¥æ¨¡æ€</strong></th><th style=text-align:center><strong>è¾“å‡ºæ¨¡æ€</strong></th><th style=text-align:center><strong>ä¸‹è½½åœ°å€</strong></th></tr></thead><tbody><tr><td style=text-align:left>Ming-Lite-Omni</td><td style=text-align:center>å›¾åƒã€æ–‡æœ¬ã€è§†é¢‘ã€éŸ³é¢‘</td><td style=text-align:center>å›¾åƒã€æ–‡æœ¬ã€éŸ³é¢‘</td><td style=text-align:center><a href=https://huggingface.co/inclusionAI/Ming-Lite-Omni>ğŸ¤— HuggingFace</a><br><a href=https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni>ğŸ¤– ModelScope</a></td></tr></tbody></table></div><p>å¦‚æœæ‚¨ä½äºä¸­å›½å¤§é™†ï¼Œæˆ‘ä»¬å¼ºçƒˆå»ºè®®æ‚¨ä» ğŸ¤– <a href=https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni>ModelScope</a> ä¸‹è½½æ¨¡å‹ã€‚</p><h2 id=ç¯å¢ƒå‡†å¤‡>ç¯å¢ƒå‡†å¤‡<a hidden class=anchor aria-hidden=true href=#ç¯å¢ƒå‡†å¤‡>#</a></h2><h3 id=installation-with-pip>Installation with pip<a hidden class=anchor aria-hidden=true href=#installation-with-pip>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>pip install -r requirements.txt
</span></span><span class=line><span class=cl><span class=c1># for python 3.10</span>
</span></span><span class=line><span class=cl>pip install data/matcha_tts-0.0.5.1-cp310-cp310-linux_x86_64.whl 
</span></span><span class=line><span class=cl><span class=c1># for python 3.8 </span>
</span></span><span class=line><span class=cl><span class=c1># pip install data/matcha_tts-0.0.5.1-cp38-cp38-linux_x86_64.whl</span>
</span></span><span class=line><span class=cl>pip install <span class=nv>diffusers</span><span class=o>==</span>0.33.0
</span></span><span class=line><span class=cl>pip install nvidia-cublas-cu12<span class=o>==</span>12.4.5.8  <span class=c1># for H20 GPU</span>
</span></span></code></pre></div><h3 id=installation-with-docker>Installation with docker<a hidden class=anchor aria-hidden=true href=#installation-with-docker>#</a></h3><p>You can also initialize the environment by building the docker image. First clone this repository:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>git clone --depth <span class=m>1</span> https://github.com/inclusionAI/Ming.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> Ming
</span></span></code></pre></div><p>Then build the docker image with the provided Dockerfile in <code>docker/docker-py310-cu121</code>. This step might take a while:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>docker build -t ming:py310-cu121 docker/docker-py310-cu121
</span></span></code></pre></div><p>At last, start the container with the current repo directory mounted:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>docker run -it --gpus all -v <span class=s2>&#34;</span><span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span><span class=s2>&#34;</span>:/workspace/Ming ming:py310-cu121 ming:py310-cu121 /bin/bash
</span></span></code></pre></div><p>You can run the model with python interface. You may download the huggingface model in the repo directory first (<code>.../Ming/</code>) or mount the downloaded model path when starting the container.</p><h2 id=ä½¿ç”¨æ ·ä¾‹>ä½¿ç”¨æ ·ä¾‹<a hidden class=anchor aria-hidden=true href=#ä½¿ç”¨æ ·ä¾‹>#</a></h2><p>We provide a step-by-step running example:</p><p>Step 1 - Download the source code</p><pre tabindex=0><code>git clone https://github.com/inclusionAI/Ming.git 
cd Ming
</code></pre><p>Step 2 - Download the model weights and create a soft link to the source code directory</p><p>Download our model following <a href=/zh/blog/ming-omni/#model-downloads>Model Downloads</a></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>mkdir inclusionAI 
</span></span><span class=line><span class=cl>ln -s /path/to/inclusionAI/Ming-Lite-Omni inclusionAI/Ming-Lite-Omni
</span></span></code></pre></div><p>Step 3 - Enter the code directory, you can refer to the following codes to run the Ming-Lite-Omni model.</p><pre tabindex=0><code>jupyter notebook cookbook.ipynb
</code></pre><p>We also provide a simple example on the usage of this repo. For detailed usage, please refer to <a href=cookbook.ipynb>cookbook.ipynb</a>.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoProcessor</span><span class=p>,</span> <span class=n>GenerationConfig</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>modeling_bailingmm</span> <span class=kn>import</span> <span class=n>BailingMMNativeForConditionalGeneration</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># load model</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>BailingMMNativeForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;inclusionAI/Ming-Lite-Omni&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>low_cpu_mem_usage</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># build processor</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>AutoProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;inclusionAI/Ming-Lite-Omni&#34;</span><span class=p>,</span> <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># qa</span>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;HUMAN&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;è¯·è¯¦ç»†ä»‹ç»é¹¦é¹‰çš„ç”Ÿæ´»ä¹ æ€§ã€‚&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=p>},</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. Format inputs using chat template</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>messages</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. Extract vision/audio data</span>
</span></span><span class=line><span class=cl><span class=n>image_inputs</span><span class=p>,</span> <span class=n>video_inputs</span><span class=p>,</span> <span class=n>audio_inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>process_vision_info</span><span class=p>(</span><span class=n>messages</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. Prepare tensor inputs</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span><span class=o>=</span><span class=p>[</span><span class=n>text</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>images</span><span class=o>=</span><span class=n>image_inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>videos</span><span class=o>=</span><span class=n>video_inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>audios</span><span class=o>=</span><span class=n>audio_inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>inputs</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>k</span> <span class=ow>in</span> <span class=n>inputs</span><span class=o>.</span><span class=n>keys</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>k</span> <span class=o>==</span> <span class=s2>&#34;pixel_values&#34;</span> <span class=ow>or</span> <span class=n>k</span> <span class=o>==</span> <span class=s2>&#34;pixel_values_videos&#34;</span> <span class=ow>or</span> <span class=n>k</span> <span class=o>==</span> <span class=s2>&#34;audio_feats&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>inputs</span><span class=p>[</span><span class=n>k</span><span class=p>]</span> <span class=o>=</span> <span class=n>inputs</span><span class=p>[</span><span class=n>k</span><span class=p>]</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. Configure generation</span>
</span></span><span class=line><span class=cl><span class=n>generation_config</span> <span class=o>=</span> <span class=n>GenerationConfig</span><span class=o>.</span><span class=n>from_dict</span><span class=p>({</span><span class=s1>&#39;no_repeat_ngram_size&#39;</span><span class=p>:</span> <span class=mi>10</span><span class=p>})</span>
</span></span><span class=line><span class=cl><span class=n>generated_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=o>**</span><span class=n>inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>use_cache</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>eos_token_id</span><span class=o>=</span><span class=n>processor</span><span class=o>.</span><span class=n>gen_terminator</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>generation_config</span><span class=o>=</span><span class=n>generation_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>generated_ids_trimmed</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>out_ids</span><span class=p>[</span><span class=nb>len</span><span class=p>(</span><span class=n>in_ids</span><span class=p>):]</span> <span class=k>for</span> <span class=n>in_ids</span><span class=p>,</span> <span class=n>out_ids</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>inputs</span><span class=o>.</span><span class=n>input_ids</span><span class=p>,</span> <span class=n>generated_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. Decode output</span>
</span></span><span class=line><span class=cl><span class=n>output_text</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>generated_ids_trimmed</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>clean_up_tokenization_spaces</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>output_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Output:</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># é¹¦é¹‰æ˜¯ä¸€ç§éå¸¸èªæ˜å’Œç¤¾äº¤æ€§å¼ºçš„é¸Ÿç±»ï¼Œå®ƒä»¬çš„ç”Ÿæ´»ä¹ æ€§éå¸¸ä¸°å¯Œå’Œæœ‰è¶£ã€‚ä»¥ä¸‹æ˜¯ä¸€äº›å…³äºé¹¦é¹‰ç”Ÿæ´»ä¹ æ€§çš„è¯¦ç»†ä»‹ç»ï¼š</span>
</span></span><span class=line><span class=cl><span class=c1># ### 1. **æ –æ¯åœ°**</span>
</span></span><span class=line><span class=cl><span class=c1># é¹¦é¹‰ä¸»è¦åˆ†å¸ƒåœ¨çƒ­å¸¦å’Œäºšçƒ­å¸¦åœ°åŒºï¼ŒåŒ…æ‹¬éæ´²ã€äºšæ´²ã€æ¾³å¤§åˆ©äºšå’Œå—ç¾æ´²ã€‚å®ƒä»¬é€šå¸¸ç”Ÿæ´»åœ¨æ£®æ—ã€è‰åŸã€æ²™æ¼ å’ŒåŸå¸‚ç¯å¢ƒä¸­ã€‚ä¸åŒç§ç±»çš„é¹¦é¹‰å¯¹æ –æ¯åœ°çš„è¦æ±‚æœ‰æ‰€ä¸åŒï¼Œä½†å¤§å¤šæ•°é¹¦é¹‰å–œæ¬¢æœ‰ä¸°å¯Œæ¤è¢«å’Œæ°´æºçš„åœ°æ–¹ã€‚</span>
</span></span><span class=line><span class=cl><span class=c1># ### 2. **é¥®é£Ÿ**</span>
</span></span><span class=line><span class=cl><span class=c1># é¹¦é¹‰æ˜¯æ‚é£Ÿæ€§åŠ¨ç‰©ï¼Œå®ƒä»¬çš„é¥®é£Ÿéå¸¸å¤šæ ·åŒ–ã€‚å®ƒä»¬çš„é£Ÿç‰©åŒ…æ‹¬ç§å­ã€åšæœã€æ°´æœã€è”¬èœã€èŠ±èœœå’Œæ˜†è™«ã€‚é¹¦é¹‰çš„å–™éå¸¸å¼ºå£®ï¼Œèƒ½å¤Ÿè½»æ¾åœ°æ‰“å¼€åšç¡¬çš„æœå£³å’Œåšæœã€‚ä¸€äº›é¹¦é¹‰è¿˜ä¼šåƒæ³¥åœŸæˆ–æ²™å­ï¼Œä»¥å¸®åŠ©æ¶ˆåŒ–å’Œè¡¥å……çŸ¿ç‰©è´¨ã€‚</span>
</span></span><span class=line><span class=cl><span class=c1># ......</span>
</span></span></code></pre></div><p>Note: We test the examples on hardware of NVIDIA H800-80GB/H20-96G with CUDA 12.4. Loading inclusionAI/Ming-Lite-Omni in bfloat16 takes about 62G GPU memory.</p><h2 id=è®¸å¯ä¸æ³•å¾‹å£°æ˜>è®¸å¯ä¸æ³•å¾‹å£°æ˜<a hidden class=anchor aria-hidden=true href=#è®¸å¯ä¸æ³•å¾‹å£°æ˜>#</a></h2><p>æœ¬ä»£ç ä»“åº“éµå¾ª <a href=./LICENSE>MIT è®¸å¯è¯</a>ï¼Œæ³•å¾‹å£°æ˜è§é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„ <a href=./LEGAL.md>LEGAL.md æ–‡ä»¶</a>ã€‚</p><h2 id=å¼•ç”¨>å¼•ç”¨<a hidden class=anchor aria-hidden=true href=#å¼•ç”¨>#</a></h2><p>å¦‚æœæ‚¨è§‰å¾—æˆ‘ä»¬çš„å·¥ä½œå¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œæ¬¢è¿å¼•ç”¨ã€‚</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bibtex data-lang=bibtex><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nc>@misc</span><span class=p>{</span><span class=nl>Mingomni2025</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>title</span>  <span class=p>=</span> <span class=s>{Ming-Omni: A Unified Multimodal Model for Perception and Generation}</span><span class=p>,</span> 
</span></span><span class=line><span class=cl>      <span class=na>author</span> <span class=p>=</span> <span class=s>{Inclusion AI}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>year</span> <span class=p>=</span> <span class=s>{2025}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>eprint</span> <span class=p>=</span> <span class=s>{2506.09344}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>archivePrefix</span> <span class=p>=</span> <span class=s>{arXiv}</span><span class=p>,</span>
</span></span><span class=line><span class=cl>      <span class=na>url</span> <span class=p>=</span> <span class=s>{https://arxiv.org/abs/2506.09344}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://inclusionai.github.io/zh/>INCLUSION AI</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 8" fill="currentColor"><path d="M12 8H0l6-8z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="å¤åˆ¶";function s(){t.innerHTML="å·²å¤åˆ¶ï¼",setTimeout(()=>{t.innerHTML="å¤åˆ¶"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>