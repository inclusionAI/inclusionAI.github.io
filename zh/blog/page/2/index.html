<!doctype html><html lang=zh dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Blog | INCLUSION AI</title><meta name=keywords content><meta name=description content="Blog - INCLUSION AI"><meta name=author content="inclusionAI, Ant Group"><link rel=canonical href=https://inclusionai.github.io/zh/blog/><link crossorigin=anonymous href=/assets/css/stylesheet.fa92d8da4b04eca0dd3a888f432d2e4fabc3dec8bebb65e348f9ce26d866c08e.css integrity="sha256-+pLY2ksE7KDdOoiPQy0uT6vD3si+u2XjSPnOJthmwI4=" rel="preload stylesheet" as=style><link rel=icon href=https://inclusionai.github.io/favicon.png><link rel=apple-touch-icon href=https://inclusionai.github.io/favicon.png><link rel=manifest href=https://inclusionai.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate type=application/rss+xml href=https://inclusionai.github.io/zh/blog/index.xml><link rel=alternate hreflang=en href=https://inclusionai.github.io/blog/><link rel=alternate hreflang=zh href=https://inclusionai.github.io/zh/blog/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.e9080c0a180dc80cf80d5fef7c857effb14f65c998e22134feb9896034b1b81a.js integrity="sha256-6QgMChgNyAz4DV/vfIV+/7FPZcmY4iE0/rmJYDSxuBo="></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90",{anonymize_ip:!1})}</script><meta property="og:title" content="Blog"><meta property="og:description" content="inclusionAI"><meta property="og:type" content="website"><meta property="og:url" content="https://inclusionai.github.io/zh/blog/"><meta property="og:image" content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="og:site_name" content="inclusionAI"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Blog"><meta name=twitter:description content="inclusionAI"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://inclusionai.github.io/zh/blog/"}]}</script></head><body class=list id=top><script>const hasHeaderBg=!0</script><header class=header><div class="nav-container nav-background"><nav class=nav><div class=logo><a href=/ accesskey=h title="inclusionAI (Alt + H)"><img src=https://inclusionai.github.io/img/logo_head.png alt aria-label=logo height=50></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://github.com/inclusionAI title="Try Ling & Ming"><span>Try Ling & Ming</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container><div class=hero-background style="background:linear-gradient(-225deg,#2CD8D5 0%,#6B8DD6 48%,#8E37D7 100%)"></div><div class="hero text-light"><h1 class=post-title>Blog<sup class=title-translation>&nbsp;&nbsp;[<ul class=i18n_list><li><a href=https://inclusionai.github.io/blog/>English</a></li></ul>]</sup></h1></div></div><main class=main><article class=post-entry><header class=entry-header><h2>Ming-Lite-Uni：自然多模态交互统一架构的进展</h2></header><div class=entry-content><p>GITHUB 📑 Technical Report｜🤗 Hugging Face｜🤖 ModelScope 简介 Ming-Lite-Uni 是一个开源的多模态框架，包含一个全新设计的统一视觉生成器，以及一个原生多模态自回归模型，用于整合视觉与语言能力。
本项目提供了集成 MetaQueries 与 M2-omni 框架的开源实现，并引入了创新性的多尺度可学习Token机制与多尺度表示对齐策略。Ming-Lite-Uni 利用固定的MLLM与可训练的扩散模型，使原生多模态AR模型不仅支持文本生成图像（text-to-image），还支持基于指令的图像编辑，从而扩展其功能，不再局限于视觉理解。实验结果表明，Ming-Lite-Uni 具备强大的性能表现，并在交互体验上展现出高度流畅性。目前该项目处于alpha阶段，将持续优化中。
感谢大家的支持与关注！我们正在稳步推进项目，并取得了良好进展，更多更新即将到来，敬请期待！
📌 更新日志 [2025.05.03] 🔥 我们的 技术报告 已在 arXiv 发布 [2025.05.03] 🔥 Ming-Lite-Uni 首个版本正式开源 为什么重要？ Ming-Lite-Uni 的统一架构克服了传统方法的根本性局限：
传统方法 Ming-Lite-Uni 的优势 模块化流程
（如 CLIP/SigLIP + 扩散模型） 端到端统一模型
理解与生成无缝融合 离散Token自回归
（视觉定位能力有限） 连续Token空间
原生支持细粒度视觉概念 固定分辨率处理
（上采样会产生伪影） 多尺度自适应
各分辨率下均保持一致的画质 编辑流程分离
（需要手动对齐） 对话驱动控制
自然语言指导像素级编辑 理解瓶颈
（视觉语义错位） 联合表示学习
理解与生成能力相互增强 核心增强点 统一的视觉理解与生成架构：Ming-Lite-Uni 在 OpenCompass 榜单中理解得分达 69.7，优于 DeepSeek-VL2 (66.4)；同时在 GenEval 图像生成基准上取得 0....</p></div><footer class=entry-footer><span title='2025-05-07 00:00:03 +0800 +0800'>2025年5月7日</span>&nbsp;·&nbsp;3 分钟&nbsp;·&nbsp;489 字&nbsp;·&nbsp;inclusionAI, Ant Group</footer><a class=entry-link aria-label="post link to Ming-Lite-Uni：自然多模态交互统一架构的进展" href=https://inclusionai.github.io/zh/blog/ming-lite-uni/></a></article><article class=post-entry><header class=entry-header><h2>Ming-Lite-Omni-Preview: MOE架构的多模态大模型</h2></header><div class=entry-content><p>GITHUB 🤗 Hugging Face | 🤖 ModelScope
简介 Ming-Lite-Omni-Preview 构建自 Ling-Lite，它是一个 MoE（专家混合）模型，能够感知文本、图像、音频和视频等多种模态，并以流式方式生成文本和自然语音。 为了更自然地处理多模态输入，我们对 Ling-Lite 进行了增强，为每种模态引入了专用路由模块。 因此，Ming-Omni 在处理多模态信息方面表现优异，并具有很强的可扩展性。
主要特性 Omni and Novel MoE Architecture: 一种基于专家混合（MoE）的创新型 Omni 架构，在多个多模态评测中取得了领先性能。
Video understanding: 支持视觉 Token 的 KV-Cache 动态压缩机制，既能理解数小时的长视频，也能对几秒钟的短视频进行精细分析。
Natural Speech Generation and Fine-grained Voice Dialogue: 支持端到端对话中的方言理解与生成，具备一次性语音克隆能力，并通过音频分词器压缩提升语调表现力。
评测结果 Image benchmark Benchmarks Ming-Lite-Omni-Preview Qwen2.5-VL-7B-Instruct InternVL2.5-8B-MPO AI2D 83.84 83.9 84.5 HallusionBench 54.68 51.9 51.7 MMBench_TEST_V11 79.63 84.3 82.0 MMMU 57.0 58.6 54.8 MMStar 62.0 63.9 65.2 MMVet 73.6 67....</p></div><footer class=entry-footer><span title='2025-05-05 00:00:03 +0800 +0800'>2025年5月5日</span>&nbsp;·&nbsp;5 分钟&nbsp;·&nbsp;944 字&nbsp;·&nbsp;inclusionAI, Ant Group</footer><a class=entry-link aria-label="post link to Ming-Lite-Omni-Preview: MOE架构的多模态大模型" href=https://inclusionai.github.io/zh/blog/ming-lite-omni-preview/></a></article><footer class=page-footer><nav class=pagination><a class=prev href=https://inclusionai.github.io/zh/blog/>«&nbsp;上一页&nbsp;</a></nav></footer></main><footer class=footer><span>&copy; 2025 <a href=https://inclusionai.github.io/zh/>INCLUSION AI</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 8" fill="currentcolor"><path d="M12 8H0l6-8z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script></body></html>