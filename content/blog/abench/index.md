---
title: "ABench: An Evolving Open-Source Benchmark"
date: 2025-07-08T00:00:03+08:00
weight: 1
math: true
# search_hidden: false # to hide from search page
show_reading_time: true
show_bread_crumbs: true
show_post_nav_links: false # the prev/next after the content
show_code_copy_buttons: true
show_word_count: true
---

 {{< button href="https://github.com/inclusionAI/ABench" label="GITHUB" external=true >}} 

## ðŸŒŸ Overview

**ABench** is an evolving open-source benchmark suite designed to rigorously evaluate and enhance Large Language Models (LLMs) on **complex cross-domain tasks**. By targeting current model weaknesses, ABench provides systematic challenges in **high-difficulty specialized domains**, including physics, actuarial science, logical reasoning, law, and psychology.

## ðŸŽ¯ Core Objectives
1.  **Address Evaluation Gaps**: Design high-differentiation assessment tasks targeting **underperforming question types**
2.  **Establish Unified Standards**: Create **reliable, comparable benchmarks** for multi-domain LLM evaluation
3.  **Expand Capability Boundaries**: Drive continuous optimization of knowledge systems and reasoning mechanisms through challenging innovative problems

## ðŸ“Š Dataset Release Status

| Domain         | Description                                                                                                      | Status                          |
|----------------|------------------------------------------------------------------------------------------------------------------|---------------------------------|
| **Physics**    | 500 university/competition-level physics problems (400 static + 100 dynamic parametric variants) covering 10+ fields from classical mechanics to modern physics | [âœ… Released](https://github.com/inclusionAI/ABench/blob/main/Physics/README.md) |
| **Actuary**    | Curated actuarial exam problems covering core topics: probability statistics, financial mathematics, life/non-life insurance, actuarial models, and risk management | [âœ… Released](https://github.com/inclusionAI/ABench/blob/main/Actuary/README.md) |
| **Logic**      | High-differentiation logical reasoning problems from authoritative tests (LSAT/GMAT/GRE/SBI/Chinese Civil Service Exam) | ðŸ”„ In Preparation               |
| **Psychology** | Psychological case studies and research questions (objective/subjective) evaluating understanding of human behavior and theories | ðŸ”„ In Preparation               |
| **Law**        | Authoritative judicial exam materials covering core legal domains: criminal/civil/administrative/procedural/international law | ðŸ”„ In Preparation               |