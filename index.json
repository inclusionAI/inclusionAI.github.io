[{"summary":"\u003ch1 id=\"using-ring-1t-with-claude-code-via-zenmux\"\u003eUsing Ring 1T with Claude Code via ZenMux\u003c/h1\u003e\n\u003ch2 id=\"what-is-ring-1t\"\u003eWhat is Ring 1T?\u003c/h2\u003e\n\u003cp\u003eRing 1T is a powerful open-source reasoning model designed for complex problem-solving and advanced coding tasks. It\u0026rsquo;s built on the Ling 2.0 architecture with impressive capabilities:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eScale\u003c/strong\u003e: 1 trillion total parameters with 50 billion activated parameters\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eContext\u003c/strong\u003e: Supports up to 128K tokens context window\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTraining\u003c/strong\u003e: Enhanced through large-scale verifiable reward reinforcement learning (RLVR)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStrengths\u003c/strong\u003e: Excels at deep reasoning, natural language inference, and sophisticated code generation\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eRing 1T represents the latest advancement in MoE (Mixture of Experts) architecture scaling, leveraging the icepop reinforcement learning stabilization method and the ASystem framework to deliver exceptional reasoning performance.\u003c/p\u003e","title":"Using Ring 1T with Claude Code via ZenMux"},{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/inclusionAI/Ming\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e  \u003ca href=\"https://arxiv.org/abs/2510.24821\" class=\"btn external\" target=\"_blank\"\u003eARXIV\u003c/a\u003e ğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI/Ming-flash-omni-Preview\"\u003eHugging Face\u003c/a\u003eï½œ ğŸ¤– \u003ca href=\"https://www.modelscope.cn/models/inclusionAI/Ming-flash-omni-Preview\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOmnimodal Ming-omni series update! \u003cstrong\u003eMing-flash-omni-Preview\u003c/strong\u003e is the \u003cstrong\u003efirst open-source omnimodal large model\u003c/strong\u003e with a parameter scale reaching the hundred billion-Scale level. Based on Ling 2.0\u0026rsquo;s sparse MoE architecture, Ming-flash-omni-Preview has a total of \u003cstrong\u003e103B parameters\u003c/strong\u003e with \u003cstrong\u003e9B activated\u003c/strong\u003e. Compared to the previous version Ming-lite-omni-1.5, Ming-flash-omni-Preview has improved in both omnimodal understanding and generation capabilities. The overall performance across various modalities has reached a \u003cstrong\u003eleading level among open-source omnimodal models\u003c/strong\u003e, with particularly outstanding performance in \u003cstrong\u003econtrollable image generation, streaming video understanding, and speech recognition\u003c/strong\u003e.\u003c/p\u003e","title":"Ming-flash-omni-Preview: A Sparse, Unified Architecture for Multimodal Perception and Generation"},{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/inclusionAI/Ming-UniAudio\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e ğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI/Ming-UniAudio-16B-A3B\"\u003eHugging Face\u003c/a\u003eï½œ ğŸ¤– \u003ca href=\"https://modelscope.cn/models/inclusionAI/Ming-UniAudio-16B-A3B\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"the-introduction-video-of-ming-uniaudio\"\u003eThe Introduction Video of Ming-UniAudio\u003c/h2\u003e\n\u003cp\u003e\u003cvideo src=\"https://gw.alipayobjects.com/v/huamei_xb4oy7/afts/video/oVK9TY4AEBwAAAAAgWAAAAgADmiGAQFr\" width=\"1024px\" height=\"660px\" controls autoplay muted playsinline\u003e\u003c/video\u003e\u003c/p\u003e\n\u003ch2 id=\"audio-edit-demo\"\u003eAudio Edit Demo\u003c/h2\u003e\n\u003cp\u003e\u003cvideo src=\"https://gw.alipayobjects.com/v/huamei_xb4oy7/afts/video/-FcPSYBMkDMAAAAAgoAAAAgADmiGAQFr\" width=\"1024px\" height=\"660px\" controls autoplay muted playsinline\u003e\u003c/video\u003e\u003c/p\u003e\n\u003ch2 id=\"editing-tasks-video-demos\"\u003eEditing Tasks Video demos\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth style=\"text-align: center\"\u003e\u003c/th\u003e\n          \u003cth style=\"text-align: center\"\u003e\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cvideo src=\"https://gw.alipayobjects.com/v/huamei_xb4oy7/afts/video/xGZ4R5Tg09MAAAAAgGAAAAgADmiGAQFr\" controls width=\"100%\"\u003e\u003c/video\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cvideo src=\"https://gw.alipayobjects.com/v/huamei_xb4oy7/afts/video/QORqR68bUPYAAAAAgHAAAAgADmiGAQFr\" controls width=\"100%\"\u003e\u003c/video\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cvideo src=\"https://gw.alipayobjects.com/v/huamei_xb4oy7/afts/video/MHIuTbHoLVoAAAAAgGAAAAgADmiGAQFr\" controls width=\"100%\"\u003e\u003c/video\u003e\u003c/td\u003e\n          \u003ctd style=\"text-align: center\"\u003e\u003cvideo src=\"https://gw.alipayobjects.com/v/huamei_xb4oy7/afts/video/k6NERayHTS8AAAAAgGAAAAgADmiGAQFr\" controls width=\"100%\"\u003e\u003c/video\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003c!-- # Ming-UniVision: Joint Image Understanding and Generation via a Unified Continuous Tokenizer --\u003e\n\u003ch2 id=\"-technical-highlights\"\u003eğŸš€ Technical Highlights\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eFirst unified continuous speech tokenizer for both understanding and generation tasks:\u003c/strong\u003e \u003cstrong\u003eMingTok-Audio\u003c/strong\u003e is a unified continuous speech tokenizer MingTok-Audio based on a VAE framework with a causal Transformer architecture, the first continuous speech tokenizer to effectively integrate semantic and acoustic features, and enables a closed-loop system with LLMs through hierarchical feature representations, makes it suitable for both understanding and generation tasks.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFirst Speech LLM with unifed continuous tokenizer for both understanding and generation:\u003c/strong\u003e \u003cstrong\u003eMing-UniAudio\u003c/strong\u003e is an end-to-end unified speech language model with a single LLM backbone for both understanding and generation tasks, enhanced with a Diffusion Head to ensure high-fidelity speech synthesis.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFirst universal free-form speech editing model for semantic and acoustic tasks without temporal regime:\u003c/strong\u003e We introduce the first instruction-guided, free-form speech editing framework that supports comprehensive semantic and acoustic edits without requiring explicit edit regions, along with Ming-Freeform-Audio-Edit, the first open-source evaluation set for such tasks.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFirst benchmark for free-form speech editing:\u003c/strong\u003e We propose Audio-Edit-Benchmark, the first open-source free-form evaluation set comprising editing tasks of four semantic and five acoustic types, to evaluate the model\u0026rsquo;s editing performance.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"instruction-guided-free-form-speech-editing\"\u003eInstruction-Guided Free-Form Speech Editing\u003c/h2\u003e\n\u003ch3 id=\"semantic-editing---insert\"\u003eSemantic Editing - Insert\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n          \u003cth\u003eTarget Transcription\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003einsert \u0026lsquo;ç®€ç›´\u0026rsquo; after the character or word at index 8.\u003c/td\u003e\n          \u003ctd\u003eçœŸæ˜¯ä¸ªæµªæ¼«çš„é‚‚é€…å¯ä»¥è¯´æ˜¯è‹±é›„æ•‘ç¾äº†\u003c/td\u003e\n          \u003ctd\u003eçœŸæ˜¯ä¸ªæµªæ¼«çš„é‚‚é€…ç®€ç›´å¯ä»¥è¯´æ˜¯è‹±é›„æ•‘ç¾äº†\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/JdKpT5F_JtcAAAAASHAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/WfvQQKsB4dQAAAAAScAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003einsert \u0026lsquo;çœŸæ­£\u0026rsquo; before the character or word \u0026lsquo;å¥½\u0026rsquo;.\u003c/td\u003e\n          \u003ctd\u003eå°±æœ‰é“è€Œæ­£ç„‰å¯è°“å¥½å­¦ä¹Ÿå·²\u003c/td\u003e\n          \u003ctd\u003eå°±æœ‰é“è€Œæ­£ç„‰å¯è°“çœŸæ­£å¥½å­¦ä¹Ÿå·²\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/EQA0RrEZEy4AAAAASSAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/afDpSI_C_P0AAAAASmAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003einsert \u0026lsquo;clearly\u0026rsquo; before the character or word at index 8.\u003c/td\u003e\n          \u003ctd\u003eIts legal status in Trinidad was insufficient to preserve its ecological status.\u003c/td\u003e\n          \u003ctd\u003eIts legal status in Trinidad was insufficient clearly to preserve its ecological status.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/pNLORqb9lUcAAAAASLAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/UtbRRY_BLdgAAAAASTAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003einsert \u0026lsquo;successfully\u0026rsquo; after the character or word \u0026lsquo;profession\u0026rsquo;.\u003c/td\u003e\n          \u003ctd\u003ePreviously an attorney Korona left the profession to pursue a career in music.\u003c/td\u003e\n          \u003ctd\u003ePreviously an attorney Korona left the profession successfully to pursue a career in music.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/HJoKS4foKaQAAAAASYAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/H7YbQr6zTyEAAAAASpAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"semantic-editing---substitute\"\u003eSemantic Editing - Substitute\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n          \u003cth\u003eTarget Transcription\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003esubstitute \u0026lsquo;å¦ˆå¦ˆ\u0026rsquo; with \u0026lsquo;çˆ¸çˆ¸\u0026rsquo;.\u003c/td\u003e\n          \u003ctd\u003eæˆ‘æƒ³å¯¹äºå¦ˆå¦ˆæ¥è¯´ä¼šæ¯”ä»»ä½•ç¤¼ç‰©éƒ½è¦æ¸©æš–\u003c/td\u003e\n          \u003ctd\u003eæˆ‘æƒ³å¯¹äºçˆ¸çˆ¸æ¥è¯´ä¼šæ¯”ä»»ä½•ç¤¼ç‰©éƒ½è¦æ¸©æš–\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/8CQiSIZebqAAAAAATdAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/CtYrQq7gmmkAAAAAUgAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003esubstitute the characters or words from index 8 to index 10 with \u0026lsquo;äº”ä¸‡å…ƒ\u0026rsquo;.\u003c/td\u003e\n          \u003ctd\u003eå½“æ—¶æˆ‘æƒ³ç­‰ç­¹é½ä¸¤ä¸‡å…ƒè˜ç¤¼å°±é€å¥¹å¦ˆå›å®¶\u003c/td\u003e\n          \u003ctd\u003eå½“æ—¶æˆ‘æƒ³ç­‰ç­¹é½äº”ä¸‡å…ƒè˜ç¤¼å°±é€å¥¹å¦ˆå›å®¶\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/9N09RL4k5AoAAAAASEAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/-63tQ5FSxWoAAAAASAAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003esubstitute \u0026lsquo;get pictures off\u0026rsquo; with \u0026rsquo;transfer photos from\u0026rsquo;.\u003c/td\u003e\n          \u003ctd\u003eI\u0026rsquo;m trying to explain to my mother how to get pictures off her phone.\u003c/td\u003e\n          \u003ctd\u003eI\u0026rsquo;m trying to explain to my mother how to transfer photos from her phone.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Wur_RKhjsTkAAAAASGAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/x-PGQIC1dJsAAAAASTAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003esubstitute the words from index 8 to index 9 with \u0026lsquo;could become\u0026rsquo;.\u003c/td\u003e\n          \u003ctd\u003eConsidering the growth of human population insects might be the food of the future.\u003c/td\u003e\n          \u003ctd\u003eConsidering the growth of human population insects could become the food of the future.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Pu-_TY8088EAAAAASxAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/aVQ9SoLVfM0AAAAAS4AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"semantic-editing---delete\"\u003eSemantic Editing - Delete\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n          \u003cth\u003eTarget Transcription\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003edelete \u0026lsquo;æ¯”æ™®é€šçš„èŒ¶å¶è¦\u0026rsquo;.\u003c/td\u003e\n          \u003ctd\u003eèŠ±è‰èŒ¶çš„å£å‘³ä¸€èˆ¬æ¯”æ™®é€šçš„èŒ¶å¶è¦è‹¦ä¸€äº›\u003c/td\u003e\n          \u003ctd\u003eèŠ±è‰èŒ¶çš„å£å‘³ä¸€èˆ¬è‹¦ä¸€äº›\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/C1jQTKJCUSgAAAAASJAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Pl2CR4QVw2EAAAAARYAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003edelete the characters or words from index 11 to index 15.\u003c/td\u003e\n          \u003ctd\u003eæˆ‘åƒäº†ç‚¹ç‡•éº¦ç‰‡ç…é¸¡è›‹è¿˜å–äº†ç‚¹æ©™æ±\u003c/td\u003e\n          \u003ctd\u003eæˆ‘åƒäº†ç‚¹ç‡•éº¦ç‰‡ç…é¸¡è›‹æ±\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/txKrRLpnBH4AAAAASIAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/C5LvS67ATOEAAAAARjAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003edelete \u0026rsquo;times\u0026rsquo;.\u003c/td\u003e\n          \u003ctd\u003eThe classification of this gibbon has changed several times in the past few years.\u003c/td\u003e\n          \u003ctd\u003eThe classification of this gibbon has changed several in the past few years.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/M5h2TbiN37wAAAAATAAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/PxcTTrVjcrAAAAAAS4AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003edelete the characters or words from index 2 to index 6.\u003c/td\u003e\n          \u003ctd\u003eOn the second day the boy climbed to the top of a cliff near the camp\u003c/td\u003e\n          \u003ctd\u003eOn climbed to the top of a cliff near the camp\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/yHJ3Q54WNY4AAAAASCAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/EKtETaHIfPUAAAAARhAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"acoustic-editing---dialect-conversion\"\u003eAcoustic Editing - Dialect Conversion\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eChange the accent of the speech to Dongbei.\u003c/td\u003e\n          \u003ctd\u003eä¹‹åï¼Œä»–è€ƒå–å¯¼æ¸¸è¯ï¼Œæˆä¸ºæ‹±åŒ—å£å²¸ä¸­æ—…çš„å¯¼æ¸¸ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/RmuPT4u48BIAAAAATAAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/GcUzTLgBYYQAAAAAUTAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eChange the accent of the speech to Chengdu.\u003c/td\u003e\n          \u003ctd\u003eåªæœ‰å½“ç§‘æŠ€ä¸ºæœ¬åœ°ç¤¾ç¾¤åˆ›é€ ä»·å€¼çš„æ—¶å€™ï¼Œæ‰èƒ½çœŸæ­£æœ‰æ„ä¹‰ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Cd0GRauyLh8AAAAAUMAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/wGu6Q7fB96EAAAAAUyAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eChange the accent of the speech to Chengdu.\u003c/td\u003e\n          \u003ctd\u003eæˆ‘å¾—ç”¨å›æƒ³ä¸å¹»æƒ³è¡¥å……æˆ‘æ‰€ç¼ºå°‘çš„é¥®é£Ÿï¼Œå®‰æ…°æˆ‘æ‰€å¾—åˆ°çš„ç—›è‹¦ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/jnf2RKh_lskAAAAAURAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/N90aR4CNHy4AAAAAVSAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eChange the accent of the speech to Guangxi.\u003c/td\u003e\n          \u003ctd\u003eå…¨å›½æ¶æ€§è‚¿ç˜¤å‘ç—…ï¼ŒåŠæ­»äº¡ç¬¬ä¸€ä½çš„æ˜¯è‚ºç™Œã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/-X4eSpyIon4AAAAAVRAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/8CDxQq717cUAAAAAWKAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"acoustic-editing---speed\"\u003eAcoustic Editing - Speed\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadjusts the speed to 0.5.\u003c/td\u003e\n          \u003ctd\u003eæˆ‘ç”¨èƒ¸æŠµä½è½¦æŠŠï¼ŒæŒæ¡æ–¹å‘ï¼Œé€Ÿåº¦ä¸€ç‚¹ä¹Ÿä¸æ¯”åˆ«äººæ…¢ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/R9HrRKU4XJgAAAAAVPAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Z7rBRKF0VcoAAAAAc_AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadjusts the speed to 0.7.\u003c/td\u003e\n          \u003ctd\u003eThere is a growing body of case law on Bayh-Dole.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/MBcXTKBliGMAAAAASgAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/oh3UTIJzHysAAAAAUgAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadjusts the speed to 1.3.\u003c/td\u003e\n          \u003ctd\u003eCribb was born near Bristol but moved to London before starting professional fighting.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/D9lDQo0Zjz8AAAAAUBAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Kc2kTZ-Wh5IAAAAAT0AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadjusts the speed to 2.\u003c/td\u003e\n          \u003ctd\u003eåˆ‡å®å¸®åŠ©å›°éš¾ç¾¤ä¼—è§£å†³ç”Ÿäº§ç”Ÿæ´»ä¸­ï¼Œé‡åˆ°çš„å›°éš¾å’Œé—®é¢˜ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/PHbSSJZGnjEAAAAAUDAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/KmPERIhGVTIAAAAASjAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"acoustic-editing---pitch\"\u003eAcoustic Editing - Pitch\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eshifts the pitch by 3 steps.\u003c/td\u003e\n          \u003ctd\u003eå› ä¸ºå¤–é¢æœ‰æˆ˜äº‰ï¼Œå®¶é‡Œåˆæœ‰æˆ˜äº‰å¸¦æ¥çš„æ‚²ä¼¤å’ŒåŒ®ä¹ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/sA5dRL1s_pkAAAAAURAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/wMaHQaX_gZ4AAAAAVrAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eshifts the pitch by 5 steps.\u003c/td\u003e\n          \u003ctd\u003eè‡ªåŠ¨é©¾é©¶å°†å¤§å¹…æå‡å‡ºè¡Œå®‰å…¨ï¼Œæ•ˆç‡ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/q2-QTp1S49QAAAAATzAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/ar7qRrxbA-0AAAAAU_AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eshifts the pitch by -1 steps.\u003c/td\u003e\n          \u003ctd\u003eThe heart of the campus has a number of historic buildings.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/_2E0Q6STH2YAAAAASiAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/fwtWQaSWCeoAAAAATVAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eshifts the pitch by -1 steps.\u003c/td\u003e\n          \u003ctd\u003eStevenson is also the director of music ministries at Angeles Mesa Presbyterian Church.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/qFzmT7Q_LGIAAAAAVAAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/3lSvSLJcx9oAAAAAWjAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"acoustic-editing---volume\"\u003eAcoustic Editing - Volume\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadjusts the volume to 1.4.\u003c/td\u003e\n          \u003ctd\u003eA woman sits as she shows the designs she has made in the floor.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/IKI3Sq9VfrUAAAAAS7AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/ZipySrVXlRsAAAAAT6AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadjusts the volume to 1.6.\u003c/td\u003e\n          \u003ctd\u003eFor example, they both consist of predominately older, hence redder, stars.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/-STIR7ZWR4cAAAAAT6AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/YStPSoQ1o_MAAAAAVLAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadjusts the volume to 0.9.\u003c/td\u003e\n          \u003ctd\u003eä¼ç¾²çš„å„¿å­™ä»¬çœ‹è§ä¼ç¾²æ‰æ¥äº†é±¼ï¼Œä¹Ÿéƒ½æ¬¢æ¬¢å–œå–œè·‘æ¥é—®é•¿é—®çŸ­ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/n1qOS4vXT44AAAAAUnAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/DuTPR5fSJrwAAAAAWKAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadjusts the volume to 0.3.\u003c/td\u003e\n          \u003ctd\u003eä»–ä»¬è¿˜å‘Šè¯‰å·¨äººï¼Œé‚£åº§åŸå¸‚é‡Œç¾¤è‹±èŸèƒã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/3DgxTLQAwaQAAAAATuAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/qA3JSqPKPRkAAAAAU5AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"acoustic-editing---denoise\"\u003eAcoustic Editing - Denoise\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003edenoise the audio.\u003c/td\u003e\n          \u003ctd\u003eBe shape of example,before deriving this formula we explained what we mean by problems of this kind we now generalize these ideas for general binomial experiments.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/1OAFTqgJIwcAAAAAU5AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/0EAKT6Mi0KkAAAAAZ3AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003edenoise the audio.\u003c/td\u003e\n          \u003ctd\u003eSummoned to himself with firmness no surrender his superiors had also preached this saying it was the way of eternal honor his comrades were old.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/DfUMTKdSXL8AAAAAU5AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/89QhSLDv0-oAAAAAZrAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003edenoise the audio.\u003c/td\u003e\n          \u003ctd\u003eThere are people who travel long distances to assure my continued existence we have also seen the power of faith at work among us it was muscular but it wasn\u0026rsquo;t symmetrical.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/ROrmQJzxSHgAAAAAU5AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/niWWSLMGNeIAAAAAZxAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003edenoise the audio.\u003c/td\u003e\n          \u003ctd\u003eTheory eventually proved inexact the heavens refused to give up their weeping but what has been happening recently might be described as creeping mannerism clever.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/DJ-YR6aHUYIAAAAAU5AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/woakSZCLjzMAAAAAZxAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"acoustic-editing---background-music\"\u003eAcoustic Editing - Background Music\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadd rain to audio.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/74mRQJBHEDsAAAAASkAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/RxFHSZGgWgsAAAAAU_AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadd car sound to audio.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/37sbT4bQ95sAAAAARsAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/bUK1Qo4QxhwAAAAATbAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadd carefree music to audio.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/SYorQ6L3vSwAAAAAUMAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/c1rCSpdBOUYAAAAAYTAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eadd groovy music to audio.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/LNqDTKx-eq4AAAAARWAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/NfMfTaa1aDIAAAAASpAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"acoustic-editing---emotion-conversion\"\u003eAcoustic Editing - Emotion Conversion\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInstruction\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n          \u003cth\u003eBefore Edit\u003c/th\u003e\n          \u003cth\u003eSpeechedit Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003echange the emotion to happy mood.\u003c/td\u003e\n          \u003ctd\u003eæ¯”å°”æƒ³å†çœ‹å°ä¸»äººä¸€çœ¼ç„¶åèµ°è¿›æ£®æ—å®‰é™åœ°æ­»å»ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/EodrRIWu_ucAAAAASuAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/dO35RbVvSTIAAAAAVFAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003echange the emotion to happy mood.\u003c/td\u003e\n          \u003ctd\u003eä¸–ç•Œçˆ±çœ¼æ—¥æ˜¯æ¯å¹´åæœˆçš„ç¬¬äºŒä¸ªæ˜ŸæœŸå››ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Yf78Q7yF5YoAAAAASMAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/nlUUS5Jv3zcAAAAATVAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003echange the emotion to happy mood.\u003c/td\u003e\n          \u003ctd\u003eæˆ‘ä¼šç©å¾ˆå¤šæ¸¸æˆå‘¢å¬è¯´å¤šå–æ°´èƒ½æ²»ç™¾ç—…ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/5bCPTJ9cRswAAAAASWAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/LH_vTb1udC0AAAAAUZAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003echange the emotion to happy mood.\u003c/td\u003e\n          \u003ctd\u003eå»ºè®®æˆ´å£ç½©ç©ºæ°”è´¨é‡è½»åº¦æ±¡æŸ“ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/x1h0RpWyfooAAAAAR9AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/P1CQSpx5x_8AAAAATIAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"audio-understanding\"\u003eAudio Understanding\u003c/h2\u003e\n\u003ch3 id=\"chinese-and-english-asr\"\u003eChinese and English ASR\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInput\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/HgRPQI-yCT0AAAAASQAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003eå‘ƒå¾ˆä¹…æ²¡æœ‰çœ‹åˆ°çœ‹è¿‡å¦‚æ­¤ä¸å¸¦ä»·å€¼åˆ¤æ–­çš„ç”µå½±\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/jPUNTKLTwwMAAAAAaBAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003eæ¡ƒèŠ±åº„äººå¡”ä¿±ä¹éƒ¨æ˜¯ä½äºæ­å·å¸‚å¾·æ¸…å¿çš„ä¸€ä¸ªä¿±ä¹éƒ¨\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/lfRkQp3qH68AAAAAbDAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003ehe was excited and at the same time uneasy maybe the girl had already forgotten him\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/ROdTTobjQk4AAAAAaYAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003eit\u0026rsquo;s true that everything has its destiny but one day that destiny will be realized\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"dialect-understanding\"\u003eDialect Understanding\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInput\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/VMJDRb-I-poAAAAASkAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e[æ–¹è¨€-ç²¤è¯­] ä½ åšä¹œå˜¢å•Šç³»å’ªå””æƒ³å€¾åˆå•Šã€‚\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/kd0sRqfBceUAAAAARfAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e[æ–¹è¨€-ä¸Šæµ·è¯] é˜¿æ‹‰è€ƒè¯•è¿˜æ²¡å®šä¸‹æ¥å”»ã€‚\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/6JfkSJqSF5YAAAAARyAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e[æ–¹è¨€-é—½å—è¯­] å®è´è¾ƒæ—©ä¼‘å›°æ™šå®‰ã€‚\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/VY5oTKxs3LgAAAAASTAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003e[æ–¹è¨€-å·æ¸æ–¹è¨€] æˆ‘éš¾å—å¾—å¾ˆåˆ«ä¸ªéƒ½ç¡äº†ã€‚\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"context-asr\"\u003eContext ASR\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInput\u003c/th\u003e\n          \u003cth\u003ePrompt\u003c/th\u003e\n          \u003cth\u003eTranscription\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/kPmlSarKaTgAAAAAgBAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003ePlease recognize the language of this speech and transcribe it. Format: oral. This is an audio about Banking. This audio may contains the following words or phrases:Zelle,daily A C H transfer limit,cashier\u0026rsquo;s checks,transaction memos,F D I C regulations,cryptocurrency wallet,K Y C requirements.\u003c/td\u003e\n          \u003ctd\u003eHey Chris, you won\u0026rsquo;t believe what happened when I tried sending rent through Zelle yesterday. I hit some daily ACH transfer limit! My landlord\u0026rsquo;s insisting on cashier\u0026rsquo;s checks now. Remember how Sarah\u0026rsquo;s Venmo payment got flagged last month? The bank\u0026rsquo;s fraud detection system kept asking about transaction memos and \u0026lsquo;source of funds\u0026rsquo; verification. Honestly, these FDIC regulations around peer-to-peer payments are getting ridiculous. I had to provide three months of bank statements just to increase my wire transfer threshold. Oh, and don\u0026rsquo;t even get me started on cryptocurrency wallet KYC requirements.\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/A-j2QKPsWvAAAAAAgCAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003ePlease recognize the language of this speech and transcribe it. Format: oral. This is an audio about Banking. This audio may contains the following words or phrases:Priority Pass lounges,T S A Pre Check,rewards structure,bonus miles,Citibank\u0026rsquo;s Prestige Card,Visa Infinite,E M V chip security protocols,dynamic currency conversion.\u003c/td\u003e\n          \u003ctd\u003eSo listen, I finally canceled my Chase Sapphire Reserve last week. Remember how they touted those Priority Pass lounges and Luxury Hotel Collection benefits? Turns out I only used the T S A Pre Check credit once this whole year! The annual fee jumped to five hundred fifty dollars, plus they started requiring eighteen thousand points to waive it. My Amex Platinum isn\u0026rsquo;t any better that seven hundred dollar fee just hit, and their new rewards structure requires thirty thousand in annual spending for bonus miles. Oh, and get this Citibank\u0026rsquo;s Prestige Card now charges two hundred bucks for authorized users! Honestly, these Visa Infinite perks like concierge services and purchase protection sound fancy, but when do regular people actually use E M V chip security protocols or dynamic currency conversion?\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/6L8lRpfRvhoAAAAAgBAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003ePlease recognize the language of this speech and transcribe it. Format: oral. This is an audio about é…’åº—å¸¸æ—…å®¢è®¡åˆ’. This audio may contains the following words or phrases:è‡³æ‚¦å¤§ä½¿,é‡åº†æ¥ç¦å£«æ´²é™…,é…’å»Šå¾…é‡,ä¸‡è±ªæ—…äº«å®¶,é’›é‡‘ä¼šå‘˜.\u003c/td\u003e\n          \u003ctd\u003eè¯¶ï¼Ÿå°æï¼Œæˆ‘æœ€è¿‘åœ¨ç ”ç©¶IHGçš„ä¼šå‘˜ä½“ç³»ï¼Œè¿™ä¸ªâ€˜è‡³æ‚¦å¤§ä½¿â€™çš„è¾¾æ ‡æ¡ä»¶ä¹Ÿå¤ªè‹›åˆ»äº†å§ï¼â€˜ä¸‰ç™¾æƒç›Šâ€™é‡Œï¼Œæ´²é™…çš„è®¤å¯æˆ¿æ™šæ‰ç»™ä¸‰åæ™šã€‚ä½ è¯´ï¼Œä»–ä»¬å®¶çš„â€˜å…ˆè¡Œè€…ä»»åŠ¡â€™ç®—ä¸ç®—â€˜é‡Œç¨‹ç¢‘å¥–åŠ±â€™å•Šï¼Ÿå¯¹äº†ï¼Œæˆ‘ä¹‹å‰ç”¨ç§¯åˆ†å…‘æ¢é‡åº†æ¥ç¦å£«æ´²é™…çš„è¡Œæ”¿å¥—æˆ¿ï¼Œç¤¼å®¾éƒ¨å±…ç„¶æ²¡ç»™é…’å»Šå¾…é‡ï¼Œåè€Œç°é‡‘è®¢æˆ¿çš„å®¢äººèƒ½æ‹¿åˆ°åŒæ—©ã€‚ä¸‡è±ªæ—…äº«å®¶çš„â€˜é’›é‡‘ä¼šå‘˜â€™éƒ½èƒ½è‡ªåŠ¨åŒ¹é…å¥—æˆ¿å‡çº§åˆ¸ï¼ŒIHGè¿™ä¸ªåŠ¨æ€å®šä»·ç³»ç»ŸçœŸæ˜¯è®©äººå¤´å¤§ï¼\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/bwa5Trrt_8AAAAAAgBAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003ePlease recognize the language of this speech and transcribe it. Format: oral. This is an audio about æ±½è½¦è¡Œä¸š. This audio may contains the following words or phrases:æ±½è½¦ä¹‹å®¶æ›¹é›·,çŸ©é˜µå¼ L E D å¤§ç¯,å››åå…«ä¼è½»æ··ç³»ç»Ÿ,å¯å˜æ°”é—¨å‡ç¨‹æŠ€æœ¯,M B U X è¶…è”å±,Sportback,Allroad.\u003c/td\u003e\n          \u003ctd\u003eå˜¿ï¼Œè€æï¼Œä½ çœ‹åˆ°â€˜æ±½è½¦ä¹‹å®¶â€™æ›¹é›·å‘çš„æ–‡ç« æ²¡ï¼Ÿè¯´æ–°æ¬¾å¥¥è¿ªA3åŠ é•¿åˆ°å››ç±³å…­äº†ã€‚æ˜¨å„¿æˆ‘å»4Såº—è¯•é©¾ï¼Œé”€å”®è¯´è¿™è½¦é…äº†å•¥çŸ©é˜µå¼LEDå¤§ç¯ï¼Œè¿˜æœ‰å››åå…«ä¼è½»æ··ç³»ç»Ÿã€‚ä¸è¿‡ï¼Œå®é©¬1ç³»é‚£ä¸ªB48å‘åŠ¨æœºä¹Ÿæ”¹äº†â€˜å¯å˜æ°”é—¨å‡ç¨‹æŠ€æœ¯â€™ï¼Œå¥”é©°Açº§æ›´å¤¸å¼ ï¼Œç›´æ¥æŠŠMBUXè¶…è”å±å¡è¿›ç´§å‡‘è½¦é‡Œï¼è¦æˆ‘è¯´å•Šï¼Œç°åœ¨è½¦ä¼æç»†åˆ†å¸‚åœºçœŸå¤Ÿæ‹¼çš„ï¼å¬è¯´å¥¥è¿ªè¿˜è¦å‡ºSportbackã€Allroadç­‰å››ä¸ªç‰ˆæœ¬å‘¢ï¼Œè¿è‡ªé€‚åº”å·¡èˆªéƒ½æ ‡é…äº†ï¼\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch2 id=\"audio-generation\"\u003eAudio Generation\u003c/h2\u003e\n\u003ch3 id=\"voice-clone\"\u003eVoice Clone\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInput Prompt\u003c/th\u003e\n          \u003cth\u003eTarget Text\u003c/th\u003e\n          \u003cth\u003eTTS Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/FjxTQqU_YwkAAAAATuAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003eå…¨çƒæ¯å¹´æœ‰è¶…è¿‡ä¸€ç™¾ä¸‰åäº”ä¸‡äººï¼Œå› äº¤é€šäº‹æ•…è€Œæ­»äº¡ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/2vMrQpm1ok8AAAAATEAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/wmxOR52zO5kAAAAAS3AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003eThe stained glass offered a hypnotic atmosphere.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Wu73RaH8UfsAAAAAR3AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003ch3 id=\"multi-lingual-synthesis\"\u003eMulti-lingual Synthesis\u003c/h3\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eInput Prompt Text\u003c/th\u003e\n          \u003cth\u003eInput Prompt audio\u003c/th\u003e\n          \u003cth\u003eTarget Text\u003c/th\u003e\n          \u003cth\u003eTTS Result\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eWe asked over twenty different people, and they all said it was his.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/J5M7R7mrCIoAAAAAS3AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003eThe stained glass offered a hypnotic atmosphere.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Pr_3Tqem6_gAAAAATbAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eThe wedding was photographed by celebrity wedding photographer Kid Chan.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/jOIAQrN4ZOsAAAAAUIAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003eBender also conducted extensive research on autism.\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/kPl1TY7Mcz8AAAAAUmAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eå…³äºä¸å°‘ä¸‡è¾¾å¹¿åœºçš„æ³¨å†Œèµ„æœ¬é‡‘æ›´æ”¹ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Exe3SJb_Xk8AAAAATFAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003eå“ï¼Œè¿™äº›æƒ…å†µåœ¨åŒ—äº¬è¿™æ ·çš„å¤§éƒ½å¸‚ï¼Œæ˜¯æ— æ³•é¿å…çš„ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/xOqOSoogXqcAAAAAVLAAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003eé•¿æ˜¥å‘¨äºŒä¹‹å‰æ™´å¤©å¤šäº‘äº”æœˆä¸ƒæ—¥æ˜¯æ™´å¤©ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/pmrSSLsTKMoAAAAAT6AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n          \u003ctd\u003eä¸¤äººä¸€ç›´å¯¹å©šå˜å°å£ï¼Œä½¿ä¼ é—»é—¹å¾—çƒ­çƒ˜çƒ˜ã€‚\u003c/td\u003e\n          \u003ctd\u003e\u003caudio controls src=\"https://mdn.alipayobjects.com/huamei_xb4oy7/afts/file/Wrd3Rpb6PnUAAAAAT6AAAAgADmiGAQFr\"\u003e\u003c/audio\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e","title":"Ming-UniAudio: Speech LLM for Joint Understanding, Generation and Editing with Unified Representation"},{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/inclusionAI/Ming-UniVision\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e ğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI/Ming-UniVision-16B-A3B\"\u003eHugging Face\u003c/a\u003eï½œ ğŸ¤– \u003ca href=\"https://www.modelscope.cn/models/inclusionAI/Ming-UniVision-16B-A3B\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cvideo src=\"https://gw.alipayobjects.com/v/huamei_qlf8jc/afts/video/A*ZBkgTruOxA4AAAAAgyAAAAgAehi-AQ\" width=\"1024px\" height=\"660px\" controls autoplay muted playsinline\u003e\u003c/video\u003e\u003c/p\u003e\n\u003c!-- # Ming-UniVision: Joint Image Understanding and Generation via a Unified Continuous Tokenizer --\u003e\n\u003ch2 id=\"-technical-highlights\"\u003eğŸš€ Technical Highlights\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eFirst Continuous Unified Tokenizer for Vision:\u003c/strong\u003e \u003cstrong\u003eMingTok\u003c/strong\u003e seamlessly supports both image understanding and generation within a single continuous latent spaceâ€”eliminating quantization and bridging modalities.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eFirst NTP-style Autoregressive MLLM with Unified Continuous Visual Tokens:\u003c/strong\u003e By building on MingTok, \u003cstrong\u003eMing-UniVision\u003c/strong\u003e unifies vision and language under a shared next-token prediction framework, enabling end-to-end autoregressive modeling of diverse vision tasks.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReduced Representational Competition â†’ 3.5Ã— Faster Convergence:\u003c/strong\u003e The unified continuous representation aligns semantic understanding and generative dynamics, significantly accelerating joint training without performance trade-offs.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMulti-Round In-Context Learning in a Single Feature Space:\u003c/strong\u003e All operationsâ€”understanding, generation, and editingâ€”occur in the same continuous space, eliminating costly cross-space conversions and enabling simpler, more efficient training and inference.\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"the-challenge-the-inverse-nature-of-seeing-and-drawing\"\u003eThe Challenge: The Inverse Nature of Seeing and Drawing\u003c/h2\u003e\n\u003cp\u003eAutoregressionâ€”the powerful paradigm of modeling the world by â€œpredicting the next tokenâ€â€”has already unified diverse modalities like language and audio. The next frontier is to bring visual understanding (seeing) and visual generation (drawing) into this unified sequenceâ€‘toâ€‘sequence framework.\u003c/p\u003e","title":"Ming-UniVision: Joint Image Understanding and Generation via a Unified Continuous Tokenizer"},{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/inclusionAI/Ming\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e ğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5\"\u003eHugging Face\u003c/a\u003eï½œ ğŸ¤– \u003ca href=\"https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"ming-lite-omni-15-segmentation-as-editing-for-unified-multimodal-ai\"\u003eMing-lite-omni 1.5: Segmentation-as-Editing for Unified Multimodal AI\u003c/h1\u003e\n\u003ch3 id=\"the-hype-and-the-hidden-question\"\u003eThe Hype and the Hidden Question\u003c/h3\u003e\n\u003cp\u003eThe multimodal AI world has been thriving.\u003c/p\u003e\n\u003cp\u003eFrom the debut of Qwen-Image to the interactive editing hype sparked by Nano Banana, image editing has rapidly become the next battlefield for generative AI.\u003c/p\u003e\n\u003cp\u003eEditing fundamentally requires two distinct skill sets:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eKnow \u003cem\u003ewhere\u003c/em\u003e, \u003cem\u003ewhat\u003c/em\u003e, and \u003cem\u003ehow\u003c/em\u003e to change\u003c/strong\u003e (understanding the image)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eProduce the change with high visual quality\u003c/strong\u003e (generating the image)\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eIts rich gameplay and strong interactivity have pulled in users, developers, and creators alike.\u003c/p\u003e","title":"Segmentation-as-Editing for Unified Multimodal AI"},{"summary":"\u003cp\u003eğŸ“– \u003ca href=\"https://arxiv.org/abs/2506.14731\"\u003eTechnical Report\u003c/a\u003e | ğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI/Ring-lite-2507\"\u003eHugging Face\u003c/a\u003eï½œ ğŸ¤– \u003ca href=\"https://modelscope.cn/models/inclusionAI/Ring-lite-2507\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eWe present \u003cstrong\u003eRing-lite-2507\u003c/strong\u003e, an upgraded version of our previously released lightweight reasoning model, \u003cstrong\u003eRing-lite\u003c/strong\u003e (2506). Built upon a \u003cstrong\u003e16.8B\u003c/strong\u003e Mixture-of-Experts (MoE) large language model with \u003cstrong\u003e2.75B\u003c/strong\u003e activated parameters, \u003cstrong\u003eRing-lite-2507\u003c/strong\u003e further advances its reasoning capabilities while demonstrating superior performance across a comprehensive range of LLM benchmarks, including general text understanding, alignment, coding, logical, and agentic tasks. Thanks to our innovative and robust reinforcement learning training pipeline, \u003cstrong\u003eRing-lite-2507\u003c/strong\u003e distinguishes itself from the latest public dense models under 10B parameters by offering competitive performance across various tasks, despite activating only \u003cstrong\u003e1/3\u003c/strong\u003e of their parameter size.\u003c/p\u003e","title":"Introducing Ring-lite-2507"},{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/inclusionAI/Ming\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e ğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI/Ming-Lite-Omni-1.5\"\u003eHugging Face\u003c/a\u003eï½œ ğŸ¤– \u003ca href=\"https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni-1.5\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"overview\"\u003eOverview\u003c/h2\u003e\n\u003cp\u003eMing-lite-omni v1.5 is a comprehensive upgrade to the full-modal capabilities of Ming-lite-omni(\u003ca href=\"https://github.com/inclusionAI/Ming/tree/v1.0\"\u003eGithub\u003c/a\u003e). It significantly improves performance across tasks including image-text understanding, document understanding, video understanding, speech understanding and synthesis, and image generation and editing. Built upon Ling-lite-1.5, Ming-lite-omni v1.5 has a total of 20.3 billion parameters, with 3 billion active parameters in its MoE (Mixture-of-Experts) section. It demonstrates highly competitive results in various modal benchmarks compared to industry-leading models.\u003c/p\u003e","title":"Introducing Ming-Lite-Omni V1.5"},{"summary":"\u003cp\u003eğŸ“– \u003ca href=\"https://arxiv.org/abs/2507.08306\"\u003eTechnical Report\u003c/a\u003e | ğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI/M2-Reasoning\"\u003eHugging Face\u003c/a\u003eï½œ ğŸ¤– \u003ca href=\"https://www.modelscope.cn/models/inclusionAI/M2-Reasoning\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eWe introduce M2-Reasoning-7B, a model designed to excel in both general and spatial reasoning. Our approach integrates two key innovations: (1) a novel data pipeline that generates 294.2K high-quality data samples (168K for cold-start fine-tuning and 126.2K for RLVR), which feature logically coherent reasoning trajectories and have undergone comprehensive assessment; and (2) a dynamic multi-task training strategy with step-wise optimization to mitigate conflicts between data, and task-specific rewards for delivering tailored incentive signals. This combination of curated data and advanced training allows M2-Reasoning-7B to set a new state-of-the-art (SOTA) across 8 benchmarks, showcasing superior performance in both general and spatial reasoning domains.\n\u003cimg loading=\"lazy\" src=\"assets/teaser.png\" alt=\"\"  /\u003e\n\u003c/p\u003e","title":"M2-Reasoning: Empowering MLLMs with Unified General and Spatial Reasoning"},{"summary":"\u003ca href=\"https://github.com/inclusionAI/ABench\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e\n\u003ch2 id=\"-overview\"\u003eğŸŒŸ Overview\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eABench\u003c/strong\u003e is an evolving open-source benchmark suite designed to rigorously evaluate and enhance Large Language Models (LLMs) on \u003cstrong\u003ecomplex cross-domain tasks\u003c/strong\u003e. By targeting current model weaknesses, ABench provides systematic challenges in \u003cstrong\u003ehigh-difficulty specialized domains\u003c/strong\u003e, including physics, actuarial science, logical reasoning, law, and psychology.\u003c/p\u003e\n\u003ch2 id=\"-core-objectives\"\u003eğŸ¯ Core Objectives\u003c/h2\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eAddress Evaluation Gaps\u003c/strong\u003e: Design high-differentiation assessment tasks targeting \u003cstrong\u003eunderperforming question types\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEstablish Unified Standards\u003c/strong\u003e: Create \u003cstrong\u003ereliable, comparable benchmarks\u003c/strong\u003e for multi-domain LLM evaluation\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExpand Capability Boundaries\u003c/strong\u003e: Drive continuous optimization of knowledge systems and reasoning mechanisms through challenging innovative problems\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2 id=\"-dataset-release-status\"\u003eğŸ“Š Dataset Release Status\u003c/h2\u003e\n\u003ctable\u003e\n  \u003cthead\u003e\n      \u003ctr\u003e\n          \u003cth\u003eDomain\u003c/th\u003e\n          \u003cth\u003eDescription\u003c/th\u003e\n          \u003cth\u003eStatus\u003c/th\u003e\n      \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003ePhysics\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003e500 university/competition-level physics problems (400 static + 100 dynamic parametric variants) covering 10+ fields from classical mechanics to modern physics\u003c/td\u003e\n          \u003ctd\u003e\u003ca href=\"https://github.com/inclusionAI/ABench/blob/main/Physics/README.md\"\u003eâœ… Released\u003c/a\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003eActuary\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003eCurated actuarial exam problems covering core topics: probability statistics, financial mathematics, life/non-life insurance, actuarial models, and risk management\u003c/td\u003e\n          \u003ctd\u003e\u003ca href=\"https://github.com/inclusionAI/ABench/blob/main/Actuary/README.md\"\u003eâœ… Released\u003c/a\u003e\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003eLogic\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003eHigh-differentiation logical reasoning problems from authoritative tests (LSAT/GMAT/GRE/SBI/Chinese Civil Service Exam)\u003c/td\u003e\n          \u003ctd\u003eğŸ”„ In Preparation\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003ePsychology\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003ePsychological case studies and research questions (objective/subjective) evaluating understanding of human behavior and theories\u003c/td\u003e\n          \u003ctd\u003eğŸ”„ In Preparation\u003c/td\u003e\n      \u003c/tr\u003e\n      \u003ctr\u003e\n          \u003ctd\u003e\u003cstrong\u003eLaw\u003c/strong\u003e\u003c/td\u003e\n          \u003ctd\u003eAuthoritative judicial exam materials covering core legal domains: criminal/civil/administrative/procedural/international law\u003c/td\u003e\n          \u003ctd\u003eğŸ”„ In Preparation\u003c/td\u003e\n      \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e","title":"ABench: An Evolving Open-Source Benchmark"},{"summary":"\u003cp\u003e\u003cem\u003e\u0026ldquo;Self-awareness: the hardest problem isn\u0026rsquo;t solving within limits, it\u0026rsquo;s discovering the own limitations\u0026rdquo;\u003c/em\u003e\n\u003ca href=\"https://x.com/InclusionAI666\"\u003e\u003cimg loading=\"lazy\" src=\"https://img.shields.io/twitter/follow/AWorld_AI?style=social\" alt=\"Twitter Follow\"  /\u003e\n\u003c/a\u003e\n\u003ca href=\"https://raw.githubusercontent.com/inclusionAI/AWorld/main/readme_assets/aworld_wechat_qr.jpg\"\u003e\u003cimg loading=\"lazy\" src=\"https://img.shields.io/badge/WeChat-Add%20us-green?logo=wechat\u0026amp;logoColor=white\" alt=\"WeChat QR Code\"  /\u003e\n\u003c/a\u003e\n\u003ca href=\"https://discord.gg/b4Asj2ynMw\"\u003e\u003cimg loading=\"lazy\" src=\"https://img.shields.io/badge/Discord-Join%20us-blue?logo=discord\u0026amp;logoColor=white\" alt=\"Discord\"  /\u003e\n\u003c/a\u003e\n\u003ca href=\"https://opensource.org/licenses/MIT\"\u003e\u003cimg loading=\"lazy\" src=\"https://img.shields.io/badge/License-MIT-yellow.svg\" alt=\"License: MIT\"  /\u003e\n\u003c/a\u003e\n\u003ca href=\"https://deepwiki.com/inclusionAI/AWorld\"\u003e\u003cimg loading=\"lazy\" src=\"https://img.shields.io/badge/DeepWiki-Explore-blueviolet?logo=wikipedia\u0026amp;logoColor=white\" alt=\"DeepWiki\"  /\u003e\n\u003c/a\u003e\u003c/p\u003e\n\u003c!-- [![arXiv](https://img.shields.io/badge/arXiv-xxxx.xxxxx-b31b1b.svg)](https://arxiv.org/abs/xxxx.xxxxx) --\u003e\n\u003ch2 id=\"table-of-contents\"\u003eTable of Contents\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"/blog/aworld/#news\"\u003eNews\u003c/a\u003e â€” Latest updates and announcements.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/blog/aworld/#introduction\"\u003eIntroduction\u003c/a\u003e â€” Overview and purpose of the project.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/blog/aworld/#installation\"\u003eInstallation\u003c/a\u003e â€” Step-by-step setup instructions.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/blog/aworld/#quick-start\"\u003eQuick Start\u003c/a\u003e â€” Get started with usage examples.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/blog/aworld/#architecture\"\u003eArchitecture\u003c/a\u003e â€” Explore the multi-agent system design.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/blog/aworld/#demo\"\u003eDemo\u003c/a\u003e â€” See the project in action with demonstrations.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/blog/aworld/#contributing\"\u003eContributing\u003c/a\u003e â€” How to get involved and contribute.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"/blog/aworld/#license\"\u003eLicense\u003c/a\u003e â€” Project licensing details.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"news\"\u003eNews\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eğŸ¦¤ [2025/07/07] AWorld, as a runtime, is now ready for agentic training. See \u003ca href=\"/blog/aworld/#self-improvement-with-diverse-runtimes\"\u003eSelf-Improvement section\u003c/a\u003e for details. We have updated our score to 77.08 on the GAIA test. Learn how to construct a GAIA runtime in the \u003ca href=\"/blog/aworld/#demo-of-gaia-agent-runtime\"\u003eDemo section\u003c/a\u003e.\u003c/li\u003e\n\u003cli\u003eğŸ¦© [2025/06/19] We have updated our score to 72.43 on the GAIA test. Additionally, we have introduced a new local running mode. See \u003ccode\u003e./README-local.md\u003c/code\u003e for detailed instructions.\u003c/li\u003e\n\u003cli\u003eğŸ³ [2025/05/22] For quick GAIA evaluation, MCP tools, AWorld, and models are now available in a single Docker image. See \u003ccode\u003e./README-docker.md\u003c/code\u003e for instructions and \u003ca href=\"https://www.youtube.com/watch?v=kkYWeVvJKrg\"\u003eyoutube video\u003c/a\u003e for demo.\u003c/li\u003e\n\u003cli\u003eğŸ¥³ [2025/05/13] AWorld has updated its state management for browser use and enhanced the video processing MCP server, achieving a score of 77.58 on GAIA validation (Pass@1 = 61.8) and maintaining its position as the top-ranked open-source framework. Learn more: \u003ca href=\"https://huggingface.co/spaces/gaia-benchmark/leaderboard\"\u003eGAIA leaderboard\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eâœ¨ [2025/04/23] AWorld ranks 3rd on GAIA benchmark (69.7 avg) with impressive Pass@1 = 58.8, 1st among open-source frameworks. Reproduce with \u003ccode\u003epython examples/gaia/run.py\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eAWorld (Agent World) is a multi-agent playground that enables agents to collaborate and self-improve. The framework supports a wide range of applications, including but not limited to product prototype verification, foundation model training and Multi-Agent System (MAS) design meta-learning.\u003c/p\u003e","title":"AWorld: The Agent Runtime for Self-Improvement"},{"summary":"\u003c!-- # Ming-Lite-Omni --\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/inclusionAI/Ming/tree/Ming-Lite-Omni-Preview/Ming-unify\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e ğŸ“‘ \u003ca href=\"https://arxiv.org/abs/2506.09344\"\u003eTechnical Report\u003c/a\u003eï½œğŸ“–\u003ca href=\"https://lucaria-academy.github.io/Ming-Omni/\"\u003eProject Page\u003c/a\u003e ï½œğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI/Ming-Lite-Omni\"\u003eHugging Face\u003c/a\u003eï½œ ğŸ¤– \u003ca href=\"https://www.modelscope.cn/models/inclusionAI/Ming-Lite-Omni\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eMing-lite-omni, a light version of Ming-omni, which is derived from \u003ca href=\"https://github.com/inclusionAI/Ling\"\u003eLing-lite\u003c/a\u003e and features 2.8 billion activated parameter. Ming-lite-omni is a unified multimodal model capable of processing images, text, audio, and video, while demonstrating strong proficiency in both speech and image generation. Ming-lite-omni employs dedicated encoders to extract tokens from different modalities, which are then processed by Ling, an MoE architecture equipped with newly proposed modality-specific routers. This design enables a single model to efficiently process and fuse multimodal inputs within a unified framework, thereby facilitating diverse tasks without requiring separate models, task-specific fine-tuning, or structural redesign. Importantly, Ming-lite-omni extends beyond conventional multimodal models by supporting audio and image generation. This is achieved through the integration of an advanced audio decoder for natural-sounding speech and Ming-Lite-Uni for high-quality image generation, which also allow the model to engage in context-aware chatting, perform text-to-speech conversion, and conduct versatile image editing. Our experimental results showcase Ming-lite-omni offers a powerful solution for unified perception and generation across all modalities.\nNotably, Ming-lite-omni is the first open-source model we are aware of to match GPT-4o in modality support, and we release all code and model weights to encourage further research and development in the community.\u003c/p\u003e","title":"Ming-Omni: A Unified Multimodal Model for Perception and Generation"},{"summary":"\u003cp align=\"center\"\u003eğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI\"\u003eHugging Face\u003c/a\u003e\u0026nbsp\u0026nbsp | \u0026nbsp\u0026nbspğŸ¤– \u003ca href=\"https://modelscope.cn/organization/inclusionAI\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eLing is a MoE LLM provided and open-sourced by InclusionAI. We introduce two different sizes, which are Ling-lite and Ling-plus. Ling-lite has 16.8 billion parameters with 2.75 billion activated parameters, while Ling-plus has 290 billion parameters with 28.8 billion activated parameters. Both models demonstrate impressive performance compared to existing models in the industry.\u003c/p\u003e\n\u003cp\u003eTheir structure makes it easy to scale up and down and adapt to different tasks, so users can use these models for a wide range of tasks, from processing natural language to solving complex problems. Furthermore, the open-source nature of Ling promotes collaboration and innovation within the AI community, fostering a diverse range of use cases and enhancements.\u003c/p\u003e","title":"Ling: A MoE LLM Provided and Open-sourced by InclusionAI"},{"summary":"\u003c!-- \u003ch1 align=\"center\"\u003eMing-Lite-Uni: Advancements in Unified Architecture for Natural Multimodal Interaction\u003c/h1\u003e --\u003e\n\u003cp align=\"left\"\u003e\n        \u003ca href=\"https://github.com/inclusionAI/Ming/tree/Ming-Lite-Omni-Preview/Ming-unify\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e ğŸ“‘ \u003ca href=\"https://arxiv.org/pdf/2505.02471\"\u003ePaper\u003c/a\u003eï½œğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI/Ming-Lite-Uni\"\u003eHugging Face\u003c/a\u003eï½œğŸ¤– \u003ca href=\"https://modelscope.cn/models/inclusionAI/Ming-Lite-Uni\"\u003eModelScope\u003c/a\u003e\n\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eMing-Lite-Uni\u003c/code\u003e is an open-source multimodal framework that includes a newly developed unified visual generator, and a native multimodal autoregressive model meant to integrate vision and language.\u003c/p\u003e\n\u003cp\u003eThis project offers an open-source implementation of the integrated MetaQueries and M2-omni framework, while offering the innovative \u003cstrong\u003emulti-scale learnable tokens\u003c/strong\u003e and \u003cstrong\u003emulti-scale representation alignment strategy\u003c/strong\u003e. Ming-Lite-Uni utilizes a fixed MLLM and a learnable diffusion model, allowing native multimodal AR models to execute text-to-image production and instruction-based image editing tasks, hence enhancing their functionalities beyond mere visual comprehension. Our experimental findings demonstrate the robust efficacy of Ming-Lite-Uni and highlight the remarkable fluidity of its interactive process. Ming-Lite-Uni is now in the alpha phase and will soon undergo additional refinement.\u003c/p\u003e","title":"Ming-Lite-Uni: Advancements in Unified Architecture for Natural Multimodal Interaction"},{"summary":"\u003cp\u003e\u003ca href=\"https://github.com/inclusionAI/Ming\" class=\"btn external\" target=\"_blank\"\u003eGITHUB\u003c/a\u003e ğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI\"\u003eHugging Face\u003c/a\u003e | ğŸ¤– \u003ca href=\"https://modelscope.cn/organization/inclusionAI\"\u003eModelScope\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eMing-Lite-Omni-Preview is built upon \u003ca href=\"https://github.com/inclusionAI/Ling\"\u003eLing-Lite\u003c/a\u003e, which is a MoE model designed to perceive a wide range of modalities, including text, images, audio, and video, while generating text and natural speech in a streaming manner. To naturely handle the diverse modalities, we have enhanced Ling-Lite by incorporating modality-specific routers for each modality. As a result, Ming-Omni excels at handling information from diverse modalities and is highly scalable.\u003c/p\u003e","title":"Ming-Lite-Omni-Preview: A MoE Model Designed to Perceive a Wide Range of Modalities"},{"summary":"\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eAgent exhibits powerful capabilities by interacting with the external environment and making decisions based on the feedback it receives from the environment.\nFor complex problems, it is often necessary for an agent to have multi-turn interactions with the environment to reach a solution. The complexity and dynamism of environments, coupled with the necessity for multi-turn interactions, pose numerous challenges in training agents.\u003c/p\u003e\n\u003cp\u003eWe introduce \u003cstrong\u003eAgenticLearning\u003c/strong\u003e, an open-source agent training paradigm designed to empower researchers to train and evaluate autonomous agents effectively. AgenticLearning offers a framework for multi-turn interactions with the environment, enabling models to learn how to interact with the environment and make decisions based on its feedback, thereby enhancing the models\u0026rsquo; ability to leverage the environment to solve complex problems.\u003c/p\u003e","title":"Agentic Learning"},{"summary":"\u003cp align=\"center\"\u003e\n| \u003ca href=\"https://arxiv.org/pdf/2505.24298\"\u003e\u003cb\u003ePaper\u003c/b\u003e\u003c/a\u003e | \u003ca href=\"https://inclusionai.github.io/AReaL/\"\u003e\u003cb\u003eDocumentation\u003c/b\u003e\u003c/a\u003e | \u003ca href=\"https://deepwiki.com/inclusionAI/AReaL\"\u003e\u003cb\u003eAsk DeepWiki\u003c/b\u003e\u003c/a\u003e | \u003ca href=\"https://huggingface.co/collections/inclusionAI/areal-boba-2-683f0e819ccb7bb2e1b2f2d5\"\u003e\u003cb\u003eğŸ¤— Models \u0026 Data\u003c/b\u003e\u003c/a\u003e |\n\u003ca href=\"https://github.com/inclusionAI/AReaL/blob/main/assets/wechat_qrcode.png\" target=\"_blank\"\u003e\u003cb\u003eWeChat Group\u003c/b\u003e\u003c/a\u003e |\n\u003c/p\u003e\n\u003cp\u003eAReaL (Ant Reasoning RL) is an open-source \u003cstrong\u003efully asynchronous reinforcement learning training system\u003c/strong\u003e for large reasoning models developed at \u003cstrong\u003ethe RL Lab, Ant Research\u003c/strong\u003e. Built upon the open-source project \u003ca href=\"https://github.com/openpsi-project/ReaLHF\"\u003eRealHF\u003c/a\u003e, we are fully committed to open-source by providing training details, data, and infrastructure required to reproduce results along with the model itself. AReaL aims to help everyone build their own AI agents easily and affordably. Our team loves milk tea because it\u0026rsquo;s delicious, customizable, and affordable. We hope you enjoy our project just like how you enjoy real-world milk tea (cheers).\u003c/p\u003e","title":"AReaL: Ant Reasoning Reinforcement Learning for LLMs"},{"summary":"\u003ch2 id=\"news\"\u003e\u003cstrong\u003eNews\u003c/strong\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMay 30, 2025\u003c/strong\u003e: PromptCoT-Mamba released! Introducing an attention-free foundation model for reasoning tasks.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eApr 11, 2025\u003c/strong\u003e: PromptCoT-QwQ-32B model and its training data released, achieving new state-of-the-art results.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMar 7, 2025\u003c/strong\u003e: PromptCoT project launched, including the problem generation model, distilled models (PromptCoT-DS series), and associated datasets.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"overview\"\u003e\u003cstrong\u003eOverview\u003c/strong\u003e\u003c/h2\u003e\n\u003cp\u003eThis repository unifies two synergistic projects aimed at advancing the frontiers of mathematical and code reasoning in Large Language Models (LLMs): \u003cstrong\u003ePromptCoT\u003c/strong\u003e and \u003cstrong\u003ePromptCoT-Mamba\u003c/strong\u003e.\u003c/p\u003e","title":"PromptCoT \u0026 PromptCoT-Mamba: Advancing the Frontiers of Reasoning"},{"summary":"\u003cp align=\"center\"\u003e\n          ğŸ¤— \u003ca href=\"https://huggingface.co/inclusionAI\"\u003eHugging Face\u003c/a\u003e\u0026nbsp\u0026nbsp | \u0026nbsp\u0026nbspğŸ¤– \u003ca href=\"https://modelscope.cn/organization/inclusionAI\"\u003eModelScope\u003c/a\u003e\n\u003ch2 id=\"news\"\u003eNews\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e[2025-06]:ğŸ‰ Add \u003ca href=\"https://huggingface.co/inclusionAI/Ring-lite\"\u003eRing-lite\u003c/a\u003e Model\u003c/li\u003e\n\u003cli\u003e[2025-04]:ğŸ‰ Add \u003ca href=\"hybrid_linear\"\u003eRing-lite-linear-preview\u003c/a\u003e Model\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"introduction\"\u003eIntroduction\u003c/h2\u003e\n\u003cp\u003eRing is a reasoning MoE LLM provided and open-sourced by InclusionAI, derived from \u003ca href=\"https://github.com/inclusionAI/Ling\"\u003eLing\u003c/a\u003e. We introduce Ring-lite-distill-preview, which has 16.8 billion parameters with 2.75 billion activated parameters. This model demonstrates impressive reasoning performance compared to existing models in the industry.\u003c/p\u003e\n\u003ch2 id=\"model-downloads\"\u003eModel Downloads\u003c/h2\u003e\n\u003cp\u003eYou can download the following table to see the various parameters for your use case. If you are located in mainland China, we also provide the model on ModelScope.cn to speed up the download process.\u003c/p\u003e","title":"Ring: A Reasoning MoE LLM Provided and Open-sourced by InclusionAI"}]