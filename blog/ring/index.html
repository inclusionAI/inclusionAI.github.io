<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Ring: A Reasoning MoE LLM Provided and Open-sourced by InclusionAI | INCLUSION AI</title><meta name=keywords content><meta name=description content="
          ðŸ¤— Hugging Face&nbsp&nbsp | &nbsp&nbspðŸ¤– ModelScope
News

[2025-06]:ðŸŽ‰ Add Ring-lite Model
[2025-04]:ðŸŽ‰ Add Ring-lite-linear-preview Model

Introduction
Ring is a reasoning MoE LLM provided and open-sourced by InclusionAI, derived from Ling. We introduce Ring-lite-distill-preview, which has 16.8 billion parameters with 2.75 billion activated parameters. This model demonstrates impressive reasoning performance compared to existing models in the industry.
Model Downloads
You can download the following table to see the various parameters for your use case. If you are located in mainland China, we also provide the model on ModelScope.cn to speed up the download process."><meta name=author content="inclusionAI, Ant Group"><link rel=canonical href=https://inclusionai.github.io/blog/ring/><link crossorigin=anonymous href=/assets/css/stylesheet.419cab9a4e041985806269ccd5fb7e29179062491b1e90454454dcf1af0c9022.css integrity="sha256-QZyrmk4EGYWAYmnM1ft+KReQYkkbHpBFRFTc8a8MkCI=" rel="preload stylesheet" as=style><link rel=icon href=https://inclusionai.github.io/favicon.png><link rel=apple-touch-icon href=https://inclusionai.github.io/favicon.png><link rel=manifest href=https://inclusionai.github.io/site.webmanifest><meta name=theme-color content="#615CED"><link rel=alternate hreflang=en href=https://inclusionai.github.io/blog/ring/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script defer crossorigin=anonymous src=/js/custom.e9080c0a180dc80cf80d5fef7c857effb14f65c998e22134feb9896034b1b81a.js integrity="sha256-6QgMChgNyAz4DV/vfIV+/7FPZcmY4iE0/rmJYDSxuBo="></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.css integrity=sha384-Juol1FqnotbkyZUT5Z7gUPjQ9gzlwCENvUZTpQBAPxtusdwFLRy382PSDx5UUJ4/ crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/katex.min.js integrity=sha384-97gW6UIJxnlKemYavrqDHSX3SiygeOwIZhwyOKRfSaf0JWKRVj9hLASHgFTzT+0O crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.3/dist/contrib/auto-render.min.js integrity=sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05 crossorigin=anonymous></script><script>document.addEventListener("DOMContentLoaded",function(){renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],throwOnError:!1})})</script><script async src="https://www.googletagmanager.com/gtag/js?id=G-NMEMBZ8R90"></script><script>var doNotTrack=!1,dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes";if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-NMEMBZ8R90")}</script><meta property="og:title" content="Ring: A Reasoning MoE LLM Provided and Open-sourced by InclusionAI"><meta property="og:description" content="
          ðŸ¤— Hugging Face&nbsp&nbsp | &nbsp&nbspðŸ¤– ModelScope
News

[2025-06]:ðŸŽ‰ Add Ring-lite Model
[2025-04]:ðŸŽ‰ Add Ring-lite-linear-preview Model

Introduction
Ring is a reasoning MoE LLM provided and open-sourced by InclusionAI, derived from Ling. We introduce Ring-lite-distill-preview, which has 16.8 billion parameters with 2.75 billion activated parameters. This model demonstrates impressive reasoning performance compared to existing models in the industry.
Model Downloads
You can download the following table to see the various parameters for your use case. If you are located in mainland China, we also provide the model on ModelScope.cn to speed up the download process."><meta property="og:type" content="article"><meta property="og:url" content="https://inclusionai.github.io/blog/ring/"><meta property="og:image" content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="blog"><meta property="article:published_time" content="2025-04-01T00:00:03+08:00"><meta property="article:modified_time" content="2025-04-01T00:00:03+08:00"><meta property="og:site_name" content="inclusionAI"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://inclusionai.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="Ring: A Reasoning MoE LLM Provided and Open-sourced by InclusionAI"><meta name=twitter:description content="
          ðŸ¤— Hugging Face&nbsp&nbsp | &nbsp&nbspðŸ¤– ModelScope
News

[2025-06]:ðŸŽ‰ Add Ring-lite Model
[2025-04]:ðŸŽ‰ Add Ring-lite-linear-preview Model

Introduction
Ring is a reasoning MoE LLM provided and open-sourced by InclusionAI, derived from Ling. We introduce Ring-lite-distill-preview, which has 16.8 billion parameters with 2.75 billion activated parameters. This model demonstrates impressive reasoning performance compared to existing models in the industry.
Model Downloads
You can download the following table to see the various parameters for your use case. If you are located in mainland China, we also provide the model on ModelScope.cn to speed up the download process."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Blog","item":"https://inclusionai.github.io/blog/"},{"@type":"ListItem","position":2,"name":"Ring: A Reasoning MoE LLM Provided and Open-sourced by InclusionAI","item":"https://inclusionai.github.io/blog/ring/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Ring: A Reasoning MoE LLM Provided and Open-sourced by InclusionAI","name":"Ring: A Reasoning MoE LLM Provided and Open-sourced by InclusionAI","description":" ðŸ¤— Hugging Face\u0026nbsp\u0026nbsp | \u0026nbsp\u0026nbspðŸ¤– ModelScope News [2025-06]:ðŸŽ‰ Add Ring-lite Model [2025-04]:ðŸŽ‰ Add Ring-lite-linear-preview Model Introduction Ring is a reasoning MoE LLM provided and open-sourced by InclusionAI, derived from Ling. We introduce Ring-lite-distill-preview, which has 16.8 billion parameters with 2.75 billion activated parameters. This model demonstrates impressive reasoning performance compared to existing models in the industry.\nModel Downloads You can download the following table to see the various parameters for your use case. If you are located in mainland China, we also provide the model on ModelScope.cn to speed up the download process.\n","keywords":[],"articleBody":" ðŸ¤— Hugging FaceÂ | ðŸ¤– ModelScope News [2025-06]:ðŸŽ‰ Add Ring-lite Model [2025-04]:ðŸŽ‰ Add Ring-lite-linear-preview Model Introduction Ring is a reasoning MoE LLM provided and open-sourced by InclusionAI, derived from Ling. We introduce Ring-lite-distill-preview, which has 16.8 billion parameters with 2.75 billion activated parameters. This model demonstrates impressive reasoning performance compared to existing models in the industry.\nModel Downloads You can download the following table to see the various parameters for your use case. If you are located in mainland China, we also provide the model on ModelScope.cn to speed up the download process.\nModel #Total Params #Activated Params Context Length Download Ring-lite-distill-preview 16.8B 2.75B 64K ðŸ¤— HuggingFace ðŸ¤– ModelScope Ring-lite 16.8B 2.75B 128K ðŸ¤— HuggingFace ðŸ¤– ModelScope Quickstart ðŸ¤— Hugging Face Transformers Here is a code snippet to show you how to use the chat model with transformers:\nfrom transformers import AutoModelForCausalLM, AutoTokenizer model_name = \"inclusionAI/Ring-lite\" model = AutoModelForCausalLM.from_pretrained( model_name, torch_dtype=\"auto\", device_map=\"auto\" ) tokenizer = AutoTokenizer.from_pretrained(model_name) prompt = \"Give me a short introduction to large language models.\" messages = [ {\"role\": \"system\", \"content\": \"You are Ring, an assistant created by inclusionAI\"}, {\"role\": \"user\", \"content\": prompt} ] text = tokenizer.apply_chat_template( messages, tokenize=False, add_generation_prompt=True ) model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device) generated_ids = model.generate( **model_inputs, max_new_tokens=8192 ) generated_ids = [ output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids) ] response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0] ðŸ¤– ModelScope If youâ€™re in mainland China, we strongly recommend you to use our model from ðŸ¤– ModelScope.\nDeployment Please refer to Ling\nFinetuning Please refer to Ling\nLicense This code repository is licensed under the MIT License.\nCitation [TBD]\n","wordCount":"258","inLanguage":"en","datePublished":"2025-04-01T00:00:03+08:00","dateModified":"2025-04-01T00:00:03+08:00","author":{"@type":"Person","name":"inclusionAI, Ant Group"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://inclusionai.github.io/blog/ring/"},"publisher":{"@type":"Organization","name":"INCLUSION AI","logo":{"@type":"ImageObject","url":"https://inclusionai.github.io/favicon.png"}}}</script></head><body id=top><script>const hasHeaderBg=!1</script><header class=header><div class=nav-container><nav class=nav><div class=logo><a href=/ accesskey=h title="inclusionAI (Alt + H)"><img src=https://inclusionai.github.io/img/logo_head.png alt aria-label=logo height=50></a></div><ul id=menu><li><a href=/blog/ title=Blog><span>Blog</span></a></li><li><a href=/publication title=Publication><span>Publication</span></a></li><li><a href=/about title=About><span>About</span></a></li><li><a href=https://github.com/inclusionAI title="Try Ling & Ming"><span>Try Ling & Ming</span>&nbsp;
<svg fill="none" shape-rendering="geometricPrecision" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></div></header><div class=hero-container></div><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=/>Home</a>&nbsp;Â»&nbsp;<a href=https://inclusionai.github.io/blog/>Blog</a></div><h1 class=post-title>Ring: A Reasoning MoE LLM Provided and Open-sourced by InclusionAI</h1><div class=post-meta><span class=post-date title="2025-04-01 00:00:03 +0800 +0800">April 1, 2025</span>
<span class=post-word-count>258 words</span>
<span class=post-author>inclusionAI, Ant Group</span></div></header><div class=post-content><p align=center>ðŸ¤— <a href=https://huggingface.co/inclusionAI>Hugging Face</a>&nbsp&nbsp | &nbsp&nbspðŸ¤– <a href=https://modelscope.cn/organization/inclusionAI>ModelScope</a><h2 id=news>News<a hidden class=anchor aria-hidden=true href=#news>#</a></h2><ul><li>[2025-06]:ðŸŽ‰ Add <a href=https://huggingface.co/inclusionAI/Ring-lite>Ring-lite</a> Model</li><li>[2025-04]:ðŸŽ‰ Add <a href=hybrid_linear>Ring-lite-linear-preview</a> Model</li></ul><h2 id=introduction>Introduction<a hidden class=anchor aria-hidden=true href=#introduction>#</a></h2><p>Ring is a reasoning MoE LLM provided and open-sourced by InclusionAI, derived from <a href=https://github.com/inclusionAI/Ling>Ling</a>. We introduce Ring-lite-distill-preview, which has 16.8 billion parameters with 2.75 billion activated parameters. This model demonstrates impressive reasoning performance compared to existing models in the industry.</p><h2 id=model-downloads>Model Downloads<a hidden class=anchor aria-hidden=true href=#model-downloads>#</a></h2><p>You can download the following table to see the various parameters for your use case. If you are located in mainland China, we also provide the model on ModelScope.cn to speed up the download process.</p><div align=center><table><thead><tr><th style=text-align:center><strong>Model</strong></th><th style=text-align:center><strong>#Total Params</strong></th><th style=text-align:center><strong>#Activated Params</strong></th><th style=text-align:center><strong>Context Length</strong></th><th style=text-align:center><strong>Download</strong></th></tr></thead><tbody><tr><td style=text-align:center>Ring-lite-distill-preview</td><td style=text-align:center>16.8B</td><td style=text-align:center>2.75B</td><td style=text-align:center>64K</td><td style=text-align:center><a href=https://huggingface.co/inclusionAI/Ring-lite-distill-preview>ðŸ¤— HuggingFace</a><br><a href=https://modelscope.cn/models/inclusionAI/Ring-lite-distill-preview>ðŸ¤– ModelScope</a></td></tr><tr><td style=text-align:center>Ring-lite</td><td style=text-align:center>16.8B</td><td style=text-align:center>2.75B</td><td style=text-align:center>128K</td><td style=text-align:center><a href=https://huggingface.co/inclusionAI/Ring-lite>ðŸ¤— HuggingFace</a><br><a href=https://modelscope.cn/models/inclusionAI/Ring-lite>ðŸ¤– ModelScope</a></td></tr></tbody></table></div><h2 id=quickstart>Quickstart<a hidden class=anchor aria-hidden=true href=#quickstart>#</a></h2><h3 id=-hugging-face-transformers>ðŸ¤— Hugging Face Transformers<a hidden class=anchor aria-hidden=true href=#-hugging-face-transformers>#</a></h3><p>Here is a code snippet to show you how to use the chat model with <code>transformers</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoModelForCausalLM</span><span class=p>,</span> <span class=n>AutoTokenizer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model_name</span> <span class=o>=</span> <span class=s2>&#34;inclusionAI/Ring-lite&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;Give me a short introduction to large language models.&#34;</span>
</span></span><span class=line><span class=cl><span class=n>messages</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;You are Ring, an assistant created by inclusionAI&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>prompt</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>messages</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model_inputs</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=p>([</span><span class=n>text</span><span class=p>],</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>generated_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=o>**</span><span class=n>model_inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>8192</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>generated_ids</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=n>output_ids</span><span class=p>[</span><span class=nb>len</span><span class=p>(</span><span class=n>input_ids</span><span class=p>):]</span> <span class=k>for</span> <span class=n>input_ids</span><span class=p>,</span> <span class=n>output_ids</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>model_inputs</span><span class=o>.</span><span class=n>input_ids</span><span class=p>,</span> <span class=n>generated_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span></code></pre></div><h3 id=-modelscope>ðŸ¤– ModelScope<a hidden class=anchor aria-hidden=true href=#-modelscope>#</a></h3><p>If you&rsquo;re in mainland China, we strongly recommend you to use our model from ðŸ¤– <a href=https://modelscope.cn/organization/inclusionAI>ModelScope</a>.</p><h2 id=deployment>Deployment<a hidden class=anchor aria-hidden=true href=#deployment>#</a></h2><p>Please refer to <a href=https://github.com/inclusionAI/Ling>Ling</a></p><h2 id=finetuning>Finetuning<a hidden class=anchor aria-hidden=true href=#finetuning>#</a></h2><p>Please refer to <a href=https://github.com/inclusionAI/Ling>Ling</a></p><h2 id=license>License<a hidden class=anchor aria-hidden=true href=#license>#</a></h2><p>This code repository is licensed under <a href=https://github.com/inclusionAI/Ring/blob/master/LICENSE>the MIT License</a>.</p><h2 id=citation>Citation<a hidden class=anchor aria-hidden=true href=#citation>#</a></h2><p>[TBD]</p></div></article></main><footer class=footer><span>&copy; 2026 <a href=https://inclusionai.github.io/>INCLUSION AI</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 8" fill="currentColor"><path d="M12 8H0l6-8z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")},mybutton.oncontextmenu=e=>{e.preventDefault(),document.querySelectorAll(".example-container").forEach(e=>{e.style.backgroundColor="unset"}),document.querySelectorAll(".example-content").forEach(e=>{e.style.display="block",e.style.backgroundColor="var(--code-bg)",e.style.marginBottom="var(--modal-gap)",e.classList.remove("scroll")}),document.querySelectorAll(".next-button").forEach(e=>{e.style.display="none"})}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>